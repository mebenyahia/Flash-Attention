{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2b8a760",
      "metadata": {
        "id": "f2b8a760"
      },
      "source": [
        "# Demo Notebook: Flash-Transformer\n",
        "This notebook demonstrates how to:\n",
        "1. Install dependencies\n",
        "2. Download & preprocess data\n",
        "3. Train the Transformer model with FlashAttention\n",
        "4. Evaluate on the test set\n",
        "5. Run a quick inference example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0zIzMS3KpBD",
        "outputId": "cb29e209-ed1a-4f51-891d-5b51220b8ce9"
      },
      "id": "g0zIzMS3KpBD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os"
      ],
      "metadata": {
        "id": "EeLK3amsKmaM"
      },
      "id": "EeLK3amsKmaM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/flash_transformer/'"
      ],
      "metadata": {
        "id": "l_6S7JfaKnLy"
      },
      "id": "l_6S7JfaKnLy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"{path}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bh8IGOjKt8a",
        "outputId": "7b1be55e-716c-4599-ed24-b7debfd1f62b"
      },
      "id": "3Bh8IGOjKt8a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bleu_scores_plot.png\t  checkpoints  data\t  requirements.txt  scripts  tests\n",
            "bleu_scores_results.json  config       notebooks  results.json\t    src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"{path}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOyyBPoCKvvC",
        "outputId": "9473f8f6-c44d-494c-f196-05af5ca7181e"
      },
      "id": "BOyyBPoCKvvC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/flash_transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Current directory:\", os.getcwd())\n",
        "\n",
        "!ls -R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z-6Xg_zK6PK",
        "outputId": "89a5ff90-3373-4466-c8d2-96ff1642148c"
      },
      "id": "0z-6Xg_zK6PK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/My Drive/flash_transformer\n",
            ".:\n",
            "bleu_scores_plot.png\t  checkpoints  data\t  requirements.txt  scripts  tests\n",
            "bleu_scores_results.json  config       notebooks  results.json\t    src\n",
            "\n",
            "./checkpoints:\n",
            "model_epoch_100.pt  model_epoch_193.pt\tmodel_epoch_92.pt    model_step_51500.pt\n",
            "model_epoch_101.pt  model_epoch_194.pt\tmodel_epoch_93.pt    model_step_52000.pt\n",
            "model_epoch_102.pt  model_epoch_195.pt\tmodel_epoch_94.pt    model_step_52500.pt\n",
            "model_epoch_103.pt  model_epoch_196.pt\tmodel_epoch_95.pt    model_step_53000.pt\n",
            "model_epoch_104.pt  model_epoch_197.pt\tmodel_epoch_96.pt    model_step_53500.pt\n",
            "model_epoch_105.pt  model_epoch_198.pt\tmodel_epoch_97.pt    model_step_54000.pt\n",
            "model_epoch_106.pt  model_epoch_199.pt\tmodel_epoch_98.pt    model_step_54500.pt\n",
            "model_epoch_107.pt  model_epoch_19.pt\tmodel_epoch_99.pt    model_step_55000.pt\n",
            "model_epoch_108.pt  model_epoch_1.pt\tmodel_epoch_9.pt     model_step_5500.pt\n",
            "model_epoch_109.pt  model_epoch_200.pt\tmodel_step_10000.pt  model_step_55500.pt\n",
            "model_epoch_10.pt   model_epoch_201.pt\tmodel_step_1000.pt   model_step_56000.pt\n",
            "model_epoch_110.pt  model_epoch_202.pt\tmodel_step_10500.pt  model_step_56500.pt\n",
            "model_epoch_111.pt  model_epoch_203.pt\tmodel_step_11000.pt  model_step_57000.pt\n",
            "model_epoch_112.pt  model_epoch_204.pt\tmodel_step_11500.pt  model_step_57500.pt\n",
            "model_epoch_113.pt  model_epoch_205.pt\tmodel_step_12000.pt  model_step_58000.pt\n",
            "model_epoch_114.pt  model_epoch_206.pt\tmodel_step_12500.pt  model_step_58500.pt\n",
            "model_epoch_115.pt  model_epoch_207.pt\tmodel_step_13000.pt  model_step_59000.pt\n",
            "model_epoch_116.pt  model_epoch_208.pt\tmodel_step_13500.pt  model_step_59500.pt\n",
            "model_epoch_117.pt  model_epoch_209.pt\tmodel_step_14000.pt  model_step_60000.pt\n",
            "model_epoch_118.pt  model_epoch_20.pt\tmodel_step_14500.pt  model_step_6000.pt\n",
            "model_epoch_119.pt  model_epoch_210.pt\tmodel_step_15000.pt  model_step_60500.pt\n",
            "model_epoch_11.pt   model_epoch_211.pt\tmodel_step_1500.pt   model_step_61000.pt\n",
            "model_epoch_120.pt  model_epoch_212.pt\tmodel_step_15500.pt  model_step_61500.pt\n",
            "model_epoch_121.pt  model_epoch_213.pt\tmodel_step_16000.pt  model_step_62000.pt\n",
            "model_epoch_122.pt  model_epoch_21.pt\tmodel_step_16500.pt  model_step_62500.pt\n",
            "model_epoch_123.pt  model_epoch_22.pt\tmodel_step_17000.pt  model_step_63000.pt\n",
            "model_epoch_124.pt  model_epoch_23.pt\tmodel_step_17500.pt  model_step_63500.pt\n",
            "model_epoch_125.pt  model_epoch_24.pt\tmodel_step_18000.pt  model_step_64000.pt\n",
            "model_epoch_126.pt  model_epoch_25.pt\tmodel_step_18500.pt  model_step_64500.pt\n",
            "model_epoch_127.pt  model_epoch_26.pt\tmodel_step_19000.pt  model_step_65000.pt\n",
            "model_epoch_128.pt  model_epoch_27.pt\tmodel_step_19500.pt  model_step_6500.pt\n",
            "model_epoch_129.pt  model_epoch_28.pt\tmodel_step_20000.pt  model_step_65500.pt\n",
            "model_epoch_12.pt   model_epoch_29.pt\tmodel_step_2000.pt   model_step_66000.pt\n",
            "model_epoch_130.pt  model_epoch_2.pt\tmodel_step_20500.pt  model_step_66500.pt\n",
            "model_epoch_131.pt  model_epoch_30.pt\tmodel_step_21000.pt  model_step_67000.pt\n",
            "model_epoch_132.pt  model_epoch_31.pt\tmodel_step_21500.pt  model_step_67500.pt\n",
            "model_epoch_133.pt  model_epoch_32.pt\tmodel_step_22000.pt  model_step_68000.pt\n",
            "model_epoch_134.pt  model_epoch_33.pt\tmodel_step_22500.pt  model_step_68500.pt\n",
            "model_epoch_135.pt  model_epoch_34.pt\tmodel_step_23000.pt  model_step_69000.pt\n",
            "model_epoch_136.pt  model_epoch_35.pt\tmodel_step_23500.pt  model_step_69500.pt\n",
            "model_epoch_137.pt  model_epoch_36.pt\tmodel_step_24000.pt  model_step_70000.pt\n",
            "model_epoch_138.pt  model_epoch_37.pt\tmodel_step_24500.pt  model_step_7000.pt\n",
            "model_epoch_139.pt  model_epoch_38.pt\tmodel_step_25000.pt  model_step_70500.pt\n",
            "model_epoch_13.pt   model_epoch_39.pt\tmodel_step_2500.pt   model_step_71000.pt\n",
            "model_epoch_140.pt  model_epoch_3.pt\tmodel_step_25500.pt  model_step_71500.pt\n",
            "model_epoch_141.pt  model_epoch_40.pt\tmodel_step_26000.pt  model_step_72000.pt\n",
            "model_epoch_142.pt  model_epoch_41.pt\tmodel_step_26500.pt  model_step_72500.pt\n",
            "model_epoch_143.pt  model_epoch_42.pt\tmodel_step_27000.pt  model_step_73000.pt\n",
            "model_epoch_144.pt  model_epoch_43.pt\tmodel_step_27500.pt  model_step_73500.pt\n",
            "model_epoch_145.pt  model_epoch_44.pt\tmodel_step_28000.pt  model_step_74000.pt\n",
            "model_epoch_146.pt  model_epoch_45.pt\tmodel_step_28500.pt  model_step_74500.pt\n",
            "model_epoch_147.pt  model_epoch_46.pt\tmodel_step_29000.pt  model_step_75000.pt\n",
            "model_epoch_148.pt  model_epoch_47.pt\tmodel_step_29500.pt  model_step_7500.pt\n",
            "model_epoch_149.pt  model_epoch_48.pt\tmodel_step_30000.pt  model_step_75500.pt\n",
            "model_epoch_14.pt   model_epoch_49.pt\tmodel_step_3000.pt   model_step_76000.pt\n",
            "model_epoch_150.pt  model_epoch_4.pt\tmodel_step_30500.pt  model_step_76500.pt\n",
            "model_epoch_151.pt  model_epoch_50.pt\tmodel_step_31000.pt  model_step_77000.pt\n",
            "model_epoch_152.pt  model_epoch_51.pt\tmodel_step_31500.pt  model_step_77500.pt\n",
            "model_epoch_153.pt  model_epoch_52.pt\tmodel_step_32000.pt  model_step_78000.pt\n",
            "model_epoch_154.pt  model_epoch_53.pt\tmodel_step_32500.pt  model_step_78500.pt\n",
            "model_epoch_155.pt  model_epoch_54.pt\tmodel_step_33000.pt  model_step_79000.pt\n",
            "model_epoch_156.pt  model_epoch_55.pt\tmodel_step_33500.pt  model_step_79500.pt\n",
            "model_epoch_157.pt  model_epoch_56.pt\tmodel_step_34000.pt  model_step_80000.pt\n",
            "model_epoch_158.pt  model_epoch_57.pt\tmodel_step_34500.pt  model_step_8000.pt\n",
            "model_epoch_159.pt  model_epoch_58.pt\tmodel_step_35000.pt  model_step_80500.pt\n",
            "model_epoch_15.pt   model_epoch_59.pt\tmodel_step_3500.pt   model_step_81000.pt\n",
            "model_epoch_160.pt  model_epoch_5.pt\tmodel_step_35500.pt  model_step_81500.pt\n",
            "model_epoch_161.pt  model_epoch_60.pt\tmodel_step_36000.pt  model_step_82000.pt\n",
            "model_epoch_162.pt  model_epoch_61.pt\tmodel_step_36500.pt  model_step_82500.pt\n",
            "model_epoch_163.pt  model_epoch_62.pt\tmodel_step_37000.pt  model_step_83000.pt\n",
            "model_epoch_164.pt  model_epoch_63.pt\tmodel_step_37500.pt  model_step_83500.pt\n",
            "model_epoch_165.pt  model_epoch_64.pt\tmodel_step_38000.pt  model_step_84000.pt\n",
            "model_epoch_166.pt  model_epoch_65.pt\tmodel_step_38500.pt  model_step_84500.pt\n",
            "model_epoch_167.pt  model_epoch_66.pt\tmodel_step_39000.pt  model_step_85000.pt\n",
            "model_epoch_168.pt  model_epoch_67.pt\tmodel_step_39500.pt  model_step_8500.pt\n",
            "model_epoch_169.pt  model_epoch_68.pt\tmodel_step_40000.pt  model_step_85500.pt\n",
            "model_epoch_16.pt   model_epoch_69.pt\tmodel_step_4000.pt   model_step_86000.pt\n",
            "model_epoch_170.pt  model_epoch_6.pt\tmodel_step_40500.pt  model_step_86500.pt\n",
            "model_epoch_171.pt  model_epoch_70.pt\tmodel_step_41000.pt  model_step_87000.pt\n",
            "model_epoch_172.pt  model_epoch_71.pt\tmodel_step_41500.pt  model_step_87500.pt\n",
            "model_epoch_173.pt  model_epoch_72.pt\tmodel_step_42000.pt  model_step_88000.pt\n",
            "model_epoch_174.pt  model_epoch_73.pt\tmodel_step_42500.pt  model_step_88500.pt\n",
            "model_epoch_175.pt  model_epoch_74.pt\tmodel_step_43000.pt  model_step_89000.pt\n",
            "model_epoch_176.pt  model_epoch_75.pt\tmodel_step_43500.pt  model_step_89500.pt\n",
            "model_epoch_177.pt  model_epoch_76.pt\tmodel_step_44000.pt  model_step_90000.pt\n",
            "model_epoch_178.pt  model_epoch_77.pt\tmodel_step_44500.pt  model_step_9000.pt\n",
            "model_epoch_179.pt  model_epoch_78.pt\tmodel_step_45000.pt  model_step_90500.pt\n",
            "model_epoch_17.pt   model_epoch_79.pt\tmodel_step_4500.pt   model_step_91000.pt\n",
            "model_epoch_180.pt  model_epoch_7.pt\tmodel_step_45500.pt  model_step_91500.pt\n",
            "model_epoch_181.pt  model_epoch_80.pt\tmodel_step_46000.pt  model_step_92000.pt\n",
            "model_epoch_182.pt  model_epoch_81.pt\tmodel_step_46500.pt  model_step_92500.pt\n",
            "model_epoch_183.pt  model_epoch_82.pt\tmodel_step_47000.pt  model_step_93000.pt\n",
            "model_epoch_184.pt  model_epoch_83.pt\tmodel_step_47500.pt  model_step_93500.pt\n",
            "model_epoch_185.pt  model_epoch_84.pt\tmodel_step_48000.pt  model_step_94000.pt\n",
            "model_epoch_186.pt  model_epoch_85.pt\tmodel_step_48500.pt  model_step_94500.pt\n",
            "model_epoch_187.pt  model_epoch_86.pt\tmodel_step_49000.pt  model_step_95000.pt\n",
            "model_epoch_188.pt  model_epoch_87.pt\tmodel_step_49500.pt  model_step_9500.pt\n",
            "model_epoch_189.pt  model_epoch_88.pt\tmodel_step_50000.pt  model_step_95500.pt\n",
            "model_epoch_18.pt   model_epoch_89.pt\tmodel_step_5000.pt   model_step_96000.pt\n",
            "model_epoch_190.pt  model_epoch_8.pt\tmodel_step_500.pt\n",
            "model_epoch_191.pt  model_epoch_90.pt\tmodel_step_50500.pt\n",
            "model_epoch_192.pt  model_epoch_91.pt\tmodel_step_51000.pt\n",
            "\n",
            "./config:\n",
            "config.yaml\n",
            "\n",
            "./data:\n",
            "download_dataset.py  preprocess.py  raw  tokenized\n",
            "\n",
            "./data/raw:\n",
            "test.arrow  train.arrow  validation.arrow\n",
            "\n",
            "./data/raw/test.arrow:\n",
            "data-00000-of-00001.arrow  dataset_info.json  state.json\n",
            "\n",
            "./data/raw/train.arrow:\n",
            "data-00000-of-00001.arrow  data-00001-of-00003.arrow  dataset_info.json\n",
            "data-00000-of-00003.arrow  data-00002-of-00003.arrow  state.json\n",
            "\n",
            "./data/raw/validation.arrow:\n",
            "data-00000-of-00001.arrow  dataset_info.json  state.json\n",
            "\n",
            "./data/tokenized:\n",
            "combined.txt  test.en.bpe  train.de.bpe  train.fr.bpe  valid.en.bpe  vocab.model\n",
            "test.de.bpe   test.fr.bpe  train.en.bpe  valid.de.bpe  valid.fr.bpe  vocab.vocab\n",
            "\n",
            "./notebooks:\n",
            "demo.ipynb  Demo_Notebook_Flash_Transformer.ipynb\n",
            "\n",
            "./scripts:\n",
            "evaluate.sh  preprocess.sh  train.sh\n",
            "\n",
            "./src:\n",
            "evaluation  model  training  visualization\n",
            "\n",
            "./src/evaluation:\n",
            "evaluate.py  inference.py  metrics.py  __pycache__\n",
            "\n",
            "./src/evaluation/__pycache__:\n",
            "evaluate.cpython-310.pyc  inference.cpython-310.pyc  metrics.cpython-311.pyc\n",
            "evaluate.cpython-311.pyc  inference.cpython-311.pyc\n",
            "\n",
            "./src/model:\n",
            "decoder.py  embeddings.py  encoder.py  flash_attention.py  __pycache__\ttransformer.py\tutils.py\n",
            "\n",
            "./src/model/__pycache__:\n",
            "decoder.cpython-310.pyc     encoder.cpython-310.pyc\t     transformer.cpython-310.pyc\n",
            "decoder.cpython-311.pyc     encoder.cpython-311.pyc\t     transformer.cpython-311.pyc\n",
            "embeddings.cpython-310.pyc  flash_attention.cpython-310.pyc  utils.cpython-310.pyc\n",
            "embeddings.cpython-311.pyc  flash_attention.cpython-311.pyc  utils.cpython-311.pyc\n",
            "\n",
            "./src/training:\n",
            "optimizer.py  __pycache__  regularization.py  train.py\n",
            "\n",
            "./src/training/__pycache__:\n",
            "optimizer.cpython-310.pyc  regularization.cpython-310.pyc  train.cpython-310.pyc\n",
            "optimizer.cpython-311.pyc  regularization.cpython-311.pyc  train.cpython-311.pyc\n",
            "\n",
            "./src/visualization:\n",
            "embedding_visuals.py  plot_attention.py  training_curves.py\n",
            "\n",
            "./tests:\n",
            "test_evaluation.py  test_model.py  test_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c106369",
      "metadata": {
        "id": "8c106369"
      },
      "source": [
        "## 1. Install Dependencies\n",
        "We'll install everything from `requirements.txt`. In Colab, we can run `%pip install ...` directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eae9864",
      "metadata": {
        "id": "7eae9864"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5536e74",
      "metadata": {
        "id": "b5536e74"
      },
      "source": [
        "## 2. Data Download & Preprocessing\n",
        "This will:\n",
        "- Download a reduced WMT14 (EN–DE) dataset via Hugging Face.\n",
        "- Train a SentencePiece model.\n",
        "- Apply BPE tokenization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWNYKpihLNvj",
        "outputId": "e720f18b-38e9-44c8-b772-36917fe4a57a"
      },
      "id": "nWNYKpihLNvj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f4d397",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6f4d397",
        "outputId": "43d05453-10a8-489a-9990-88c758e09a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Downloading a 1% subset of WMT14 de-en...\n",
            "Saving the dataset (1/1 shards): 100% 45088/45088 [00:00<00:00, 627256.37 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 3000/3000 [00:00<00:00, 340170.64 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 3003/3003 [00:00<00:00, 320381.92 examples/s]\n",
            "Download and subset extraction complete!\n",
            "Preprocessing dataset...\n",
            "Building combined corpus from training data...\n",
            "Combined corpus lines written (each line is a single sentence): 90176\n",
            "Training BPE model...\n",
            "Training BPE with vocab size=8000...\n",
            "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=data/tokenized/combined.txt --model_prefix=data/tokenized/vocab --vocab_size=8000 --unk_id=0 --pad_id=1 --bos_id=2 --eos_id=3 --user_defined_symbols=[SEP]\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: data/tokenized/combined.txt\n",
            "  input_format: \n",
            "  model_prefix: data/tokenized/vocab\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [SEP]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: data/tokenized/combined.txt\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 90176 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=14405057\n",
            "trainer_interface.cc(550) LOG(INFO) Done: 99.9552% characters are covered.\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=77\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999552\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 90176 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=7599693\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 229199 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 90176\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 107526\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 107526 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=61665 obj=11.4289 num_tokens=212063 num_tokens/piece=3.43895\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=50050 obj=8.87463 num_tokens=213061 num_tokens/piece=4.25696\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=37508 obj=8.86592 num_tokens=227175 num_tokens/piece=6.05671\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=37485 obj=8.84889 num_tokens=227194 num_tokens/piece=6.06093\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=28106 obj=8.9548 num_tokens=251866 num_tokens/piece=8.96129\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=28100 obj=8.93458 num_tokens=251847 num_tokens/piece=8.96253\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=21075 obj=9.08986 num_tokens=280952 num_tokens/piece=13.3311\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=21075 obj=9.06322 num_tokens=280943 num_tokens/piece=13.3306\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=15806 obj=9.27054 num_tokens=312829 num_tokens/piece=19.7918\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=15806 obj=9.23613 num_tokens=312832 num_tokens/piece=19.792\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=11854 obj=9.50086 num_tokens=343980 num_tokens/piece=29.0181\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=11854 obj=9.45709 num_tokens=343989 num_tokens/piece=29.0188\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8890 obj=9.78788 num_tokens=375877 num_tokens/piece=42.2809\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8890 obj=9.73483 num_tokens=375883 num_tokens/piece=42.2816\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8800 obj=9.74569 num_tokens=377008 num_tokens/piece=42.8418\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8800 obj=9.74354 num_tokens=377013 num_tokens/piece=42.8424\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: data/tokenized/vocab.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: data/tokenized/vocab.vocab\n",
            "BPE training complete!\n",
            "Applying BPE to train set...\n",
            "Wrote 45088 lines to data/tokenized/train.en.bpe and data/tokenized/train.de.bpe\n",
            "Applying BPE to validation set...\n",
            "Wrote 3000 lines to data/tokenized/valid.en.bpe and data/tokenized/valid.de.bpe\n",
            "Applying BPE to test set...\n",
            "Wrote 3003 lines to data/tokenized/test.en.bpe and data/tokenized/test.de.bpe\n",
            "Preprocessing complete!\n"
          ]
        }
      ],
      "source": [
        "!bash scripts/preprocess.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e237212f",
      "metadata": {
        "id": "e237212f"
      },
      "source": [
        "## 3. Train the Model\n",
        "We'll run the `train.sh` script, which calls `src/training/train.py`.\n",
        "Check `config/config.yaml` to modify hyperparameters such as:\n",
        "- `max_epochs`\n",
        "- `batch_size`\n",
        "- `learning_rate`\n",
        "- etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CoYEzm2UYlk",
        "outputId": "6883873d-0680-4b4c-fcf4-aaf8c6b768b4"
      },
      "id": "4CoYEzm2UYlk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->flash-attn)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->flash-attn)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->flash-attn)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->flash-attn)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->flash-attn)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->flash-attn)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.3-cp311-cp311-linux_x86_64.whl size=191363917 sha256=b1243e9b86687348a5ab03a073abacdf8e3d5e9e4b7e5326a183f47348c5dfba\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/a3/f9/48d2706cb2eac05ec0dc144bf6954fe47bb3c2cd0de280765e\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flash-attn\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed flash-attn-2.7.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is enabled!\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU needed to run x_x.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8D3cC7JWWs1",
        "outputId": "7b3b9104-c27e-47db-f843-9e2f03eb3caa"
      },
      "id": "E8D3cC7JWWs1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is enabled!\n",
            "Using GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c39d5c",
      "metadata": {
        "id": "d4c39d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9930c03-639f-4849-d70f-eca88bc82535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 14:  55% 498/901 [00:58<00:44,  9.13it/s]Step 6100: loss = 2.4381\n",
            "Epoch 14:  55% 500/901 [00:58<00:40,  9.91it/s]Step 6100: loss = 2.4381\n",
            "Epoch 14:  66% 598/901 [01:10<00:35,  8.56it/s]Step 6150: loss = 2.4460\n",
            "Epoch 14:  67% 600/901 [01:10<00:34,  8.69it/s]Step 6150: loss = 2.4463\n",
            "Epoch 14:  77% 698/901 [01:21<00:22,  8.83it/s]Step 6200: loss = 2.4497\n",
            "Epoch 14:  78% 700/901 [01:21<00:22,  8.84it/s]Step 6200: loss = 2.4507\n",
            "Epoch 14:  89% 798/901 [01:32<00:12,  8.58it/s]Step 6250: loss = 2.4570\n",
            "Epoch 14:  89% 800/901 [01:32<00:10,  9.60it/s]Step 6250: loss = 2.4562\n",
            "Epoch 14: 100% 899/901 [01:44<00:00,  9.04it/s]Step 6300: loss = 2.4532\n",
            "Epoch 14: 100% 900/901 [01:44<00:00,  8.72it/s]Step 6300: loss = 2.4535\n",
            "Epoch 14: 100% 901/901 [01:44<00:00,  8.61it/s]\n",
            "Epoch 14 completed. Average training loss: 2.4535\n",
            "Validation loss after epoch 14: 2.6159\n",
            "Checkpoint saved -> checkpoints/model_epoch_14.pt\n",
            "Epoch 15:   0% 0/901 [00:00<?, ?it/s]Step 6300: loss = 3.5148\n",
            "Epoch 15:  11% 98/901 [00:11<01:47,  7.49it/s]Step 6350: loss = 2.4000\n",
            "Epoch 15:  11% 100/901 [00:11<01:37,  8.20it/s]Step 6350: loss = 2.3958\n",
            "Epoch 15:  22% 198/901 [00:23<01:18,  8.94it/s]Step 6400: loss = 2.4421\n",
            "Epoch 15:  22% 200/901 [00:23<01:14,  9.44it/s]Step 6400: loss = 2.4411\n",
            "Epoch 15:  33% 298/901 [00:34<00:57, 10.41it/s]Step 6450: loss = 2.4412\n",
            "Epoch 15:  33% 300/901 [00:34<00:59, 10.08it/s]Step 6450: loss = 2.4404\n",
            "Epoch 15:  44% 399/901 [00:46<00:55,  9.01it/s]Step 6500: loss = 2.4299\n",
            "Checkpoint saved -> checkpoints/model_step_6500.pt\n",
            "Epoch 15:  44% 400/901 [00:46<02:01,  4.14it/s]Step 6500: loss = 2.4289\n",
            "Checkpoint saved -> checkpoints/model_step_6500.pt\n",
            "Epoch 15:  55% 498/901 [00:58<00:47,  8.51it/s]Step 6550: loss = 2.4348\n",
            "Epoch 15:  55% 500/901 [00:58<00:43,  9.24it/s]Step 6550: loss = 2.4356\n",
            "Epoch 15:  66% 598/901 [01:10<00:35,  8.55it/s]Step 6600: loss = 2.4336\n",
            "Epoch 15:  67% 600/901 [01:10<00:34,  8.80it/s]Step 6600: loss = 2.4331\n",
            "Epoch 15:  78% 699/901 [01:22<00:27,  7.44it/s]Step 6650: loss = 2.4164\n",
            "Epoch 15:  78% 700/901 [01:22<00:25,  7.79it/s]Step 6650: loss = 2.4171\n",
            "Epoch 15:  89% 798/901 [01:34<00:11,  8.62it/s]Step 6700: loss = 2.4180\n",
            "Epoch 15:  89% 800/901 [01:34<00:10,  9.19it/s]Step 6700: loss = 2.4182\n",
            "Epoch 15: 100% 898/901 [01:45<00:00,  8.99it/s]Step 6750: loss = 2.4235\n",
            "Epoch 15: 100% 900/901 [01:45<00:00,  9.03it/s]Step 6750: loss = 2.4228\n",
            "Epoch 15: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 15 completed. Average training loss: 2.4228\n",
            "Validation loss after epoch 15: 2.6063\n",
            "Checkpoint saved -> checkpoints/model_epoch_15.pt\n",
            "Epoch 16:   0% 0/901 [00:00<?, ?it/s]Step 6750: loss = 2.5937\n",
            "Epoch 16:  11% 98/901 [00:10<01:26,  9.28it/s]Step 6800: loss = 2.4668\n",
            "Epoch 16:  11% 100/901 [00:10<01:26,  9.28it/s]Step 6800: loss = 2.4687\n",
            "Epoch 16:  22% 198/901 [00:22<01:30,  7.77it/s]Step 6850: loss = 2.4321\n",
            "Epoch 16:  22% 200/901 [00:22<01:21,  8.57it/s]Step 6850: loss = 2.4309\n",
            "Epoch 16:  33% 298/901 [00:35<01:09,  8.63it/s]Step 6900: loss = 2.3766\n",
            "Epoch 16:  33% 300/901 [00:35<01:10,  8.50it/s]Step 6900: loss = 2.3772\n",
            "Epoch 16:  44% 399/901 [00:46<00:55,  9.11it/s]Step 6950: loss = 2.3879\n",
            "Epoch 16:  44% 400/901 [00:46<01:01,  8.21it/s]Step 6950: loss = 2.3896\n",
            "Epoch 16:  55% 499/901 [00:58<00:47,  8.38it/s]Step 7000: loss = 2.3811\n",
            "Checkpoint saved -> checkpoints/model_step_7000.pt\n",
            "Epoch 16:  55% 500/901 [00:59<01:43,  3.86it/s]Step 7000: loss = 2.3809\n",
            "Checkpoint saved -> checkpoints/model_step_7000.pt\n",
            "Epoch 16:  66% 598/901 [01:10<00:33,  9.13it/s]Step 7050: loss = 2.3921\n",
            "Epoch 16:  67% 600/901 [01:11<00:32,  9.26it/s]Step 7050: loss = 2.3931\n",
            "Epoch 16:  77% 698/901 [01:22<00:22,  9.23it/s]Step 7100: loss = 2.4015\n",
            "Epoch 16:  78% 700/901 [01:22<00:21,  9.29it/s]Step 7100: loss = 2.4007\n",
            "Epoch 16:  89% 798/901 [01:33<00:12,  8.10it/s]Step 7150: loss = 2.4027\n",
            "Epoch 16:  89% 800/901 [01:33<00:11,  8.78it/s]Step 7150: loss = 2.4029\n",
            "Epoch 16: 100% 898/901 [01:44<00:00,  8.66it/s]Step 7200: loss = 2.4110\n",
            "Epoch 16: 100% 900/901 [01:44<00:00,  9.30it/s]Step 7200: loss = 2.4116\n",
            "Epoch 16: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 16 completed. Average training loss: 2.4116\n",
            "Validation loss after epoch 16: 2.5970\n",
            "Checkpoint saved -> checkpoints/model_epoch_16.pt\n",
            "Epoch 17:   0% 0/901 [00:00<?, ?it/s]Step 7200: loss = 1.7942\n",
            "Epoch 17:  11% 99/901 [00:11<01:41,  7.91it/s]Step 7250: loss = 2.4390\n",
            "Epoch 17:  11% 100/901 [00:11<01:43,  7.76it/s]Step 7250: loss = 2.4457\n",
            "Epoch 17:  22% 199/901 [00:22<01:21,  8.66it/s]Step 7300: loss = 2.4489\n",
            "Epoch 17:  22% 200/901 [00:22<01:21,  8.60it/s]Step 7300: loss = 2.4497\n",
            "Epoch 17:  33% 298/901 [00:33<01:03,  9.48it/s]Step 7350: loss = 2.4529\n",
            "Epoch 17:  33% 300/901 [00:33<01:02,  9.62it/s]Step 7350: loss = 2.4538\n",
            "Epoch 17:  44% 398/901 [00:44<01:02,  8.10it/s]Step 7400: loss = 2.4591\n",
            "Epoch 17:  44% 400/901 [00:44<01:07,  7.38it/s]Step 7400: loss = 2.4611\n",
            "Epoch 17:  55% 498/901 [00:56<00:42,  9.38it/s]Step 7450: loss = 2.4479\n",
            "Epoch 17:  55% 500/901 [00:56<00:45,  8.78it/s]Step 7450: loss = 2.4465\n",
            "Epoch 17:  66% 599/901 [01:08<00:32,  9.28it/s]Step 7500: loss = 2.4374\n",
            "Checkpoint saved -> checkpoints/model_step_7500.pt\n",
            "Epoch 17:  67% 600/901 [01:08<01:07,  4.49it/s]Step 7500: loss = 2.4367\n",
            "Checkpoint saved -> checkpoints/model_step_7500.pt\n",
            "Epoch 17:  77% 698/901 [01:20<00:23,  8.75it/s]Step 7550: loss = 2.4393\n",
            "Epoch 17:  78% 700/901 [01:20<00:21,  9.50it/s]Step 7550: loss = 2.4390\n",
            "Epoch 17:  89% 799/901 [01:32<00:11,  8.56it/s]Step 7600: loss = 2.4292\n",
            "Epoch 17:  89% 800/901 [01:32<00:12,  8.41it/s]Step 7600: loss = 2.4285\n",
            "Epoch 17: 100% 899/901 [01:44<00:00,  9.38it/s]Step 7650: loss = 2.4206\n",
            "Epoch 17: 100% 900/901 [01:44<00:00,  9.38it/s]Step 7650: loss = 2.4205\n",
            "Epoch 17: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 17 completed. Average training loss: 2.4205\n",
            "Validation loss after epoch 17: 2.5884\n",
            "Checkpoint saved -> checkpoints/model_epoch_17.pt\n",
            "Epoch 18:   0% 0/901 [00:00<?, ?it/s]Step 7650: loss = 1.8794\n",
            "Epoch 18:  11% 99/901 [00:11<01:28,  9.11it/s]Step 7700: loss = 2.3996\n",
            "Step 7700: loss = 2.4081\n",
            "Epoch 18:  22% 198/901 [00:23<01:26,  8.17it/s]Step 7750: loss = 2.4058\n",
            "Epoch 18:  22% 200/901 [00:23<01:27,  8.05it/s]Step 7750: loss = 2.4073\n",
            "Epoch 18:  33% 298/901 [00:34<01:04,  9.28it/s]Step 7800: loss = 2.4325\n",
            "Epoch 18:  33% 300/901 [00:34<01:01,  9.71it/s]Step 7800: loss = 2.4298\n",
            "Epoch 18:  44% 399/901 [00:46<01:02,  8.00it/s]Step 7850: loss = 2.4114\n",
            "Epoch 18:  44% 400/901 [00:46<01:14,  6.75it/s]Step 7850: loss = 2.4102\n",
            "Epoch 18:  55% 499/901 [00:57<00:42,  9.42it/s]Step 7900: loss = 2.4049\n",
            "Epoch 18:  55% 500/901 [00:57<00:42,  9.54it/s]Step 7900: loss = 2.4053\n",
            "Epoch 18:  66% 599/901 [01:09<00:33,  8.92it/s]Step 7950: loss = 2.3958\n",
            "Epoch 18:  67% 600/901 [01:09<00:34,  8.83it/s]Step 7950: loss = 2.3962\n",
            "Epoch 18:  77% 698/901 [01:20<00:21,  9.64it/s]Step 8000: loss = 2.3999\n",
            "Checkpoint saved -> checkpoints/model_step_8000.pt\n",
            "Epoch 18:  78% 700/901 [01:21<00:38,  5.24it/s]Step 8000: loss = 2.3995\n",
            "Checkpoint saved -> checkpoints/model_step_8000.pt\n",
            "Epoch 18:  89% 799/901 [01:33<00:12,  8.35it/s]Step 8050: loss = 2.3955\n",
            "Epoch 18:  89% 800/901 [01:33<00:13,  7.58it/s]Step 8050: loss = 2.3955\n",
            "Epoch 18: 100% 898/901 [01:45<00:00,  9.66it/s]Step 8100: loss = 2.3958\n",
            "Epoch 18: 100% 900/901 [01:45<00:00, 10.50it/s]Step 8100: loss = 2.3960\n",
            "Epoch 18: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 18 completed. Average training loss: 2.3960\n",
            "Validation loss after epoch 18: 2.5801\n",
            "Checkpoint saved -> checkpoints/model_epoch_18.pt\n",
            "Epoch 19:   0% 0/901 [00:00<?, ?it/s]Step 8100: loss = 2.1826\n",
            "Epoch 19:  11% 99/901 [00:12<01:26,  9.31it/s]Step 8150: loss = 2.3622\n",
            "Epoch 19:  11% 100/901 [00:12<01:35,  8.36it/s]Step 8150: loss = 2.3659\n",
            "Epoch 19:  22% 198/901 [00:23<01:39,  7.07it/s]Step 8200: loss = 2.3553\n",
            "Epoch 19:  22% 200/901 [00:24<01:30,  7.74it/s]Step 8200: loss = 2.3571\n",
            "Epoch 19:  33% 298/901 [00:35<01:12,  8.28it/s]Step 8250: loss = 2.3800\n",
            "Epoch 19:  33% 300/901 [00:35<01:08,  8.83it/s]Step 8250: loss = 2.3795\n",
            "Epoch 19:  44% 398/901 [00:46<01:01,  8.21it/s]Step 8300: loss = 2.3753\n",
            "Epoch 19:  44% 400/901 [00:47<00:57,  8.72it/s]Step 8300: loss = 2.3755\n",
            "Epoch 19:  55% 498/901 [00:58<00:42,  9.46it/s]Step 8350: loss = 2.3782\n",
            "Epoch 19:  55% 500/901 [00:58<00:41,  9.68it/s]Step 8350: loss = 2.3793\n",
            "Epoch 19:  66% 598/901 [01:09<00:46,  6.50it/s]Step 8400: loss = 2.3766\n",
            "Epoch 19:  67% 600/901 [01:10<00:42,  7.04it/s]Step 8400: loss = 2.3767\n",
            "Epoch 19:  78% 699/901 [01:21<00:24,  8.17it/s]Step 8450: loss = 2.3740\n",
            "Epoch 19:  78% 700/901 [01:21<00:23,  8.48it/s]Step 8450: loss = 2.3737\n",
            "Epoch 19:  89% 798/901 [01:33<00:10, 10.21it/s]Step 8500: loss = 2.3695\n",
            "Checkpoint saved -> checkpoints/model_step_8500.pt\n",
            "Epoch 19:  89% 800/901 [01:33<00:18,  5.58it/s]Step 8500: loss = 2.3698\n",
            "Checkpoint saved -> checkpoints/model_step_8500.pt\n",
            "Epoch 19: 100% 898/901 [01:45<00:00,  9.25it/s]Step 8550: loss = 2.3791\n",
            "Epoch 19: 100% 900/901 [01:45<00:00,  9.86it/s]Step 8550: loss = 2.3796\n",
            "Epoch 19: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 19 completed. Average training loss: 2.3796\n",
            "Validation loss after epoch 19: 2.5722\n",
            "Checkpoint saved -> checkpoints/model_epoch_19.pt\n",
            "Epoch 20:   0% 0/901 [00:00<?, ?it/s]Step 8550: loss = 2.5459\n",
            "Epoch 20:  11% 99/901 [00:11<01:53,  7.06it/s]Step 8600: loss = 2.4154\n",
            "Epoch 20:  11% 100/901 [00:11<01:58,  6.75it/s]Step 8600: loss = 2.4157\n",
            "Epoch 20:  22% 198/901 [00:23<01:17,  9.07it/s]Step 8650: loss = 2.3614\n",
            "Epoch 20:  22% 200/901 [00:23<01:16,  9.18it/s]Step 8650: loss = 2.3579\n",
            "Epoch 20:  33% 298/901 [00:34<00:59, 10.13it/s]Step 8700: loss = 2.3885\n",
            "Epoch 20:  33% 300/901 [00:34<01:01,  9.71it/s]Step 8700: loss = 2.3891\n",
            "Epoch 20:  44% 398/901 [00:45<01:06,  7.51it/s]Step 8750: loss = 2.3937\n",
            "Epoch 20:  44% 400/901 [00:45<00:58,  8.63it/s]Step 8750: loss = 2.3919\n",
            "Epoch 20:  55% 499/901 [00:57<00:46,  8.62it/s]Step 8800: loss = 2.3758\n",
            "Epoch 20:  55% 500/901 [00:57<00:46,  8.57it/s]Step 8800: loss = 2.3755\n",
            "Epoch 20:  66% 598/901 [01:09<00:29, 10.22it/s]Step 8850: loss = 2.3749\n",
            "Epoch 20:  67% 600/901 [01:09<00:30,  9.78it/s]Step 8850: loss = 2.3732\n",
            "Epoch 20:  77% 698/901 [01:21<00:24,  8.35it/s]Step 8900: loss = 2.3720\n",
            "Epoch 20:  78% 700/901 [01:21<00:21,  9.22it/s]Step 8900: loss = 2.3729\n",
            "Epoch 20:  89% 799/901 [01:32<00:10,  9.30it/s]Step 8950: loss = 2.3738\n",
            "Step 8950: loss = 2.3740\n",
            "Epoch 20: 100% 898/901 [01:44<00:00,  8.74it/s]Step 9000: loss = 2.3693\n",
            "Checkpoint saved -> checkpoints/model_step_9000.pt\n",
            "Epoch 20: 100% 900/901 [01:44<00:00,  4.78it/s]Step 9000: loss = 2.3695\n",
            "Checkpoint saved -> checkpoints/model_step_9000.pt\n",
            "Epoch 20: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 20 completed. Average training loss: 2.3695\n",
            "Validation loss after epoch 20: 2.5647\n",
            "Checkpoint saved -> checkpoints/model_epoch_20.pt\n",
            "Epoch 21:   0% 0/901 [00:00<?, ?it/s]Step 9000: loss = 1.9178\n",
            "Checkpoint saved -> checkpoints/model_step_9000.pt\n",
            "Epoch 21:  11% 98/901 [00:12<01:39,  8.08it/s]Step 9050: loss = 2.3474\n",
            "Epoch 21:  11% 100/901 [00:12<01:34,  8.46it/s]Step 9050: loss = 2.3521\n",
            "Epoch 21:  22% 199/901 [00:23<01:22,  8.51it/s]Step 9100: loss = 2.3686\n",
            "Epoch 21:  22% 200/901 [00:24<01:30,  7.75it/s]Step 9100: loss = 2.3616\n",
            "Epoch 21:  33% 299/901 [00:35<01:13,  8.22it/s]Step 9150: loss = 2.3517\n",
            "Epoch 21:  33% 300/901 [00:35<01:14,  8.03it/s]Step 9150: loss = 2.3543\n",
            "Epoch 21:  44% 399/901 [00:47<00:59,  8.39it/s]Step 9200: loss = 2.3456\n",
            "Epoch 21:  44% 400/901 [00:47<00:59,  8.49it/s]Step 9200: loss = 2.3447\n",
            "Epoch 21:  55% 498/901 [00:58<00:51,  7.75it/s]Step 9250: loss = 2.3722\n",
            "Epoch 21:  55% 500/901 [00:58<00:46,  8.57it/s]Step 9250: loss = 2.3726\n",
            "Epoch 21:  66% 598/901 [01:09<00:29, 10.17it/s]Step 9300: loss = 2.3783\n",
            "Epoch 21:  67% 600/901 [01:09<00:31,  9.46it/s]Step 9300: loss = 2.3797\n",
            "Epoch 21:  77% 698/901 [01:21<00:22,  9.13it/s]Step 9350: loss = 2.3722\n",
            "Epoch 21:  78% 700/901 [01:21<00:20,  9.89it/s]Step 9350: loss = 2.3718\n",
            "Epoch 21:  89% 799/901 [01:32<00:11,  8.57it/s]Step 9400: loss = 2.3735\n",
            "Epoch 21:  89% 800/901 [01:32<00:11,  8.82it/s]Step 9400: loss = 2.3731\n",
            "Epoch 21: 100% 899/901 [01:44<00:00,  9.20it/s]Step 9450: loss = 2.3728\n",
            "Epoch 21: 100% 900/901 [01:44<00:00,  9.19it/s]Step 9450: loss = 2.3733\n",
            "Epoch 21: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 21 completed. Average training loss: 2.3733\n",
            "Validation loss after epoch 21: 2.5576\n",
            "Checkpoint saved -> checkpoints/model_epoch_21.pt\n",
            "Epoch 22:   0% 0/901 [00:00<?, ?it/s]Step 9450: loss = 2.2947\n",
            "Epoch 22:  11% 99/901 [00:11<01:29,  8.98it/s]Step 9500: loss = 2.4032\n",
            "Checkpoint saved -> checkpoints/model_step_9500.pt\n",
            "Epoch 22:  11% 100/901 [00:11<02:55,  4.57it/s]Step 9500: loss = 2.4080\n",
            "Checkpoint saved -> checkpoints/model_step_9500.pt\n",
            "Epoch 22:  22% 198/901 [00:23<01:25,  8.21it/s]Step 9550: loss = 2.3913\n",
            "Epoch 22:  22% 200/901 [00:23<01:16,  9.11it/s]Step 9550: loss = 2.3915\n",
            "Epoch 22:  33% 298/901 [00:35<01:10,  8.51it/s]Step 9600: loss = 2.3620\n",
            "Epoch 22:  33% 300/901 [00:35<01:07,  8.91it/s]Step 9600: loss = 2.3645\n",
            "Epoch 22:  44% 398/901 [00:46<00:52,  9.56it/s]Step 9650: loss = 2.3824\n",
            "Epoch 22:  44% 400/901 [00:47<00:50,  9.95it/s]Step 9650: loss = 2.3826\n",
            "Epoch 22:  55% 498/901 [00:57<00:44,  8.99it/s]Step 9700: loss = 2.3857\n",
            "Epoch 22:  55% 500/901 [00:58<00:46,  8.53it/s]Step 9700: loss = 2.3849\n",
            "Epoch 22:  66% 598/901 [01:09<00:33,  9.00it/s]Step 9750: loss = 2.3833\n",
            "Epoch 22:  67% 600/901 [01:09<00:32,  9.36it/s]Step 9750: loss = 2.3821\n",
            "Epoch 22:  77% 698/901 [01:21<00:23,  8.79it/s]Step 9800: loss = 2.3864\n",
            "Epoch 22:  78% 700/901 [01:21<00:22,  8.88it/s]Step 9800: loss = 2.3862\n",
            "Epoch 22:  89% 799/901 [01:32<00:13,  7.64it/s]Step 9850: loss = 2.3783\n",
            "Epoch 22:  89% 800/901 [01:33<00:14,  7.10it/s]Step 9850: loss = 2.3770\n",
            "Epoch 22: 100% 899/901 [01:44<00:00,  7.55it/s]Step 9900: loss = 2.3767\n",
            "Epoch 22: 100% 900/901 [01:44<00:00,  7.60it/s]Step 9900: loss = 2.3771\n",
            "Epoch 22: 100% 901/901 [01:44<00:00,  8.58it/s]\n",
            "Epoch 22 completed. Average training loss: 2.3771\n",
            "Validation loss after epoch 22: 2.5508\n",
            "Checkpoint saved -> checkpoints/model_epoch_22.pt\n",
            "Epoch 23:   0% 0/901 [00:00<?, ?it/s]Step 9900: loss = 2.3857\n",
            "Epoch 23:  11% 98/901 [00:10<01:28,  9.04it/s]Step 9950: loss = 2.4299\n",
            "Epoch 23:  11% 100/901 [00:11<01:29,  8.94it/s]Step 9950: loss = 2.4287\n",
            "Epoch 23:  22% 198/901 [00:22<01:32,  7.61it/s]Step 10000: loss = 2.3875\n",
            "Checkpoint saved -> checkpoints/model_step_10000.pt\n",
            "Epoch 23:  22% 200/901 [00:23<02:35,  4.49it/s]Step 10000: loss = 2.3817\n",
            "Checkpoint saved -> checkpoints/model_step_10000.pt\n",
            "Epoch 23:  33% 299/901 [00:36<01:04,  9.32it/s]Step 10050: loss = 2.3565\n",
            "Step 10050: loss = 2.3563\n",
            "Epoch 23:  44% 399/901 [00:47<00:53,  9.31it/s]Step 10100: loss = 2.3548\n",
            "Epoch 23:  44% 400/901 [00:47<00:58,  8.50it/s]Step 10100: loss = 2.3525\n",
            "Epoch 23:  55% 499/901 [00:59<00:51,  7.87it/s]Step 10150: loss = 2.3495\n",
            "Step 10150: loss = 2.3489\n",
            "Epoch 23:  66% 599/901 [01:10<00:33,  9.10it/s]Step 10200: loss = 2.3609\n",
            "Epoch 23:  67% 600/901 [01:10<00:39,  7.54it/s]Step 10200: loss = 2.3599\n",
            "Epoch 23:  78% 699/901 [01:21<00:24,  8.10it/s]Step 10250: loss = 2.3585\n",
            "Epoch 23:  78% 700/901 [01:22<00:25,  7.87it/s]Step 10250: loss = 2.3581\n",
            "Epoch 23:  89% 798/901 [01:33<00:13,  7.73it/s]Step 10300: loss = 2.3545\n",
            "Epoch 23:  89% 800/901 [01:33<00:11,  8.83it/s]Step 10300: loss = 2.3546\n",
            "Epoch 23: 100% 898/901 [01:44<00:00,  8.37it/s]Step 10350: loss = 2.3508\n",
            "Epoch 23: 100% 900/901 [01:45<00:00,  8.17it/s]Step 10350: loss = 2.3509\n",
            "Epoch 23: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 23 completed. Average training loss: 2.3509\n",
            "Validation loss after epoch 23: 2.5444\n",
            "Checkpoint saved -> checkpoints/model_epoch_23.pt\n",
            "Epoch 24:   0% 0/901 [00:00<?, ?it/s]Step 10350: loss = 1.5027\n",
            "Epoch 24:  11% 98/901 [00:11<01:24,  9.53it/s]Step 10400: loss = 2.3512\n",
            "Epoch 24:  11% 100/901 [00:11<01:25,  9.36it/s]Step 10400: loss = 2.3509\n",
            "Epoch 24:  22% 199/901 [00:22<01:25,  8.18it/s]Step 10450: loss = 2.3431\n",
            "Epoch 24:  22% 200/901 [00:23<01:28,  7.93it/s]Step 10450: loss = 2.3426\n",
            "Epoch 24:  33% 298/901 [00:34<01:10,  8.55it/s]Step 10500: loss = 2.3498\n",
            "Checkpoint saved -> checkpoints/model_step_10500.pt\n",
            "Epoch 24:  33% 300/901 [00:35<02:04,  4.84it/s]Step 10500: loss = 2.3521\n",
            "Checkpoint saved -> checkpoints/model_step_10500.pt\n",
            "Epoch 24:  44% 398/901 [00:47<00:55,  9.10it/s]Step 10550: loss = 2.3551\n",
            "Epoch 24:  44% 400/901 [00:47<00:54,  9.11it/s]Step 10550: loss = 2.3546\n",
            "Epoch 24:  55% 498/901 [00:59<00:44,  9.08it/s]Step 10600: loss = 2.3404\n",
            "Epoch 24:  55% 500/901 [00:59<00:42,  9.37it/s]Step 10600: loss = 2.3407\n",
            "Epoch 24:  66% 599/901 [01:10<00:35,  8.41it/s]Step 10650: loss = 2.3553\n",
            "Epoch 24:  67% 600/901 [01:10<00:37,  7.93it/s]Step 10650: loss = 2.3549\n",
            "Epoch 24:  77% 698/901 [01:22<00:21,  9.24it/s]Step 10700: loss = 2.3508\n",
            "Epoch 24:  78% 700/901 [01:22<00:24,  8.15it/s]Step 10700: loss = 2.3505\n",
            "Epoch 24:  89% 799/901 [01:33<00:11,  8.91it/s]Step 10750: loss = 2.3516\n",
            "Step 10750: loss = 2.3504\n",
            "Epoch 24: 100% 899/901 [01:44<00:00,  8.57it/s]Step 10800: loss = 2.3572\n",
            "Step 10800: loss = 2.3570\n",
            "Epoch 24: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 24 completed. Average training loss: 2.3570\n",
            "Validation loss after epoch 24: 2.5382\n",
            "Checkpoint saved -> checkpoints/model_epoch_24.pt\n",
            "Epoch 25:   0% 0/901 [00:00<?, ?it/s]Step 10800: loss = 2.7802\n",
            "Epoch 25:  11% 98/901 [00:11<01:27,  9.16it/s]Step 10850: loss = 2.3379\n",
            "Epoch 25:  11% 100/901 [00:11<01:28,  9.00it/s]Step 10850: loss = 2.3358\n",
            "Epoch 25:  22% 198/901 [00:23<01:16,  9.24it/s]Step 10900: loss = 2.3329\n",
            "Epoch 25:  22% 200/901 [00:23<01:10, 10.01it/s]Step 10900: loss = 2.3317\n",
            "Epoch 25:  33% 298/901 [00:34<01:06,  9.13it/s]Step 10950: loss = 2.3528\n",
            "Epoch 25:  33% 300/901 [00:34<01:05,  9.20it/s]Step 10950: loss = 2.3513\n",
            "Epoch 25:  44% 399/901 [00:45<00:50,  9.87it/s]Step 11000: loss = 2.3588\n",
            "Checkpoint saved -> checkpoints/model_step_11000.pt\n",
            "Epoch 25:  44% 400/901 [00:46<01:51,  4.51it/s]Step 11000: loss = 2.3581\n",
            "Checkpoint saved -> checkpoints/model_step_11000.pt\n",
            "Epoch 25:  55% 498/901 [00:58<00:46,  8.62it/s]Step 11050: loss = 2.3533\n",
            "Epoch 25:  55% 500/901 [00:58<00:44,  9.04it/s]Step 11050: loss = 2.3534\n",
            "Epoch 25:  66% 599/901 [01:10<00:32,  9.38it/s]Step 11100: loss = 2.3495\n",
            "Epoch 25:  67% 600/901 [01:10<00:33,  9.05it/s]Step 11100: loss = 2.3497\n",
            "Epoch 25:  77% 698/901 [01:21<00:22,  9.21it/s]Step 11150: loss = 2.3546\n",
            "Epoch 25:  78% 700/901 [01:21<00:20,  9.79it/s]Step 11150: loss = 2.3537\n",
            "Epoch 25:  89% 799/901 [01:33<00:15,  6.74it/s]Step 11200: loss = 2.3543\n",
            "Epoch 25:  89% 800/901 [01:33<00:13,  7.24it/s]Step 11200: loss = 2.3552\n",
            "Epoch 25: 100% 898/901 [01:45<00:00,  8.53it/s]Step 11250: loss = 2.3478\n",
            "Epoch 25: 100% 900/901 [01:45<00:00,  9.27it/s]Step 11250: loss = 2.3473\n",
            "Epoch 25: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 25 completed. Average training loss: 2.3473\n",
            "Validation loss after epoch 25: 2.5324\n",
            "Checkpoint saved -> checkpoints/model_epoch_25.pt\n",
            "Epoch 26:   0% 0/901 [00:00<?, ?it/s]Step 11250: loss = 2.6457\n",
            "Epoch 26:  11% 99/901 [00:11<01:32,  8.66it/s]Step 11300: loss = 2.3468\n",
            "Epoch 26:  11% 100/901 [00:11<01:37,  8.24it/s]Step 11300: loss = 2.3486\n",
            "Epoch 26:  22% 199/901 [00:22<01:33,  7.53it/s]Step 11350: loss = 2.3522\n",
            "Epoch 26:  22% 200/901 [00:23<01:28,  7.91it/s]Step 11350: loss = 2.3504\n",
            "Epoch 26:  33% 298/901 [00:33<01:09,  8.64it/s]Step 11400: loss = 2.3641\n",
            "Epoch 26:  33% 300/901 [00:34<01:07,  8.95it/s]Step 11400: loss = 2.3641\n",
            "Epoch 26:  44% 399/901 [00:45<00:57,  8.71it/s]Step 11450: loss = 2.3628\n",
            "Epoch 26:  44% 400/901 [00:45<00:55,  8.97it/s]Step 11450: loss = 2.3623\n",
            "Epoch 26:  55% 498/901 [00:56<00:49,  8.06it/s]Step 11500: loss = 2.3644\n",
            "Checkpoint saved -> checkpoints/model_step_11500.pt\n",
            "Epoch 26:  55% 500/901 [00:57<01:25,  4.67it/s]Step 11500: loss = 2.3644\n",
            "Checkpoint saved -> checkpoints/model_step_11500.pt\n",
            "Epoch 26:  66% 598/901 [01:09<00:32,  9.31it/s]Step 11550: loss = 2.3658\n",
            "Epoch 26:  67% 600/901 [01:09<00:31,  9.61it/s]Step 11550: loss = 2.3657\n",
            "Epoch 26:  77% 698/901 [01:20<00:24,  8.25it/s]Step 11600: loss = 2.3656\n",
            "Epoch 26:  78% 700/901 [01:20<00:22,  9.06it/s]Step 11600: loss = 2.3653\n",
            "Epoch 26:  89% 799/901 [01:33<00:12,  8.50it/s]Step 11650: loss = 2.3539\n",
            "Epoch 26:  89% 800/901 [01:33<00:11,  8.74it/s]Step 11650: loss = 2.3544\n",
            "Epoch 26: 100% 898/901 [01:44<00:00,  7.01it/s]Step 11700: loss = 2.3479\n",
            "Epoch 26: 100% 900/901 [01:45<00:00,  7.64it/s]Step 11700: loss = 2.3482\n",
            "Epoch 26: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 26 completed. Average training loss: 2.3482\n",
            "Validation loss after epoch 26: 2.5268\n",
            "Checkpoint saved -> checkpoints/model_epoch_26.pt\n",
            "Epoch 27:   0% 0/901 [00:00<?, ?it/s]Step 11700: loss = 2.2960\n",
            "Epoch 27:  11% 99/901 [00:10<01:29,  9.01it/s]Step 11750: loss = 2.3997\n",
            "Epoch 27:  11% 100/901 [00:11<01:28,  9.09it/s]Step 11750: loss = 2.3965\n",
            "Epoch 27:  22% 199/901 [00:22<01:26,  8.14it/s]Step 11800: loss = 2.3863\n",
            "Epoch 27:  22% 200/901 [00:22<01:30,  7.74it/s]Step 11800: loss = 2.3901\n",
            "Epoch 27:  33% 299/901 [00:33<01:07,  8.93it/s]Step 11850: loss = 2.3622\n",
            "Epoch 27:  33% 300/901 [00:33<01:07,  8.95it/s]Step 11850: loss = 2.3604\n",
            "Epoch 27:  44% 399/901 [00:45<01:03,  7.85it/s]Step 11900: loss = 2.3446\n",
            "Epoch 27:  44% 400/901 [00:45<01:06,  7.53it/s]Step 11900: loss = 2.3438\n",
            "Epoch 27:  55% 499/901 [00:57<00:42,  9.49it/s]Step 11950: loss = 2.3443\n",
            "Epoch 27:  55% 500/901 [00:57<00:46,  8.65it/s]Step 11950: loss = 2.3445\n",
            "Epoch 27:  66% 598/901 [01:08<00:35,  8.55it/s]Step 12000: loss = 2.3470\n",
            "Checkpoint saved -> checkpoints/model_step_12000.pt\n",
            "Epoch 27:  67% 600/901 [01:09<00:59,  5.08it/s]Step 12000: loss = 2.3460\n",
            "Checkpoint saved -> checkpoints/model_step_12000.pt\n",
            "Epoch 27:  78% 699/901 [01:21<00:26,  7.52it/s]Step 12050: loss = 2.3426\n",
            "Epoch 27:  78% 700/901 [01:21<00:25,  7.77it/s]Step 12050: loss = 2.3435\n",
            "Epoch 27:  89% 798/901 [01:32<00:11,  8.71it/s]Step 12100: loss = 2.3495\n",
            "Epoch 27:  89% 800/901 [01:33<00:12,  8.17it/s]Step 12100: loss = 2.3490\n",
            "Epoch 27: 100% 899/901 [01:45<00:00,  7.30it/s]Step 12150: loss = 2.3416\n",
            "Epoch 27: 100% 900/901 [01:45<00:00,  7.72it/s]Step 12150: loss = 2.3414\n",
            "Epoch 27: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 27 completed. Average training loss: 2.3414\n",
            "Validation loss after epoch 27: 2.5215\n",
            "Checkpoint saved -> checkpoints/model_epoch_27.pt\n",
            "Epoch 28:   0% 0/901 [00:00<?, ?it/s]Step 12150: loss = 2.3438\n",
            "Epoch 28:  11% 98/901 [00:11<01:37,  8.20it/s]Step 12200: loss = 2.2871\n",
            "Epoch 28:  11% 100/901 [00:11<01:36,  8.26it/s]Step 12200: loss = 2.2878\n",
            "Epoch 28:  22% 199/901 [00:23<01:20,  8.68it/s]Step 12250: loss = 2.3181\n",
            "Epoch 28:  22% 200/901 [00:23<01:29,  7.79it/s]Step 12250: loss = 2.3200\n",
            "Epoch 28:  33% 298/901 [00:34<01:06,  9.08it/s]Step 12300: loss = 2.3357\n",
            "Epoch 28:  33% 300/901 [00:34<01:02,  9.58it/s]Step 12300: loss = 2.3375\n",
            "Epoch 28:  44% 398/901 [00:46<00:56,  8.93it/s]Step 12350: loss = 2.3433\n",
            "Epoch 28:  44% 400/901 [00:46<00:58,  8.51it/s]Step 12350: loss = 2.3432\n",
            "Epoch 28:  55% 498/901 [00:57<00:42,  9.50it/s]Step 12400: loss = 2.3343\n",
            "Epoch 28:  55% 500/901 [00:57<00:41,  9.61it/s]Step 12400: loss = 2.3339\n",
            "Epoch 28:  66% 598/901 [01:09<00:35,  8.55it/s]Step 12450: loss = 2.3360\n",
            "Epoch 28:  67% 600/901 [01:09<00:34,  8.62it/s]Step 12450: loss = 2.3364\n",
            "Epoch 28:  77% 698/901 [01:21<00:24,  8.31it/s]Step 12500: loss = 2.3222\n",
            "Checkpoint saved -> checkpoints/model_step_12500.pt\n",
            "Epoch 28:  78% 700/901 [01:21<00:44,  4.48it/s]Step 12500: loss = 2.3220\n",
            "Checkpoint saved -> checkpoints/model_step_12500.pt\n",
            "Epoch 28:  89% 798/901 [01:33<00:11,  9.32it/s]Step 12550: loss = 2.3292\n",
            "Epoch 28:  89% 800/901 [01:33<00:10,  9.56it/s]Step 12550: loss = 2.3291\n",
            "Epoch 28: 100% 898/901 [01:45<00:00,  7.93it/s]Step 12600: loss = 2.3248\n",
            "Epoch 28: 100% 900/901 [01:45<00:00,  7.49it/s]Step 12600: loss = 2.3250\n",
            "Epoch 28: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 28 completed. Average training loss: 2.3250\n",
            "Validation loss after epoch 28: 2.5165\n",
            "Checkpoint saved -> checkpoints/model_epoch_28.pt\n",
            "Epoch 29:   0% 0/901 [00:00<?, ?it/s]Step 12600: loss = 2.0078\n",
            "Epoch 29:  11% 98/901 [00:10<01:19, 10.06it/s]Step 12650: loss = 2.3955\n",
            "Epoch 29:  11% 100/901 [00:10<01:21,  9.79it/s]Step 12650: loss = 2.3973\n",
            "Epoch 29:  22% 199/901 [00:22<01:28,  7.93it/s]Step 12700: loss = 2.3267\n",
            "Epoch 29:  22% 200/901 [00:22<01:35,  7.31it/s]Step 12700: loss = 2.3259\n",
            "Epoch 29:  33% 299/901 [00:34<01:07,  8.94it/s]Step 12750: loss = 2.3541\n",
            "Epoch 29:  33% 300/901 [00:34<01:06,  9.04it/s]Step 12750: loss = 2.3535\n",
            "Epoch 29:  44% 398/901 [00:45<00:57,  8.73it/s]Step 12800: loss = 2.3325\n",
            "Epoch 29:  44% 400/901 [00:45<00:55,  9.08it/s]Step 12800: loss = 2.3326\n",
            "Epoch 29:  55% 498/901 [00:57<00:55,  7.29it/s]Step 12850: loss = 2.3188\n",
            "Epoch 29:  55% 500/901 [00:58<00:49,  8.16it/s]Step 12850: loss = 2.3187\n",
            "Epoch 29:  66% 598/901 [01:09<00:36,  8.20it/s]Step 12900: loss = 2.3215\n",
            "Epoch 29:  67% 600/901 [01:09<00:33,  9.04it/s]Step 12900: loss = 2.3207\n",
            "Epoch 29:  77% 698/901 [01:21<00:25,  7.82it/s]Step 12950: loss = 2.3113\n",
            "Epoch 29:  78% 700/901 [01:21<00:22,  8.97it/s]Step 12950: loss = 2.3115\n",
            "Epoch 29:  89% 798/901 [01:32<00:12,  8.56it/s]Step 13000: loss = 2.3141\n",
            "Checkpoint saved -> checkpoints/model_step_13000.pt\n",
            "Epoch 29:  89% 800/901 [01:33<00:22,  4.59it/s]Step 13000: loss = 2.3144\n",
            "Checkpoint saved -> checkpoints/model_step_13000.pt\n",
            "Epoch 29: 100% 898/901 [01:45<00:00,  9.61it/s]Step 13050: loss = 2.3209\n",
            "Epoch 29: 100% 900/901 [01:45<00:00,  9.97it/s]Step 13050: loss = 2.3203\n",
            "Epoch 29: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 29 completed. Average training loss: 2.3203\n",
            "Validation loss after epoch 29: 2.5115\n",
            "Checkpoint saved -> checkpoints/model_epoch_29.pt\n",
            "Epoch 30:   0% 0/901 [00:00<?, ?it/s]Step 13050: loss = 2.9027\n",
            "Epoch 30:  11% 98/901 [00:11<01:34,  8.50it/s]Step 13100: loss = 2.3491\n",
            "Epoch 30:  11% 100/901 [00:11<01:28,  9.09it/s]Step 13100: loss = 2.3491\n",
            "Epoch 30:  22% 198/901 [00:22<01:15,  9.36it/s]Step 13150: loss = 2.3971\n",
            "Epoch 30:  22% 200/901 [00:22<01:15,  9.24it/s]Step 13150: loss = 2.3928\n",
            "Epoch 30:  33% 299/901 [00:34<01:16,  7.91it/s]Step 13200: loss = 2.3493\n",
            "Epoch 30:  33% 300/901 [00:34<01:19,  7.56it/s]Step 13200: loss = 2.3511\n",
            "Epoch 30:  44% 399/901 [00:45<01:01,  8.22it/s]Step 13250: loss = 2.3419\n",
            "Epoch 30:  44% 400/901 [00:45<01:03,  7.85it/s]Step 13250: loss = 2.3435\n",
            "Epoch 30:  55% 499/901 [00:57<00:57,  6.99it/s]Step 13300: loss = 2.3434\n",
            "Epoch 30:  55% 500/901 [00:57<01:03,  6.35it/s]Step 13300: loss = 2.3417\n",
            "Epoch 30:  66% 598/901 [01:09<00:37,  8.17it/s]Step 13350: loss = 2.3290\n",
            "Epoch 30:  67% 600/901 [01:09<00:36,  8.31it/s]Step 13350: loss = 2.3295\n",
            "Epoch 30:  78% 699/901 [01:20<00:23,  8.61it/s]Step 13400: loss = 2.3345\n",
            "Epoch 30:  78% 700/901 [01:20<00:23,  8.51it/s]Step 13400: loss = 2.3342\n",
            "Epoch 30:  89% 798/901 [01:32<00:10,  9.48it/s]Step 13450: loss = 2.3289\n",
            "Epoch 30:  89% 800/901 [01:32<00:10,  9.45it/s]Step 13450: loss = 2.3289\n",
            "Epoch 30: 100% 899/901 [01:44<00:00,  8.31it/s]Step 13500: loss = 2.3301\n",
            "Checkpoint saved -> checkpoints/model_step_13500.pt\n",
            "Epoch 30: 100% 900/901 [01:44<00:00,  4.20it/s]Step 13500: loss = 2.3306\n",
            "Checkpoint saved -> checkpoints/model_step_13500.pt\n",
            "Epoch 30: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 30 completed. Average training loss: 2.3306\n",
            "Validation loss after epoch 30: 2.5070\n",
            "Checkpoint saved -> checkpoints/model_epoch_30.pt\n",
            "Epoch 31:   0% 0/901 [00:00<?, ?it/s]Step 13500: loss = 2.4227\n",
            "Checkpoint saved -> checkpoints/model_step_13500.pt\n",
            "Epoch 31:  11% 99/901 [00:11<01:31,  8.81it/s]Step 13550: loss = 2.3440\n",
            "Epoch 31:  11% 100/901 [00:11<01:38,  8.16it/s]Step 13550: loss = 2.3362\n",
            "Epoch 31:  22% 198/901 [00:23<01:29,  7.84it/s]Step 13600: loss = 2.3394\n",
            "Epoch 31:  22% 200/901 [00:23<01:21,  8.60it/s]Step 13600: loss = 2.3395\n",
            "Epoch 31:  33% 299/901 [00:35<01:08,  8.79it/s]Step 13650: loss = 2.3274\n",
            "Epoch 31:  33% 300/901 [00:35<01:12,  8.26it/s]Step 13650: loss = 2.3269\n",
            "Epoch 31:  44% 399/901 [00:46<00:57,  8.75it/s]Step 13700: loss = 2.3166\n",
            "Epoch 31:  44% 400/901 [00:47<01:02,  8.06it/s]Step 13700: loss = 2.3156\n",
            "Epoch 31:  55% 498/901 [00:58<00:51,  7.75it/s]Step 13750: loss = 2.3239\n",
            "Epoch 31:  55% 500/901 [00:58<00:48,  8.33it/s]Step 13750: loss = 2.3228\n",
            "Epoch 31:  66% 599/901 [01:09<00:34,  8.85it/s]Step 13800: loss = 2.3295\n",
            "Epoch 31:  67% 600/901 [01:09<00:34,  8.74it/s]Step 13800: loss = 2.3311\n",
            "Epoch 31:  78% 699/901 [01:21<00:24,  8.11it/s]Step 13850: loss = 2.3225\n",
            "Epoch 31:  78% 700/901 [01:21<00:24,  8.14it/s]Step 13850: loss = 2.3221\n",
            "Epoch 31:  89% 799/901 [01:32<00:11,  8.71it/s]Step 13900: loss = 2.3299\n",
            "Epoch 31:  89% 800/901 [01:32<00:11,  8.81it/s]Step 13900: loss = 2.3302\n",
            "Epoch 31: 100% 898/901 [01:44<00:00,  9.31it/s]Step 13950: loss = 2.3212\n",
            "Epoch 31: 100% 900/901 [01:44<00:00,  9.43it/s]Step 13950: loss = 2.3208\n",
            "Epoch 31: 100% 901/901 [01:44<00:00,  8.61it/s]\n",
            "Epoch 31 completed. Average training loss: 2.3208\n",
            "Validation loss after epoch 31: 2.5026\n",
            "Checkpoint saved -> checkpoints/model_epoch_31.pt\n",
            "Epoch 32:   0% 0/901 [00:00<?, ?it/s]Step 13950: loss = 2.0386\n",
            "Epoch 32:  11% 99/901 [00:11<01:29,  8.94it/s]Step 14000: loss = 2.3085\n",
            "Checkpoint saved -> checkpoints/model_step_14000.pt\n",
            "Epoch 32:  11% 100/901 [00:12<03:04,  4.34it/s]Step 14000: loss = 2.3083\n",
            "Checkpoint saved -> checkpoints/model_step_14000.pt\n",
            "Epoch 32:  22% 198/901 [00:24<01:20,  8.78it/s]Step 14050: loss = 2.3337\n",
            "Epoch 32:  22% 200/901 [00:24<01:19,  8.84it/s]Step 14050: loss = 2.3363\n",
            "Epoch 32:  33% 299/901 [00:35<01:20,  7.48it/s]Step 14100: loss = 2.3211\n",
            "Epoch 32:  33% 300/901 [00:35<01:24,  7.13it/s]Step 14100: loss = 2.3216\n",
            "Epoch 32:  44% 399/901 [00:47<00:55,  8.98it/s]Step 14150: loss = 2.3212\n",
            "Epoch 32:  44% 400/901 [00:47<00:56,  8.90it/s]Step 14150: loss = 2.3189\n",
            "Epoch 32:  55% 499/901 [00:58<00:55,  7.18it/s]Step 14200: loss = 2.3205\n",
            "Epoch 32:  55% 500/901 [00:58<00:54,  7.42it/s]Step 14200: loss = 2.3178\n",
            "Epoch 32:  66% 598/901 [01:10<00:40,  7.47it/s]Step 14250: loss = 2.3134\n",
            "Epoch 32:  67% 600/901 [01:10<00:35,  8.54it/s]Step 14250: loss = 2.3124\n",
            "Epoch 32:  77% 698/901 [01:22<00:21,  9.54it/s]Step 14300: loss = 2.2990\n",
            "Epoch 32:  78% 700/901 [01:22<00:22,  8.93it/s]Step 14300: loss = 2.2989\n",
            "Epoch 32:  89% 798/901 [01:33<00:12,  8.20it/s]Step 14350: loss = 2.3007\n",
            "Epoch 32:  89% 800/901 [01:34<00:11,  8.54it/s]Step 14350: loss = 2.3009\n",
            "Epoch 32: 100% 899/901 [01:45<00:00,  7.85it/s]Step 14400: loss = 2.3013\n",
            "Epoch 32: 100% 900/901 [01:45<00:00,  7.71it/s]Step 14400: loss = 2.3013\n",
            "Epoch 32: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 32 completed. Average training loss: 2.3013\n",
            "Validation loss after epoch 32: 2.4985\n",
            "Checkpoint saved -> checkpoints/model_epoch_32.pt\n",
            "Epoch 33:   0% 0/901 [00:00<?, ?it/s]Step 14400: loss = 2.4994\n",
            "Epoch 33:  11% 99/901 [00:11<01:38,  8.12it/s]Step 14450: loss = 2.3538\n",
            "Epoch 33:  11% 100/901 [00:11<01:37,  8.25it/s]Step 14450: loss = 2.3567\n",
            "Epoch 33:  22% 198/901 [00:22<01:21,  8.62it/s]Step 14500: loss = 2.3404\n",
            "Checkpoint saved -> checkpoints/model_step_14500.pt\n",
            "Epoch 33:  22% 200/901 [00:22<02:36,  4.48it/s]Step 14500: loss = 2.3401\n",
            "Checkpoint saved -> checkpoints/model_step_14500.pt\n",
            "Epoch 33:  33% 298/901 [00:35<01:07,  8.89it/s]Step 14550: loss = 2.3194\n",
            "Epoch 33:  33% 300/901 [00:35<01:07,  8.84it/s]Step 14550: loss = 2.3202\n",
            "Epoch 33:  44% 399/901 [00:47<01:01,  8.11it/s]Step 14600: loss = 2.3071\n",
            "Epoch 33:  44% 400/901 [00:47<00:59,  8.40it/s]Step 14600: loss = 2.3065\n",
            "Epoch 33:  55% 498/901 [00:58<00:44,  9.01it/s]Step 14650: loss = 2.3105\n",
            "Epoch 33:  55% 500/901 [00:59<00:45,  8.89it/s]Step 14650: loss = 2.3103\n",
            "Epoch 33:  66% 599/901 [01:10<00:31,  9.44it/s]Step 14700: loss = 2.3178\n",
            "Epoch 33:  67% 600/901 [01:10<00:34,  8.64it/s]Step 14700: loss = 2.3175\n",
            "Epoch 33:  77% 698/901 [01:21<00:25,  7.95it/s]Step 14750: loss = 2.3126\n",
            "Epoch 33:  78% 700/901 [01:21<00:22,  8.84it/s]Step 14750: loss = 2.3126\n",
            "Epoch 33:  89% 798/901 [01:33<00:11,  8.91it/s]Step 14800: loss = 2.3121\n",
            "Epoch 33:  89% 800/901 [01:33<00:11,  8.67it/s]Step 14800: loss = 2.3122\n",
            "Epoch 33: 100% 898/901 [01:45<00:00, 10.06it/s]Step 14850: loss = 2.3044\n",
            "Epoch 33: 100% 900/901 [01:45<00:00,  9.96it/s]Step 14850: loss = 2.3038\n",
            "Epoch 33: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 33 completed. Average training loss: 2.3038\n",
            "Validation loss after epoch 33: 2.4945\n",
            "Checkpoint saved -> checkpoints/model_epoch_33.pt\n",
            "Epoch 34:   0% 0/901 [00:00<?, ?it/s]Step 14850: loss = 3.0049\n",
            "Epoch 34:  11% 98/901 [00:11<01:37,  8.20it/s]Step 14900: loss = 2.2666\n",
            "Epoch 34:  11% 100/901 [00:11<01:29,  8.91it/s]Step 14900: loss = 2.2748\n",
            "Epoch 34:  22% 198/901 [00:22<01:18,  8.97it/s]Step 14950: loss = 2.2890\n",
            "Epoch 34:  22% 200/901 [00:22<01:22,  8.53it/s]Step 14950: loss = 2.2899\n",
            "Epoch 34:  33% 298/901 [00:34<01:08,  8.78it/s]Step 15000: loss = 2.2944\n",
            "Checkpoint saved -> checkpoints/model_step_15000.pt\n",
            "Epoch 34:  33% 300/901 [00:34<01:59,  5.04it/s]Step 15000: loss = 2.2944\n",
            "Checkpoint saved -> checkpoints/model_step_15000.pt\n",
            "Epoch 34:  44% 399/901 [00:47<00:58,  8.61it/s]Step 15050: loss = 2.2894\n",
            "Step 15050: loss = 2.2916\n",
            "Epoch 34:  55% 498/901 [00:58<00:54,  7.46it/s]Step 15100: loss = 2.2951\n",
            "Epoch 34:  55% 500/901 [00:58<00:51,  7.75it/s]Step 15100: loss = 2.2936\n",
            "Epoch 34:  66% 598/901 [01:09<00:37,  8.05it/s]Step 15150: loss = 2.2904\n",
            "Epoch 34:  67% 600/901 [01:10<00:37,  8.01it/s]Step 15150: loss = 2.2902\n",
            "Epoch 34:  78% 699/901 [01:22<00:22,  9.06it/s]Step 15200: loss = 2.2824\n",
            "Epoch 34:  78% 700/901 [01:22<00:24,  8.37it/s]Step 15200: loss = 2.2815\n",
            "Epoch 34:  89% 799/901 [01:33<00:11,  8.57it/s]Step 15250: loss = 2.2873\n",
            "Epoch 34:  89% 800/901 [01:33<00:12,  8.21it/s]Step 15250: loss = 2.2878\n",
            "Epoch 34: 100% 899/901 [01:45<00:00,  7.81it/s]Step 15300: loss = 2.2920\n",
            "Epoch 34: 100% 900/901 [01:45<00:00,  7.90it/s]Step 15300: loss = 2.2913\n",
            "Epoch 34: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 34 completed. Average training loss: 2.2913\n",
            "Validation loss after epoch 34: 2.4906\n",
            "Checkpoint saved -> checkpoints/model_epoch_34.pt\n",
            "Epoch 35:   0% 0/901 [00:00<?, ?it/s]Step 15300: loss = 2.6985\n",
            "Epoch 35:  11% 98/901 [00:11<01:35,  8.45it/s]Step 15350: loss = 2.2778\n",
            "Epoch 35:  11% 100/901 [00:11<01:34,  8.48it/s]Step 15350: loss = 2.2832\n",
            "Epoch 35:  22% 198/901 [00:24<01:11,  9.90it/s]Step 15400: loss = 2.2290\n",
            "Epoch 35:  22% 200/901 [00:24<01:11,  9.82it/s]Step 15400: loss = 2.2313\n",
            "Epoch 35:  33% 299/901 [00:35<01:03,  9.53it/s]Step 15450: loss = 2.2607\n",
            "Step 15450: loss = 2.2617\n",
            "Epoch 35:  44% 398/901 [00:47<00:53,  9.44it/s]Step 15500: loss = 2.2623\n",
            "Checkpoint saved -> checkpoints/model_step_15500.pt\n",
            "Epoch 35:  44% 400/901 [00:47<01:35,  5.24it/s]Step 15500: loss = 2.2638\n",
            "Checkpoint saved -> checkpoints/model_step_15500.pt\n",
            "Epoch 35:  55% 499/901 [00:59<00:41,  9.65it/s]Step 15550: loss = 2.2882\n",
            "Epoch 35:  55% 500/901 [00:59<00:48,  8.31it/s]Step 15550: loss = 2.2893\n",
            "Epoch 35:  66% 598/901 [01:10<00:32,  9.42it/s]Step 15600: loss = 2.2934\n",
            "Epoch 35:  67% 600/901 [01:10<00:32,  9.30it/s]Step 15600: loss = 2.2921\n",
            "Epoch 35:  77% 698/901 [01:22<00:22,  9.20it/s]Step 15650: loss = 2.2907\n",
            "Epoch 35:  78% 700/901 [01:22<00:22,  8.93it/s]Step 15650: loss = 2.2911\n",
            "Epoch 35:  89% 799/901 [01:33<00:11,  8.52it/s]Step 15700: loss = 2.2909\n",
            "Epoch 35:  89% 800/901 [01:34<00:12,  8.23it/s]Step 15700: loss = 2.2911\n",
            "Epoch 35: 100% 898/901 [01:44<00:00,  9.37it/s]Step 15750: loss = 2.2986\n",
            "Epoch 35: 100% 900/901 [01:45<00:00,  9.41it/s]Step 15750: loss = 2.2988\n",
            "Epoch 35: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 35 completed. Average training loss: 2.2988\n",
            "Validation loss after epoch 35: 2.4869\n",
            "Checkpoint saved -> checkpoints/model_epoch_35.pt\n",
            "Epoch 36:   0% 0/901 [00:00<?, ?it/s]Step 15750: loss = 1.7667\n",
            "Epoch 36:  11% 98/901 [00:11<01:42,  7.86it/s]Step 15800: loss = 2.3507\n",
            "Epoch 36:  11% 100/901 [00:11<01:29,  8.91it/s]Step 15800: loss = 2.3513\n",
            "Epoch 36:  22% 199/901 [00:23<01:18,  8.89it/s]Step 15850: loss = 2.3333\n",
            "Epoch 36:  22% 200/901 [00:23<01:21,  8.64it/s]Step 15850: loss = 2.3315\n",
            "Epoch 36:  33% 298/901 [00:34<01:14,  8.07it/s]Step 15900: loss = 2.2983\n",
            "Epoch 36:  33% 300/901 [00:34<01:16,  7.82it/s]Step 15900: loss = 2.2982\n",
            "Epoch 36:  44% 399/901 [00:46<01:03,  7.85it/s]Step 15950: loss = 2.3072\n",
            "Epoch 36:  44% 400/901 [00:46<01:01,  8.10it/s]Step 15950: loss = 2.3060\n",
            "Epoch 36:  55% 498/901 [00:57<00:42,  9.58it/s]Step 16000: loss = 2.3039\n",
            "Checkpoint saved -> checkpoints/model_step_16000.pt\n",
            "Epoch 36:  55% 500/901 [00:58<01:17,  5.20it/s]Step 16000: loss = 2.3038\n",
            "Checkpoint saved -> checkpoints/model_step_16000.pt\n",
            "Epoch 36:  66% 599/901 [01:10<00:33,  8.99it/s]Step 16050: loss = 2.3043\n",
            "Epoch 36:  67% 600/901 [01:10<00:35,  8.45it/s]Step 16050: loss = 2.3044\n",
            "Epoch 36:  78% 699/901 [01:22<00:24,  8.15it/s]Step 16100: loss = 2.3057\n",
            "Epoch 36:  78% 700/901 [01:22<00:24,  8.32it/s]Step 16100: loss = 2.3046\n",
            "Epoch 36:  89% 798/901 [01:33<00:10,  9.55it/s]Step 16150: loss = 2.3021\n",
            "Epoch 36:  89% 800/901 [01:33<00:10,  9.20it/s]Step 16150: loss = 2.3028\n",
            "Epoch 36: 100% 899/901 [01:45<00:00,  8.78it/s]Step 16200: loss = 2.3016\n",
            "Epoch 36: 100% 900/901 [01:45<00:00,  8.78it/s]Step 16200: loss = 2.3013\n",
            "Epoch 36: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 36 completed. Average training loss: 2.3013\n",
            "Validation loss after epoch 36: 2.4833\n",
            "Checkpoint saved -> checkpoints/model_epoch_36.pt\n",
            "Epoch 37:   0% 0/901 [00:00<?, ?it/s]Step 16200: loss = 2.3575\n",
            "Epoch 37:  11% 98/901 [00:11<01:33,  8.63it/s]Step 16250: loss = 2.2622\n",
            "Epoch 37:  11% 100/901 [00:11<01:26,  9.26it/s]Step 16250: loss = 2.2679\n",
            "Epoch 37:  22% 198/901 [00:22<01:14,  9.39it/s]Step 16300: loss = 2.2957\n",
            "Epoch 37:  22% 200/901 [00:22<01:12,  9.69it/s]Step 16300: loss = 2.2952\n",
            "Epoch 37:  33% 299/901 [00:33<01:02,  9.62it/s]Step 16350: loss = 2.3250\n",
            "Epoch 37:  33% 300/901 [00:33<01:04,  9.37it/s]Step 16350: loss = 2.3216\n",
            "Epoch 37:  44% 399/901 [00:45<01:04,  7.83it/s]Step 16400: loss = 2.3016\n",
            "Epoch 37:  44% 400/901 [00:46<01:07,  7.41it/s]Step 16400: loss = 2.3001\n",
            "Epoch 37:  55% 498/901 [00:57<01:01,  6.57it/s]Step 16450: loss = 2.3022\n",
            "Epoch 37:  55% 500/901 [00:57<00:53,  7.49it/s]Step 16450: loss = 2.3023\n",
            "Epoch 37:  66% 599/901 [01:09<00:37,  8.04it/s]Step 16500: loss = 2.3026\n",
            "Checkpoint saved -> checkpoints/model_step_16500.pt\n",
            "Epoch 37:  67% 600/901 [01:10<01:18,  3.84it/s]Step 16500: loss = 2.3026\n",
            "Checkpoint saved -> checkpoints/model_step_16500.pt\n",
            "Epoch 37:  77% 698/901 [01:22<00:21,  9.42it/s]Step 16550: loss = 2.3033\n",
            "Epoch 37:  78% 700/901 [01:22<00:20,  9.57it/s]Step 16550: loss = 2.3029\n",
            "Epoch 37:  89% 798/901 [01:33<00:11,  8.70it/s]Step 16600: loss = 2.2968\n",
            "Epoch 37:  89% 800/901 [01:33<00:11,  8.80it/s]Step 16600: loss = 2.2963\n",
            "Epoch 37: 100% 898/901 [01:45<00:00,  9.71it/s]Step 16650: loss = 2.2970\n",
            "Epoch 37: 100% 900/901 [01:45<00:00,  9.84it/s]Step 16650: loss = 2.2973\n",
            "Epoch 37: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 37 completed. Average training loss: 2.2973\n",
            "Validation loss after epoch 37: 2.4799\n",
            "Checkpoint saved -> checkpoints/model_epoch_37.pt\n",
            "Epoch 38:   0% 0/901 [00:00<?, ?it/s]Step 16650: loss = 2.7380\n",
            "Epoch 38:  11% 98/901 [00:11<01:31,  8.81it/s]Step 16700: loss = 2.2865\n",
            "Epoch 38:  11% 100/901 [00:11<01:36,  8.29it/s]Step 16700: loss = 2.2841\n",
            "Epoch 38:  22% 199/901 [00:23<01:38,  7.13it/s]Step 16750: loss = 2.2848\n",
            "Epoch 38:  22% 200/901 [00:23<01:36,  7.27it/s]Step 16750: loss = 2.2816\n",
            "Epoch 38:  33% 298/901 [00:34<01:09,  8.62it/s]Step 16800: loss = 2.2896\n",
            "Epoch 38:  33% 300/901 [00:35<01:04,  9.38it/s]Step 16800: loss = 2.2877\n",
            "Epoch 38:  44% 398/901 [00:46<01:04,  7.77it/s]Step 16850: loss = 2.2818\n",
            "Epoch 38:  44% 400/901 [00:47<01:01,  8.18it/s]Step 16850: loss = 2.2802\n",
            "Epoch 38:  55% 499/901 [00:58<00:41,  9.77it/s]Step 16900: loss = 2.2752\n",
            "Epoch 38:  55% 500/901 [00:58<00:42,  9.35it/s]Step 16900: loss = 2.2750\n",
            "Epoch 38:  66% 598/901 [01:09<00:38,  7.78it/s]Step 16950: loss = 2.2797\n",
            "Epoch 38:  67% 600/901 [01:09<00:36,  8.27it/s]Step 16950: loss = 2.2805\n",
            "Epoch 38:  77% 698/901 [01:21<00:20, 10.02it/s]Step 17000: loss = 2.2835\n",
            "Checkpoint saved -> checkpoints/model_step_17000.pt\n",
            "Epoch 38:  78% 700/901 [01:21<00:38,  5.27it/s]Step 17000: loss = 2.2841\n",
            "Checkpoint saved -> checkpoints/model_step_17000.pt\n",
            "Epoch 38:  89% 799/901 [01:33<00:12,  7.90it/s]Step 17050: loss = 2.2786\n",
            "Epoch 38:  89% 800/901 [01:33<00:12,  8.30it/s]Step 17050: loss = 2.2794\n",
            "Epoch 38: 100% 899/901 [01:45<00:00,  8.02it/s]Step 17100: loss = 2.2833\n",
            "Epoch 38: 100% 900/901 [01:45<00:00,  8.22it/s]Step 17100: loss = 2.2834\n",
            "Epoch 38: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 38 completed. Average training loss: 2.2834\n",
            "Validation loss after epoch 38: 2.4766\n",
            "Checkpoint saved -> checkpoints/model_epoch_38.pt\n",
            "Epoch 39:   0% 0/901 [00:00<?, ?it/s]Step 17100: loss = 1.6585\n",
            "Epoch 39:  11% 98/901 [00:10<01:25,  9.38it/s]Step 17150: loss = 2.3537\n",
            "Epoch 39:  11% 100/901 [00:11<01:25,  9.32it/s]Step 17150: loss = 2.3587\n",
            "Epoch 39:  22% 199/901 [00:22<01:23,  8.45it/s]Step 17200: loss = 2.3311\n",
            "Step 17200: loss = 2.3318\n",
            "Epoch 39:  33% 298/901 [00:34<01:07,  8.93it/s]Step 17250: loss = 2.2907\n",
            "Epoch 39:  33% 300/901 [00:34<01:07,  8.85it/s]Step 17250: loss = 2.2871\n",
            "Epoch 39:  44% 398/901 [00:45<00:54,  9.21it/s]Step 17300: loss = 2.3020\n",
            "Epoch 39:  44% 400/901 [00:45<00:53,  9.36it/s]Step 17300: loss = 2.3022\n",
            "Epoch 39:  55% 498/901 [00:57<00:45,  8.92it/s]Step 17350: loss = 2.2963\n",
            "Epoch 39:  55% 500/901 [00:57<00:47,  8.49it/s]Step 17350: loss = 2.2969\n",
            "Epoch 39:  66% 598/901 [01:08<00:32,  9.43it/s]Step 17400: loss = 2.3000\n",
            "Epoch 39:  67% 600/901 [01:09<00:33,  9.02it/s]Step 17400: loss = 2.3004\n",
            "Epoch 39:  78% 699/901 [01:20<00:31,  6.34it/s]Step 17450: loss = 2.2892\n",
            "Epoch 39:  78% 700/901 [01:20<00:32,  6.20it/s]Step 17450: loss = 2.2893\n",
            "Epoch 39:  89% 798/901 [01:32<00:11,  8.93it/s]Step 17500: loss = 2.2878\n",
            "Checkpoint saved -> checkpoints/model_step_17500.pt\n",
            "Epoch 39:  89% 800/901 [01:33<00:21,  4.75it/s]Step 17500: loss = 2.2884\n",
            "Checkpoint saved -> checkpoints/model_step_17500.pt\n",
            "Epoch 39: 100% 898/901 [01:44<00:00,  6.99it/s]Step 17550: loss = 2.2850\n",
            "Epoch 39: 100% 900/901 [01:44<00:00,  8.19it/s]Step 17550: loss = 2.2854\n",
            "Epoch 39: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 39 completed. Average training loss: 2.2854\n",
            "Validation loss after epoch 39: 2.4735\n",
            "Checkpoint saved -> checkpoints/model_epoch_39.pt\n",
            "Epoch 40:   0% 0/901 [00:00<?, ?it/s]Step 17550: loss = 2.5604\n",
            "Epoch 40:  11% 98/901 [00:11<01:27,  9.14it/s]Step 17600: loss = 2.3027\n",
            "Epoch 40:  11% 100/901 [00:11<01:29,  8.99it/s]Step 17600: loss = 2.2994\n",
            "Epoch 40:  22% 198/901 [00:23<01:26,  8.09it/s]Step 17650: loss = 2.3055\n",
            "Epoch 40:  22% 200/901 [00:23<01:21,  8.63it/s]Step 17650: loss = 2.3078\n",
            "Epoch 40:  33% 298/901 [00:34<01:00,  9.90it/s]Step 17700: loss = 2.2849\n",
            "Epoch 40:  33% 300/901 [00:34<01:00,  9.91it/s]Step 17700: loss = 2.2862\n",
            "Epoch 40:  44% 398/901 [00:46<01:00,  8.38it/s]Step 17750: loss = 2.2793\n",
            "Epoch 40:  44% 400/901 [00:46<00:57,  8.74it/s]Step 17750: loss = 2.2796\n",
            "Epoch 40:  55% 498/901 [00:58<00:49,  8.17it/s]Step 17800: loss = 2.2786\n",
            "Epoch 40:  55% 500/901 [00:58<00:45,  8.91it/s]Step 17800: loss = 2.2795\n",
            "Epoch 40:  66% 598/901 [01:09<00:35,  8.49it/s]Step 17850: loss = 2.2756\n",
            "Epoch 40:  67% 600/901 [01:09<00:34,  8.66it/s]Step 17850: loss = 2.2770\n",
            "Epoch 40:  77% 698/901 [01:21<00:25,  8.10it/s]Step 17900: loss = 2.2771\n",
            "Epoch 40:  78% 700/901 [01:21<00:23,  8.59it/s]Step 17900: loss = 2.2763\n",
            "Epoch 40:  89% 798/901 [01:32<00:11,  8.90it/s]Step 17950: loss = 2.2734\n",
            "Epoch 40:  89% 800/901 [01:32<00:10,  9.55it/s]Step 17950: loss = 2.2740\n",
            "Epoch 40: 100% 899/901 [01:44<00:00,  7.76it/s]Step 18000: loss = 2.2707\n",
            "Checkpoint saved -> checkpoints/model_step_18000.pt\n",
            "Epoch 40: 100% 900/901 [01:45<00:00,  3.59it/s]Step 18000: loss = 2.2709\n",
            "Checkpoint saved -> checkpoints/model_step_18000.pt\n",
            "Epoch 40: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 40 completed. Average training loss: 2.2709\n",
            "Validation loss after epoch 40: 2.4704\n",
            "Checkpoint saved -> checkpoints/model_epoch_40.pt\n",
            "Epoch 41:   0% 0/901 [00:00<?, ?it/s]Step 18000: loss = 2.2894\n",
            "Checkpoint saved -> checkpoints/model_step_18000.pt\n",
            "Epoch 41:  11% 99/901 [00:11<01:37,  8.24it/s]Step 18050: loss = 2.3202\n",
            "Epoch 41:  11% 100/901 [00:11<01:36,  8.33it/s]Step 18050: loss = 2.3143\n",
            "Epoch 41:  22% 198/901 [00:23<01:14,  9.42it/s]Step 18100: loss = 2.2795\n",
            "Epoch 41:  22% 200/901 [00:23<01:13,  9.50it/s]Step 18100: loss = 2.2808\n",
            "Epoch 41:  33% 298/901 [00:35<01:34,  6.38it/s]Step 18150: loss = 2.2561\n",
            "Epoch 41:  33% 300/901 [00:35<01:23,  7.20it/s]Step 18150: loss = 2.2532\n",
            "Epoch 41:  44% 398/901 [00:47<00:59,  8.48it/s]Step 18200: loss = 2.2644\n",
            "Epoch 41:  44% 400/901 [00:47<00:56,  8.85it/s]Step 18200: loss = 2.2654\n",
            "Epoch 41:  55% 499/901 [00:58<00:45,  8.86it/s]Step 18250: loss = 2.2823\n",
            "Epoch 41:  55% 500/901 [00:58<00:52,  7.68it/s]Step 18250: loss = 2.2827\n",
            "Epoch 41:  66% 598/901 [01:09<00:29, 10.45it/s]Step 18300: loss = 2.2885\n",
            "Epoch 41:  67% 600/901 [01:09<00:28, 10.48it/s]Step 18300: loss = 2.2880\n",
            "Epoch 41:  77% 698/901 [01:20<00:31,  6.45it/s]Step 18350: loss = 2.2973\n",
            "Epoch 41:  78% 700/901 [01:21<00:28,  7.12it/s]Step 18350: loss = 2.2970\n",
            "Epoch 41:  89% 799/901 [01:32<00:11,  8.96it/s]Step 18400: loss = 2.2956\n",
            "Step 18400: loss = 2.2961\n",
            "Epoch 41: 100% 899/901 [01:44<00:00,  8.97it/s]Step 18450: loss = 2.2838\n",
            "Epoch 41: 100% 900/901 [01:44<00:00,  8.25it/s]Step 18450: loss = 2.2840\n",
            "Epoch 41: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 41 completed. Average training loss: 2.2840\n",
            "Validation loss after epoch 41: 2.4675\n",
            "Checkpoint saved -> checkpoints/model_epoch_41.pt\n",
            "Epoch 42:   0% 0/901 [00:00<?, ?it/s]Step 18450: loss = 1.5802\n",
            "Epoch 42:  11% 98/901 [00:11<01:41,  7.92it/s]Step 18500: loss = 2.2696\n",
            "Checkpoint saved -> checkpoints/model_step_18500.pt\n",
            "Epoch 42:  11% 100/901 [00:12<02:48,  4.74it/s]Step 18500: loss = 2.2725\n",
            "Checkpoint saved -> checkpoints/model_step_18500.pt\n",
            "Epoch 42:  22% 199/901 [00:23<01:26,  8.14it/s]Step 18550: loss = 2.2984\n",
            "Epoch 42:  22% 200/901 [00:23<01:25,  8.25it/s]Step 18550: loss = 2.2996\n",
            "Epoch 42:  33% 299/901 [00:35<01:20,  7.48it/s]Step 18600: loss = 2.2825\n",
            "Epoch 42:  33% 300/901 [00:35<01:16,  7.86it/s]Step 18600: loss = 2.2844\n",
            "Epoch 42:  44% 398/901 [00:47<00:51,  9.77it/s]Step 18650: loss = 2.2714\n",
            "Epoch 42:  44% 400/901 [00:47<00:55,  9.09it/s]Step 18650: loss = 2.2703\n",
            "Epoch 42:  55% 498/901 [00:59<00:44,  9.14it/s]Step 18700: loss = 2.2648\n",
            "Epoch 42:  55% 500/901 [00:59<00:41,  9.62it/s]Step 18700: loss = 2.2635\n",
            "Epoch 42:  66% 599/901 [01:10<00:33,  9.13it/s]Step 18750: loss = 2.2748\n",
            "Epoch 42:  67% 600/901 [01:10<00:32,  9.15it/s]Step 18750: loss = 2.2746\n",
            "Epoch 42:  77% 698/901 [01:21<00:21,  9.43it/s]Step 18800: loss = 2.2862\n",
            "Epoch 42:  78% 700/901 [01:21<00:20,  9.66it/s]Step 18800: loss = 2.2866\n",
            "Epoch 42:  89% 798/901 [01:32<00:11,  9.33it/s]Step 18850: loss = 2.2890\n",
            "Epoch 42:  89% 800/901 [01:33<00:10,  9.48it/s]Step 18850: loss = 2.2884\n",
            "Epoch 42: 100% 898/901 [01:44<00:00,  8.09it/s]Step 18900: loss = 2.2779\n",
            "Epoch 42: 100% 900/901 [01:45<00:00,  8.73it/s]Step 18900: loss = 2.2781\n",
            "Epoch 42: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 42 completed. Average training loss: 2.2781\n",
            "Validation loss after epoch 42: 2.4647\n",
            "Checkpoint saved -> checkpoints/model_epoch_42.pt\n",
            "Epoch 43:   0% 0/901 [00:00<?, ?it/s]Step 18900: loss = 1.6862\n",
            "Epoch 43:  11% 99/901 [00:11<01:32,  8.69it/s]Step 18950: loss = 2.2487\n",
            "Step 18950: loss = 2.2441\n",
            "Epoch 43:  22% 198/901 [00:23<01:26,  8.11it/s]Step 19000: loss = 2.2512\n",
            "Checkpoint saved -> checkpoints/model_step_19000.pt\n",
            "Epoch 43:  22% 200/901 [00:23<02:47,  4.19it/s]Step 19000: loss = 2.2508\n",
            "Checkpoint saved -> checkpoints/model_step_19000.pt\n",
            "Epoch 43:  33% 298/901 [00:35<01:04,  9.36it/s]Step 19050: loss = 2.2628\n",
            "Epoch 43:  33% 300/901 [00:35<01:02,  9.64it/s]Step 19050: loss = 2.2614\n",
            "Epoch 43:  44% 398/901 [00:47<00:56,  8.82it/s]Step 19100: loss = 2.2588\n",
            "Epoch 43:  44% 400/901 [00:47<00:53,  9.40it/s]Step 19100: loss = 2.2595\n",
            "Epoch 43:  55% 498/901 [00:58<00:44,  9.06it/s]Step 19150: loss = 2.2558\n",
            "Epoch 43:  55% 500/901 [00:58<00:43,  9.30it/s]Step 19150: loss = 2.2566\n",
            "Epoch 43:  66% 598/901 [01:10<00:38,  7.78it/s]Step 19200: loss = 2.2572\n",
            "Epoch 43:  67% 600/901 [01:10<00:36,  8.25it/s]Step 19200: loss = 2.2573\n",
            "Epoch 43:  77% 698/901 [01:21<00:22,  9.04it/s]Step 19250: loss = 2.2750\n",
            "Epoch 43:  78% 700/901 [01:21<00:21,  9.20it/s]Step 19250: loss = 2.2753\n",
            "Epoch 43:  89% 799/901 [01:33<00:12,  8.29it/s]Step 19300: loss = 2.2740\n",
            "Epoch 43:  89% 800/901 [01:33<00:13,  7.72it/s]Step 19300: loss = 2.2749\n",
            "Epoch 43: 100% 898/901 [01:44<00:00,  9.59it/s]Step 19350: loss = 2.2773\n",
            "Epoch 43: 100% 900/901 [01:45<00:00,  9.70it/s]Step 19350: loss = 2.2766\n",
            "Epoch 43: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 43 completed. Average training loss: 2.2766\n",
            "Validation loss after epoch 43: 2.4619\n",
            "Checkpoint saved -> checkpoints/model_epoch_43.pt\n",
            "Epoch 44:   0% 0/901 [00:00<?, ?it/s]Step 19350: loss = 2.7927\n",
            "Epoch 44:  11% 99/901 [00:11<01:33,  8.59it/s]Step 19400: loss = 2.2362\n",
            "Step 19400: loss = 2.2390\n",
            "Epoch 44:  22% 198/901 [00:23<01:18,  8.91it/s]Step 19450: loss = 2.2190\n",
            "Epoch 44:  22% 200/901 [00:23<01:11,  9.82it/s]Step 19450: loss = 2.2241\n",
            "Epoch 44:  33% 298/901 [00:34<01:15,  7.95it/s]Step 19500: loss = 2.2521\n",
            "Checkpoint saved -> checkpoints/model_step_19500.pt\n",
            "Epoch 44:  33% 300/901 [00:35<02:04,  4.81it/s]Step 19500: loss = 2.2507\n",
            "Checkpoint saved -> checkpoints/model_step_19500.pt\n",
            "Epoch 44:  44% 398/901 [00:46<01:01,  8.15it/s]Step 19550: loss = 2.2706\n",
            "Epoch 44:  44% 400/901 [00:47<00:59,  8.42it/s]Step 19550: loss = 2.2712\n",
            "Epoch 44:  55% 499/901 [00:58<00:44,  9.03it/s]Step 19600: loss = 2.2729\n",
            "Epoch 44:  55% 500/901 [00:58<00:47,  8.52it/s]Step 19600: loss = 2.2737\n",
            "Epoch 44:  66% 598/901 [01:09<00:32,  9.26it/s]Step 19650: loss = 2.2804\n",
            "Epoch 44:  67% 600/901 [01:09<00:34,  8.69it/s]Step 19650: loss = 2.2816\n",
            "Epoch 44:  78% 699/901 [01:21<00:26,  7.64it/s]Step 19700: loss = 2.2727\n",
            "Epoch 44:  78% 700/901 [01:22<00:25,  7.90it/s]Step 19700: loss = 2.2730\n",
            "Epoch 44:  89% 798/901 [01:33<00:11,  8.59it/s]Step 19750: loss = 2.2734\n",
            "Epoch 44:  89% 800/901 [01:33<00:10,  9.33it/s]Step 19750: loss = 2.2737\n",
            "Epoch 44: 100% 899/901 [01:45<00:00,  7.61it/s]Step 19800: loss = 2.2696\n",
            "Epoch 44: 100% 900/901 [01:45<00:00,  7.30it/s]Step 19800: loss = 2.2701\n",
            "Epoch 44: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 44 completed. Average training loss: 2.2701\n",
            "Validation loss after epoch 44: 2.4593\n",
            "Checkpoint saved -> checkpoints/model_epoch_44.pt\n",
            "Epoch 45:   0% 0/901 [00:00<?, ?it/s]Step 19800: loss = 3.1721\n",
            "Epoch 45:  11% 98/901 [00:11<01:28,  9.09it/s]Step 19850: loss = 2.2517\n",
            "Epoch 45:  11% 100/901 [00:11<01:27,  9.19it/s]Step 19850: loss = 2.2467\n",
            "Epoch 45:  22% 199/901 [00:23<01:29,  7.85it/s]Step 19900: loss = 2.2568\n",
            "Epoch 45:  22% 200/901 [00:23<01:29,  7.79it/s]Step 19900: loss = 2.2602\n",
            "Epoch 45:  33% 299/901 [00:34<01:09,  8.68it/s]Step 19950: loss = 2.2632\n",
            "Epoch 45:  33% 300/901 [00:34<01:21,  7.34it/s]Step 19950: loss = 2.2625\n",
            "Epoch 45:  44% 398/901 [00:45<00:49, 10.25it/s]Step 20000: loss = 2.2967\n",
            "Checkpoint saved -> checkpoints/model_step_20000.pt\n",
            "Epoch 45:  44% 400/901 [00:46<01:37,  5.16it/s]Step 20000: loss = 2.2977\n",
            "Checkpoint saved -> checkpoints/model_step_20000.pt\n",
            "Epoch 45:  55% 498/901 [00:58<00:46,  8.65it/s]Step 20050: loss = 2.2730\n",
            "Epoch 45:  55% 500/901 [00:58<00:44,  8.92it/s]Step 20050: loss = 2.2727\n",
            "Epoch 45:  66% 599/901 [01:10<00:36,  8.36it/s]Step 20100: loss = 2.2677\n",
            "Epoch 45:  67% 600/901 [01:10<00:35,  8.44it/s]Step 20100: loss = 2.2675\n",
            "Epoch 45:  78% 699/901 [01:22<00:23,  8.78it/s]Step 20150: loss = 2.2647\n",
            "Step 20150: loss = 2.2647\n",
            "Epoch 45:  89% 799/901 [01:33<00:12,  8.04it/s]Step 20200: loss = 2.2644\n",
            "Epoch 45:  89% 800/901 [01:33<00:12,  8.15it/s]Step 20200: loss = 2.2654\n",
            "Epoch 45: 100% 898/901 [01:44<00:00,  8.69it/s]Step 20250: loss = 2.2686\n",
            "Epoch 45: 100% 900/901 [01:44<00:00,  8.72it/s]Step 20250: loss = 2.2687\n",
            "Epoch 45: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 45 completed. Average training loss: 2.2687\n",
            "Validation loss after epoch 45: 2.4567\n",
            "Checkpoint saved -> checkpoints/model_epoch_45.pt\n",
            "Epoch 46:   0% 0/901 [00:00<?, ?it/s]Step 20250: loss = 2.1801\n",
            "Epoch 46:  11% 99/901 [00:11<01:34,  8.53it/s]Step 20300: loss = 2.2492\n",
            "Epoch 46:  11% 100/901 [00:11<01:34,  8.45it/s]Step 20300: loss = 2.2493\n",
            "Epoch 46:  22% 198/901 [00:23<01:29,  7.89it/s]Step 20350: loss = 2.2593\n",
            "Epoch 46:  22% 200/901 [00:23<01:17,  9.07it/s]Step 20350: loss = 2.2566\n",
            "Epoch 46:  33% 298/901 [00:34<01:11,  8.47it/s]Step 20400: loss = 2.2453\n",
            "Epoch 46:  33% 300/901 [00:35<01:07,  8.92it/s]Step 20400: loss = 2.2469\n",
            "Epoch 46:  44% 398/901 [00:46<00:59,  8.48it/s]Step 20450: loss = 2.2555\n",
            "Epoch 46:  44% 400/901 [00:46<00:55,  9.06it/s]Step 20450: loss = 2.2530\n",
            "Epoch 46:  55% 499/901 [00:57<00:46,  8.72it/s]Step 20500: loss = 2.2604\n",
            "Checkpoint saved -> checkpoints/model_step_20500.pt\n",
            "Epoch 46:  55% 500/901 [00:58<01:32,  4.34it/s]Step 20500: loss = 2.2597\n",
            "Checkpoint saved -> checkpoints/model_step_20500.pt\n",
            "Epoch 46:  66% 598/901 [01:10<00:30, 10.00it/s]Step 20550: loss = 2.2662\n",
            "Epoch 46:  67% 600/901 [01:10<00:31,  9.47it/s]Step 20550: loss = 2.2664\n",
            "Epoch 46:  78% 699/901 [01:21<00:24,  8.31it/s]Step 20600: loss = 2.2666\n",
            "Epoch 46:  78% 700/901 [01:21<00:24,  8.34it/s]Step 20600: loss = 2.2663\n",
            "Epoch 46:  89% 799/901 [01:32<00:12,  7.91it/s]Step 20650: loss = 2.2723\n",
            "Epoch 46:  89% 800/901 [01:32<00:12,  8.12it/s]Step 20650: loss = 2.2723\n",
            "Epoch 46: 100% 898/901 [01:45<00:00,  8.66it/s]Step 20700: loss = 2.2586\n",
            "Epoch 46: 100% 900/901 [01:45<00:00,  9.52it/s]Step 20700: loss = 2.2589\n",
            "Epoch 46: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 46 completed. Average training loss: 2.2589\n",
            "Validation loss after epoch 46: 2.4542\n",
            "Checkpoint saved -> checkpoints/model_epoch_46.pt\n",
            "Epoch 47:   0% 0/901 [00:00<?, ?it/s]Step 20700: loss = 2.7238\n",
            "Epoch 47:  11% 98/901 [00:11<01:30,  8.91it/s]Step 20750: loss = 2.2683\n",
            "Epoch 47:  11% 100/901 [00:11<01:30,  8.86it/s]Step 20750: loss = 2.2653\n",
            "Epoch 47:  22% 198/901 [00:23<01:23,  8.46it/s]Step 20800: loss = 2.2739\n",
            "Epoch 47:  22% 200/901 [00:23<01:16,  9.11it/s]Step 20800: loss = 2.2753\n",
            "Epoch 47:  33% 299/901 [00:34<01:09,  8.66it/s]Step 20850: loss = 2.2648\n",
            "Epoch 47:  33% 300/901 [00:34<01:08,  8.75it/s]Step 20850: loss = 2.2631\n",
            "Epoch 47:  44% 398/901 [00:45<00:54,  9.22it/s]Step 20900: loss = 2.2684\n",
            "Epoch 47:  44% 400/901 [00:46<00:51,  9.73it/s]Step 20900: loss = 2.2673\n",
            "Epoch 47:  55% 498/901 [00:57<00:41,  9.71it/s]Step 20950: loss = 2.2775\n",
            "Epoch 47:  55% 500/901 [00:57<00:42,  9.38it/s]Step 20950: loss = 2.2776\n",
            "Epoch 47:  66% 598/901 [01:08<00:33,  8.94it/s]Step 21000: loss = 2.2763\n",
            "Checkpoint saved -> checkpoints/model_step_21000.pt\n",
            "Epoch 47:  67% 600/901 [01:09<01:06,  4.54it/s]Step 21000: loss = 2.2750\n",
            "Checkpoint saved -> checkpoints/model_step_21000.pt\n",
            "Epoch 47:  77% 698/901 [01:21<00:22,  9.16it/s]Step 21050: loss = 2.2794\n",
            "Epoch 47:  78% 700/901 [01:21<00:24,  8.18it/s]Step 21050: loss = 2.2800\n",
            "Epoch 47:  89% 798/901 [01:32<00:10,  9.61it/s]Step 21100: loss = 2.2753\n",
            "Epoch 47:  89% 800/901 [01:32<00:10,  9.60it/s]Step 21100: loss = 2.2763\n",
            "Epoch 47: 100% 899/901 [01:44<00:00,  8.58it/s]Step 21150: loss = 2.2706\n",
            "Epoch 47: 100% 900/901 [01:44<00:00,  8.25it/s]Step 21150: loss = 2.2709\n",
            "Epoch 47: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 47 completed. Average training loss: 2.2709\n",
            "Validation loss after epoch 47: 2.4518\n",
            "Checkpoint saved -> checkpoints/model_epoch_47.pt\n",
            "Epoch 48:   0% 0/901 [00:00<?, ?it/s]Step 21150: loss = 2.4311\n",
            "Epoch 48:  11% 98/901 [00:11<01:24,  9.51it/s]Step 21200: loss = 2.2456\n",
            "Epoch 48:  11% 100/901 [00:11<01:16, 10.43it/s]Step 21200: loss = 2.2462\n",
            "Epoch 48:  22% 199/901 [00:23<01:14,  9.44it/s]Step 21250: loss = 2.2616\n",
            "Epoch 48:  22% 200/901 [00:23<01:49,  6.40it/s]Step 21250: loss = 2.2649\n",
            "Epoch 48:  33% 298/901 [00:35<01:13,  8.22it/s]Step 21300: loss = 2.2469\n",
            "Epoch 48:  33% 300/901 [00:35<01:12,  8.26it/s]Step 21300: loss = 2.2469\n",
            "Epoch 48:  44% 398/901 [00:46<00:55,  9.05it/s]Step 21350: loss = 2.2448\n",
            "Epoch 48:  44% 400/901 [00:46<00:58,  8.62it/s]Step 21350: loss = 2.2442\n",
            "Epoch 48:  55% 499/901 [00:58<00:47,  8.49it/s]Step 21400: loss = 2.2385\n",
            "Epoch 48:  55% 500/901 [00:58<00:49,  8.04it/s]Step 21400: loss = 2.2389\n",
            "Epoch 48:  66% 599/901 [01:10<00:35,  8.57it/s]Step 21450: loss = 2.2331\n",
            "Epoch 48:  67% 600/901 [01:10<00:33,  8.89it/s]Step 21450: loss = 2.2346\n",
            "Epoch 48:  78% 699/901 [01:21<00:22,  8.92it/s]Step 21500: loss = 2.2359\n",
            "Checkpoint saved -> checkpoints/model_step_21500.pt\n",
            "Epoch 48:  78% 700/901 [01:22<00:52,  3.84it/s]Step 21500: loss = 2.2361\n",
            "Checkpoint saved -> checkpoints/model_step_21500.pt\n",
            "Epoch 48:  89% 799/901 [01:34<00:11,  8.66it/s]Step 21550: loss = 2.2411\n",
            "Epoch 48:  89% 800/901 [01:34<00:12,  8.04it/s]Step 21550: loss = 2.2406\n",
            "Epoch 48: 100% 898/901 [01:45<00:00,  8.85it/s]Step 21600: loss = 2.2447\n",
            "Epoch 48: 100% 900/901 [01:45<00:00,  7.89it/s]Step 21600: loss = 2.2448\n",
            "Epoch 48: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 48 completed. Average training loss: 2.2448\n",
            "Validation loss after epoch 48: 2.4494\n",
            "Checkpoint saved -> checkpoints/model_epoch_48.pt\n",
            "Epoch 49:   0% 0/901 [00:00<?, ?it/s]Step 21600: loss = 2.0824\n",
            "Epoch 49:  11% 99/901 [00:11<01:32,  8.68it/s]Step 21650: loss = 2.2322\n",
            "Epoch 49:  11% 100/901 [00:11<01:40,  8.00it/s]Step 21650: loss = 2.2342\n",
            "Epoch 49:  22% 199/901 [00:23<01:27,  8.01it/s]Step 21700: loss = 2.2244\n",
            "Epoch 49:  22% 200/901 [00:23<01:25,  8.20it/s]Step 21700: loss = 2.2255\n",
            "Epoch 49:  33% 299/901 [00:34<01:12,  8.33it/s]Step 21750: loss = 2.2363\n",
            "Epoch 49:  33% 300/901 [00:35<01:17,  7.71it/s]Step 21750: loss = 2.2355\n",
            "Epoch 49:  44% 399/901 [00:46<00:55,  8.98it/s]Step 21800: loss = 2.2385\n",
            "Epoch 49:  44% 400/901 [00:46<00:56,  8.82it/s]Step 21800: loss = 2.2397\n",
            "Epoch 49:  55% 498/901 [00:57<00:43,  9.36it/s]Step 21850: loss = 2.2472\n",
            "Epoch 49:  55% 500/901 [00:58<00:40,  9.83it/s]Step 21850: loss = 2.2477\n",
            "Epoch 49:  66% 598/901 [01:09<00:34,  8.82it/s]Step 21900: loss = 2.2439\n",
            "Epoch 49:  67% 600/901 [01:09<00:33,  8.86it/s]Step 21900: loss = 2.2444\n",
            "Epoch 49:  77% 698/901 [01:20<00:23,  8.80it/s]Step 21950: loss = 2.2470\n",
            "Epoch 49:  78% 700/901 [01:21<00:21,  9.22it/s]Step 21950: loss = 2.2472\n",
            "Epoch 49:  89% 799/901 [01:32<00:13,  7.82it/s]Step 22000: loss = 2.2573\n",
            "Checkpoint saved -> checkpoints/model_step_22000.pt\n",
            "Epoch 49:  89% 800/901 [01:32<00:26,  3.77it/s]Step 22000: loss = 2.2569\n",
            "Checkpoint saved -> checkpoints/model_step_22000.pt\n",
            "Epoch 49: 100% 899/901 [01:45<00:00,  9.09it/s]Step 22050: loss = 2.2583\n",
            "Epoch 49: 100% 900/901 [01:45<00:00,  8.55it/s]Step 22050: loss = 2.2579\n",
            "Epoch 49: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 49 completed. Average training loss: 2.2579\n",
            "Validation loss after epoch 49: 2.4472\n",
            "Checkpoint saved -> checkpoints/model_epoch_49.pt\n",
            "Epoch 50:   0% 0/901 [00:00<?, ?it/s]Step 22050: loss = 2.5313\n",
            "Epoch 50:  11% 98/901 [00:10<01:36,  8.35it/s]Step 22100: loss = 2.2868\n",
            "Epoch 50:  11% 100/901 [00:11<01:32,  8.70it/s]Step 22100: loss = 2.2857\n",
            "Epoch 50:  22% 198/901 [00:22<01:26,  8.15it/s]Step 22150: loss = 2.2671\n",
            "Epoch 50:  22% 200/901 [00:22<01:22,  8.52it/s]Step 22150: loss = 2.2644\n",
            "Epoch 50:  33% 299/901 [00:34<01:02,  9.58it/s]Step 22200: loss = 2.2564\n",
            "Epoch 50:  33% 300/901 [00:34<01:04,  9.26it/s]Step 22200: loss = 2.2565\n",
            "Epoch 50:  44% 399/901 [00:45<01:05,  7.61it/s]Step 22250: loss = 2.2691\n",
            "Step 22250: loss = 2.2681\n",
            "Epoch 50:  55% 499/901 [00:57<00:50,  7.90it/s]Step 22300: loss = 2.2550\n",
            "Epoch 50:  55% 500/901 [00:57<00:49,  8.07it/s]Step 22300: loss = 2.2539\n",
            "Epoch 50:  66% 598/901 [01:08<00:37,  8.11it/s]Step 22350: loss = 2.2540\n",
            "Epoch 50:  67% 600/901 [01:08<00:32,  9.40it/s]Step 22350: loss = 2.2538\n",
            "Epoch 50:  77% 698/901 [01:20<00:28,  7.23it/s]Step 22400: loss = 2.2398\n",
            "Epoch 50:  78% 700/901 [01:21<00:26,  7.55it/s]Step 22400: loss = 2.2403\n",
            "Epoch 50:  89% 799/901 [01:32<00:11,  9.02it/s]Step 22450: loss = 2.2457\n",
            "Epoch 50:  89% 800/901 [01:32<00:12,  7.94it/s]Step 22450: loss = 2.2453\n",
            "Epoch 50: 100% 899/901 [01:44<00:00,  9.33it/s]Step 22500: loss = 2.2407\n",
            "Checkpoint saved -> checkpoints/model_step_22500.pt\n",
            "Epoch 50: 100% 900/901 [01:45<00:00,  4.20it/s]Step 22500: loss = 2.2404\n",
            "Checkpoint saved -> checkpoints/model_step_22500.pt\n",
            "Epoch 50: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 50 completed. Average training loss: 2.2404\n",
            "Validation loss after epoch 50: 2.4449\n",
            "Checkpoint saved -> checkpoints/model_epoch_50.pt\n",
            "Epoch 51:   0% 0/901 [00:00<?, ?it/s]Step 22500: loss = 2.3993\n",
            "Checkpoint saved -> checkpoints/model_step_22500.pt\n",
            "Epoch 51:  11% 98/901 [00:11<01:21,  9.91it/s]Step 22550: loss = 2.3324\n",
            "Epoch 51:  11% 100/901 [00:11<01:19, 10.08it/s]Step 22550: loss = 2.3322\n",
            "Epoch 51:  22% 198/901 [00:22<01:24,  8.29it/s]Step 22600: loss = 2.3195\n",
            "Epoch 51:  22% 200/901 [00:22<01:15,  9.26it/s]Step 22600: loss = 2.3200\n",
            "Epoch 51:  33% 298/901 [00:34<01:20,  7.45it/s]Step 22650: loss = 2.2661\n",
            "Epoch 51:  33% 300/901 [00:34<01:10,  8.56it/s]Step 22650: loss = 2.2683\n",
            "Epoch 51:  44% 399/901 [00:45<01:00,  8.35it/s]Step 22700: loss = 2.2797\n",
            "Epoch 51:  44% 400/901 [00:45<00:59,  8.49it/s]Step 22700: loss = 2.2793\n",
            "Epoch 51:  55% 499/901 [00:57<00:43,  9.31it/s]Step 22750: loss = 2.2734\n",
            "Epoch 51:  55% 500/901 [00:57<00:44,  9.01it/s]Step 22750: loss = 2.2746\n",
            "Epoch 51:  66% 598/901 [01:08<00:34,  8.70it/s]Step 22800: loss = 2.2737\n",
            "Epoch 51:  67% 600/901 [01:09<00:35,  8.55it/s]Step 22800: loss = 2.2745\n",
            "Epoch 51:  78% 699/901 [01:20<00:22,  9.15it/s]Step 22850: loss = 2.2717\n",
            "Epoch 51:  78% 700/901 [01:20<00:36,  5.50it/s]Step 22850: loss = 2.2724\n",
            "Epoch 51:  89% 798/901 [01:32<00:12,  8.22it/s]Step 22900: loss = 2.2652\n",
            "Epoch 51:  89% 800/901 [01:32<00:11,  8.81it/s]Step 22900: loss = 2.2641\n",
            "Epoch 51: 100% 899/901 [01:44<00:00,  6.99it/s]Step 22950: loss = 2.2532\n",
            "Epoch 51: 100% 900/901 [01:44<00:00,  7.24it/s]Step 22950: loss = 2.2537\n",
            "Epoch 51: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 51 completed. Average training loss: 2.2537\n",
            "Validation loss after epoch 51: 2.4428\n",
            "Checkpoint saved -> checkpoints/model_epoch_51.pt\n",
            "Epoch 52:   0% 0/901 [00:00<?, ?it/s]Step 22950: loss = 2.2101\n",
            "Epoch 52:  11% 99/901 [00:11<01:37,  8.18it/s]Step 23000: loss = 2.2282\n",
            "Checkpoint saved -> checkpoints/model_step_23000.pt\n",
            "Epoch 52:  11% 100/901 [00:12<03:22,  3.95it/s]Step 23000: loss = 2.2287\n",
            "Checkpoint saved -> checkpoints/model_step_23000.pt\n",
            "Epoch 52:  22% 199/901 [00:24<01:15,  9.35it/s]Step 23050: loss = 2.2402\n",
            "Epoch 52:  22% 200/901 [00:24<01:18,  8.96it/s]Step 23050: loss = 2.2404\n",
            "Epoch 52:  33% 298/901 [00:35<00:59, 10.19it/s]Step 23100: loss = 2.2497\n",
            "Epoch 52:  33% 300/901 [00:35<00:57, 10.37it/s]Step 23100: loss = 2.2512\n",
            "Epoch 52:  44% 399/901 [00:47<00:58,  8.62it/s]Step 23150: loss = 2.2432\n",
            "Epoch 52:  44% 400/901 [00:47<00:56,  8.80it/s]Step 23150: loss = 2.2437\n",
            "Epoch 52:  55% 498/901 [00:59<00:48,  8.37it/s]Step 23200: loss = 2.2453\n",
            "Epoch 52:  55% 500/901 [00:59<00:46,  8.71it/s]Step 23200: loss = 2.2464\n",
            "Epoch 52:  66% 598/901 [01:10<00:33,  9.11it/s]Step 23250: loss = 2.2535\n",
            "Epoch 52:  67% 600/901 [01:10<00:32,  9.24it/s]Step 23250: loss = 2.2540\n",
            "Epoch 52:  78% 699/901 [01:22<00:23,  8.60it/s]Step 23300: loss = 2.2459\n",
            "Epoch 52:  78% 700/901 [01:22<00:22,  8.76it/s]Step 23300: loss = 2.2455\n",
            "Epoch 52:  89% 798/901 [01:33<00:12,  8.02it/s]Step 23350: loss = 2.2462\n",
            "Epoch 52:  89% 800/901 [01:33<00:11,  8.84it/s]Step 23350: loss = 2.2461\n",
            "Epoch 52: 100% 898/901 [01:45<00:00,  8.19it/s]Step 23400: loss = 2.2504\n",
            "Epoch 52: 100% 900/901 [01:45<00:00,  8.99it/s]Step 23400: loss = 2.2506\n",
            "Epoch 52: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 52 completed. Average training loss: 2.2506\n",
            "Validation loss after epoch 52: 2.4406\n",
            "Checkpoint saved -> checkpoints/model_epoch_52.pt\n",
            "Epoch 53:   0% 0/901 [00:00<?, ?it/s]Step 23400: loss = 2.5563\n",
            "Epoch 53:  11% 98/901 [00:11<01:18, 10.23it/s]Step 23450: loss = 2.2653\n",
            "Epoch 53:  11% 100/901 [00:11<01:22,  9.68it/s]Step 23450: loss = 2.2673\n",
            "Epoch 53:  22% 198/901 [00:22<01:22,  8.53it/s]Step 23500: loss = 2.2660\n",
            "Checkpoint saved -> checkpoints/model_step_23500.pt\n",
            "Epoch 53:  22% 200/901 [00:23<02:29,  4.69it/s]Step 23500: loss = 2.2663\n",
            "Checkpoint saved -> checkpoints/model_step_23500.pt\n",
            "Epoch 53:  33% 299/901 [00:35<01:16,  7.91it/s]Step 23550: loss = 2.2527\n",
            "Epoch 53:  33% 300/901 [00:35<01:17,  7.76it/s]Step 23550: loss = 2.2523\n",
            "Epoch 53:  44% 398/901 [00:46<00:56,  8.91it/s]Step 23600: loss = 2.2576\n",
            "Epoch 53:  44% 400/901 [00:46<00:55,  9.06it/s]Step 23600: loss = 2.2577\n",
            "Epoch 53:  55% 499/901 [00:58<00:48,  8.31it/s]Step 23650: loss = 2.2436\n",
            "Epoch 53:  55% 500/901 [00:58<00:48,  8.35it/s]Step 23650: loss = 2.2443\n",
            "Epoch 53:  66% 599/901 [01:09<00:33,  8.93it/s]Step 23700: loss = 2.2503\n",
            "Step 23700: loss = 2.2497\n",
            "Epoch 53:  77% 698/901 [01:21<00:22,  8.85it/s]Step 23750: loss = 2.2550\n",
            "Epoch 53:  78% 700/901 [01:21<00:21,  9.48it/s]Step 23750: loss = 2.2548\n",
            "Epoch 53:  89% 799/901 [01:33<00:14,  7.27it/s]Step 23800: loss = 2.2507\n",
            "Step 23800: loss = 2.2508\n",
            "Epoch 53: 100% 898/901 [01:45<00:00,  8.95it/s]Step 23850: loss = 2.2475\n",
            "Epoch 53: 100% 900/901 [01:45<00:00,  8.21it/s]Step 23850: loss = 2.2476\n",
            "Epoch 53: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 53 completed. Average training loss: 2.2476\n",
            "Validation loss after epoch 53: 2.4386\n",
            "Checkpoint saved -> checkpoints/model_epoch_53.pt\n",
            "Epoch 54:   0% 0/901 [00:00<?, ?it/s]Step 23850: loss = 2.3237\n",
            "Epoch 54:  11% 98/901 [00:11<01:28,  9.10it/s]Step 23900: loss = 2.2619\n",
            "Epoch 54:  11% 100/901 [00:11<01:53,  7.07it/s]Step 23900: loss = 2.2655\n",
            "Epoch 54:  22% 198/901 [00:23<01:13,  9.55it/s]Step 23950: loss = 2.2678\n",
            "Epoch 54:  22% 200/901 [00:23<01:13,  9.53it/s]Step 23950: loss = 2.2682\n",
            "Epoch 54:  33% 299/901 [00:35<01:11,  8.41it/s]Step 24000: loss = 2.2534\n",
            "Checkpoint saved -> checkpoints/model_step_24000.pt\n",
            "Epoch 54:  33% 300/901 [00:35<02:36,  3.84it/s]Step 24000: loss = 2.2510\n",
            "Checkpoint saved -> checkpoints/model_step_24000.pt\n",
            "Epoch 54:  44% 399/901 [00:47<01:03,  7.96it/s]Step 24050: loss = 2.2524\n",
            "Epoch 54:  44% 400/901 [00:47<01:02,  8.04it/s]Step 24050: loss = 2.2524\n",
            "Epoch 54:  55% 499/901 [00:59<00:45,  8.90it/s]Step 24100: loss = 2.2393\n",
            "Epoch 54:  55% 500/901 [00:59<00:46,  8.60it/s]Step 24100: loss = 2.2402\n",
            "Epoch 54:  66% 599/901 [01:11<00:36,  8.38it/s]Step 24150: loss = 2.2410\n",
            "Epoch 54:  67% 600/901 [01:11<00:38,  7.84it/s]Step 24150: loss = 2.2410\n",
            "Epoch 54:  78% 699/901 [01:22<00:24,  8.13it/s]Step 24200: loss = 2.2400\n",
            "Step 24200: loss = 2.2407\n",
            "Epoch 54:  89% 799/901 [01:34<00:11,  8.77it/s]Step 24250: loss = 2.2382\n",
            "Epoch 54:  89% 800/901 [01:34<00:11,  8.64it/s]Step 24250: loss = 2.2374\n",
            "Epoch 54: 100% 898/901 [01:45<00:00, 10.41it/s]Step 24300: loss = 2.2391\n",
            "Epoch 54: 100% 900/901 [01:45<00:00,  9.70it/s]Step 24300: loss = 2.2395\n",
            "Epoch 54: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 54 completed. Average training loss: 2.2395\n",
            "Validation loss after epoch 54: 2.4365\n",
            "Checkpoint saved -> checkpoints/model_epoch_54.pt\n",
            "Epoch 55:   0% 0/901 [00:00<?, ?it/s]Step 24300: loss = 2.6615\n",
            "Epoch 55:  11% 99/901 [00:10<01:23,  9.57it/s]Step 24350: loss = 2.3085\n",
            "Epoch 55:  11% 100/901 [00:11<01:25,  9.38it/s]Step 24350: loss = 2.3044\n",
            "Epoch 55:  22% 199/901 [00:22<01:13,  9.52it/s]Step 24400: loss = 2.2743\n",
            "Epoch 55:  22% 200/901 [00:22<01:13,  9.50it/s]Step 24400: loss = 2.2757\n",
            "Epoch 55:  33% 298/901 [00:33<01:14,  8.09it/s]Step 24450: loss = 2.2622\n",
            "Epoch 55:  33% 300/901 [00:33<01:08,  8.72it/s]Step 24450: loss = 2.2631\n",
            "Epoch 55:  44% 399/901 [00:45<01:10,  7.08it/s]Step 24500: loss = 2.2360\n",
            "Checkpoint saved -> checkpoints/model_step_24500.pt\n",
            "Epoch 55:  44% 400/901 [00:46<02:08,  3.91it/s]Step 24500: loss = 2.2346\n",
            "Checkpoint saved -> checkpoints/model_step_24500.pt\n",
            "Epoch 55:  55% 499/901 [00:59<00:45,  8.81it/s]Step 24550: loss = 2.2226\n",
            "Epoch 55:  55% 500/901 [00:59<00:45,  8.90it/s]Step 24550: loss = 2.2220\n",
            "Epoch 55:  66% 598/901 [01:10<00:33,  8.98it/s]Step 24600: loss = 2.2271\n",
            "Epoch 55:  67% 600/901 [01:10<00:30,  9.86it/s]Step 24600: loss = 2.2273\n",
            "Epoch 55:  77% 698/901 [01:21<00:22,  8.97it/s]Step 24650: loss = 2.2370\n",
            "Epoch 55:  78% 700/901 [01:21<00:22,  9.13it/s]Step 24650: loss = 2.2380\n",
            "Epoch 55:  89% 798/901 [01:32<00:13,  7.87it/s]Step 24700: loss = 2.2500\n",
            "Epoch 55:  89% 800/901 [01:32<00:11,  8.69it/s]Step 24700: loss = 2.2496\n",
            "Epoch 55: 100% 898/901 [01:45<00:00,  8.36it/s]Step 24750: loss = 2.2334\n",
            "Epoch 55: 100% 900/901 [01:45<00:00,  8.89it/s]Step 24750: loss = 2.2333\n",
            "Epoch 55: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 55 completed. Average training loss: 2.2333\n",
            "Validation loss after epoch 55: 2.4345\n",
            "Checkpoint saved -> checkpoints/model_epoch_55.pt\n",
            "Epoch 56:   0% 0/901 [00:00<?, ?it/s]Step 24750: loss = 1.7863\n",
            "Epoch 56:  11% 98/901 [00:10<01:35,  8.37it/s]Step 24800: loss = 2.3094\n",
            "Epoch 56:  11% 100/901 [00:11<01:43,  7.75it/s]Step 24800: loss = 2.3100\n",
            "Epoch 56:  22% 198/901 [00:22<01:14,  9.40it/s]Step 24850: loss = 2.2768\n",
            "Epoch 56:  22% 200/901 [00:22<01:18,  8.94it/s]Step 24850: loss = 2.2719\n",
            "Epoch 56:  33% 299/901 [00:33<01:06,  9.11it/s]Step 24900: loss = 2.2744\n",
            "Epoch 56:  33% 300/901 [00:34<01:11,  8.38it/s]Step 24900: loss = 2.2752\n",
            "Epoch 56:  44% 399/901 [00:45<00:52,  9.55it/s]Step 24950: loss = 2.2670\n",
            "Epoch 56:  44% 400/901 [00:45<00:56,  8.91it/s]Step 24950: loss = 2.2667\n",
            "Epoch 56:  55% 498/901 [00:56<00:50,  8.03it/s]Step 25000: loss = 2.2577\n",
            "Checkpoint saved -> checkpoints/model_step_25000.pt\n",
            "Epoch 56:  55% 500/901 [00:57<01:29,  4.46it/s]Step 25000: loss = 2.2572\n",
            "Checkpoint saved -> checkpoints/model_step_25000.pt\n",
            "Epoch 56:  66% 599/901 [01:09<00:32,  9.32it/s]Step 25050: loss = 2.2637\n",
            "Epoch 56:  67% 600/901 [01:09<00:33,  8.86it/s]Step 25050: loss = 2.2620\n",
            "Epoch 56:  78% 699/901 [01:21<00:22,  8.80it/s]Step 25100: loss = 2.2582\n",
            "Epoch 56:  78% 700/901 [01:21<00:23,  8.46it/s]Step 25100: loss = 2.2583\n",
            "Epoch 56:  89% 798/901 [01:32<00:10,  9.94it/s]Step 25150: loss = 2.2556\n",
            "Epoch 56:  89% 800/901 [01:32<00:09, 10.37it/s]Step 25150: loss = 2.2560\n",
            "Epoch 56: 100% 899/901 [01:44<00:00,  8.15it/s]Step 25200: loss = 2.2440\n",
            "Epoch 56: 100% 900/901 [01:45<00:00,  8.48it/s]Step 25200: loss = 2.2444\n",
            "Epoch 56: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 56 completed. Average training loss: 2.2444\n",
            "Validation loss after epoch 56: 2.4325\n",
            "Checkpoint saved -> checkpoints/model_epoch_56.pt\n",
            "Epoch 57:   0% 0/901 [00:00<?, ?it/s]Step 25200: loss = 2.5754\n",
            "Epoch 57:  11% 98/901 [00:11<01:31,  8.82it/s]Step 25250: loss = 2.2634\n",
            "Epoch 57:  11% 100/901 [00:11<01:24,  9.50it/s]Step 25250: loss = 2.2583\n",
            "Epoch 57:  22% 198/901 [00:22<01:12,  9.65it/s]Step 25300: loss = 2.2491\n",
            "Epoch 57:  22% 200/901 [00:22<01:10,  9.91it/s]Step 25300: loss = 2.2500\n",
            "Epoch 57:  33% 299/901 [00:34<01:14,  8.07it/s]Step 25350: loss = 2.2367\n",
            "Epoch 57:  33% 300/901 [00:34<01:17,  7.80it/s]Step 25350: loss = 2.2362\n",
            "Epoch 57:  44% 399/901 [00:46<00:59,  8.50it/s]Step 25400: loss = 2.2356\n",
            "Epoch 57:  44% 400/901 [00:46<01:03,  7.85it/s]Step 25400: loss = 2.2371\n",
            "Epoch 57:  55% 498/901 [00:57<00:40, 10.00it/s]Step 25450: loss = 2.2494\n",
            "Epoch 57:  55% 500/901 [00:58<00:49,  8.15it/s]Step 25450: loss = 2.2507\n",
            "Epoch 57:  66% 598/901 [01:09<00:37,  8.12it/s]Step 25500: loss = 2.2515\n",
            "Checkpoint saved -> checkpoints/model_step_25500.pt\n",
            "Epoch 57:  67% 600/901 [01:09<01:03,  4.75it/s]Step 25500: loss = 2.2518\n",
            "Checkpoint saved -> checkpoints/model_step_25500.pt\n",
            "Epoch 57:  78% 699/901 [01:21<00:21,  9.60it/s]Step 25550: loss = 2.2497\n",
            "Epoch 57:  78% 700/901 [01:21<00:22,  9.13it/s]Step 25550: loss = 2.2501\n",
            "Epoch 57:  89% 798/901 [01:33<00:13,  7.73it/s]Step 25600: loss = 2.2410\n",
            "Epoch 57:  89% 800/901 [01:33<00:11,  8.48it/s]Step 25600: loss = 2.2410\n",
            "Epoch 57: 100% 899/901 [01:45<00:00,  8.38it/s]Step 25650: loss = 2.2416\n",
            "Epoch 57: 100% 900/901 [01:45<00:00,  7.99it/s]Step 25650: loss = 2.2410\n",
            "Epoch 57: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 57 completed. Average training loss: 2.2410\n",
            "Validation loss after epoch 57: 2.4306\n",
            "Checkpoint saved -> checkpoints/model_epoch_57.pt\n",
            "Epoch 58:   0% 0/901 [00:00<?, ?it/s]Step 25650: loss = 2.1180\n",
            "Epoch 58:  11% 98/901 [00:11<01:24,  9.47it/s]Step 25700: loss = 2.2573\n",
            "Epoch 58:  11% 100/901 [00:11<01:25,  9.40it/s]Step 25700: loss = 2.2568\n",
            "Epoch 58:  22% 198/901 [00:23<01:12,  9.65it/s]Step 25750: loss = 2.2385\n",
            "Epoch 58:  22% 200/901 [00:23<01:14,  9.36it/s]Step 25750: loss = 2.2376\n",
            "Epoch 58:  33% 299/901 [00:34<01:10,  8.57it/s]Step 25800: loss = 2.2511\n",
            "Step 25800: loss = 2.2526\n",
            "Epoch 58:  44% 398/901 [00:46<00:54,  9.24it/s]Step 25850: loss = 2.2377\n",
            "Epoch 58:  44% 400/901 [00:46<00:53,  9.39it/s]Step 25850: loss = 2.2370\n",
            "Epoch 58:  55% 498/901 [00:57<00:40,  9.86it/s]Step 25900: loss = 2.2354\n",
            "Epoch 58:  55% 500/901 [00:58<00:43,  9.26it/s]Step 25900: loss = 2.2349\n",
            "Epoch 58:  66% 598/901 [01:09<00:36,  8.31it/s]Step 25950: loss = 2.2392\n",
            "Epoch 58:  67% 600/901 [01:09<00:34,  8.77it/s]Step 25950: loss = 2.2387\n",
            "Epoch 58:  78% 699/901 [01:21<00:22,  8.86it/s]Step 26000: loss = 2.2386\n",
            "Checkpoint saved -> checkpoints/model_step_26000.pt\n",
            "Epoch 58:  78% 700/901 [01:21<00:49,  4.06it/s]Step 26000: loss = 2.2388\n",
            "Checkpoint saved -> checkpoints/model_step_26000.pt\n",
            "Epoch 58:  89% 798/901 [01:33<00:12,  8.44it/s]Step 26050: loss = 2.2358\n",
            "Epoch 58:  89% 800/901 [01:33<00:11,  9.00it/s]Step 26050: loss = 2.2355\n",
            "Epoch 58: 100% 899/901 [01:45<00:00,  8.20it/s]Step 26100: loss = 2.2339\n",
            "Epoch 58: 100% 900/901 [01:45<00:00,  7.86it/s]Step 26100: loss = 2.2339\n",
            "Epoch 58: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 58 completed. Average training loss: 2.2339\n",
            "Validation loss after epoch 58: 2.4287\n",
            "Checkpoint saved -> checkpoints/model_epoch_58.pt\n",
            "Epoch 59:   0% 0/901 [00:00<?, ?it/s]Step 26100: loss = 2.5264\n",
            "Epoch 59:  11% 98/901 [00:11<01:32,  8.66it/s]Step 26150: loss = 2.2457\n",
            "Epoch 59:  11% 100/901 [00:11<01:27,  9.17it/s]Step 26150: loss = 2.2420\n",
            "Epoch 59:  22% 198/901 [00:22<01:14,  9.49it/s]Step 26200: loss = 2.2760\n",
            "Epoch 59:  22% 200/901 [00:22<01:14,  9.38it/s]Step 26200: loss = 2.2782\n",
            "Epoch 59:  33% 298/901 [00:34<01:11,  8.41it/s]Step 26250: loss = 2.2637\n",
            "Epoch 59:  33% 300/901 [00:34<01:08,  8.73it/s]Step 26250: loss = 2.2626\n",
            "Epoch 59:  44% 399/901 [00:46<00:55,  9.00it/s]Step 26300: loss = 2.2531\n",
            "Epoch 59:  44% 400/901 [00:46<00:54,  9.22it/s]Step 26300: loss = 2.2540\n",
            "Epoch 59:  55% 499/901 [00:57<00:46,  8.72it/s]Step 26350: loss = 2.2532\n",
            "Epoch 59:  55% 500/901 [00:57<00:45,  8.76it/s]Step 26350: loss = 2.2536\n",
            "Epoch 59:  66% 598/901 [01:08<00:29, 10.12it/s]Step 26400: loss = 2.2556\n",
            "Epoch 59:  67% 600/901 [01:08<00:29, 10.28it/s]Step 26400: loss = 2.2556\n",
            "Epoch 59:  77% 698/901 [01:20<00:26,  7.75it/s]Step 26450: loss = 2.2455\n",
            "Epoch 59:  78% 700/901 [01:20<00:24,  8.10it/s]Step 26450: loss = 2.2462\n",
            "Epoch 59:  89% 798/901 [01:32<00:11,  8.88it/s]Step 26500: loss = 2.2424\n",
            "Checkpoint saved -> checkpoints/model_step_26500.pt\n",
            "Epoch 59:  89% 800/901 [01:32<00:19,  5.16it/s]Step 26500: loss = 2.2411\n",
            "Checkpoint saved -> checkpoints/model_step_26500.pt\n",
            "Epoch 59: 100% 899/901 [01:45<00:00,  8.68it/s]Step 26550: loss = 2.2338\n",
            "Epoch 59: 100% 900/901 [01:45<00:00,  8.33it/s]Step 26550: loss = 2.2344\n",
            "Epoch 59: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 59 completed. Average training loss: 2.2344\n",
            "Validation loss after epoch 59: 2.4269\n",
            "Checkpoint saved -> checkpoints/model_epoch_59.pt\n",
            "Epoch 60:   0% 0/901 [00:00<?, ?it/s]Step 26550: loss = 2.8329\n",
            "Epoch 60:  11% 99/901 [00:11<01:28,  9.04it/s]Step 26600: loss = 2.2257\n",
            "Epoch 60:  11% 100/901 [00:11<01:33,  8.55it/s]Step 26600: loss = 2.2212\n",
            "Epoch 60:  22% 199/901 [00:23<01:14,  9.48it/s]Step 26650: loss = 2.2292\n",
            "Step 26650: loss = 2.2257\n",
            "Epoch 60:  33% 298/901 [00:34<01:15,  7.95it/s]Step 26700: loss = 2.2499\n",
            "Epoch 60:  33% 300/901 [00:34<01:11,  8.38it/s]Step 26700: loss = 2.2482\n",
            "Epoch 60:  44% 399/901 [00:46<01:14,  6.73it/s]Step 26750: loss = 2.2435\n",
            "Epoch 60:  44% 400/901 [00:46<01:11,  6.96it/s]Step 26750: loss = 2.2430\n",
            "Epoch 60:  55% 498/901 [00:57<00:48,  8.38it/s]Step 26800: loss = 2.2581\n",
            "Epoch 60:  55% 500/901 [00:57<00:47,  8.45it/s]Step 26800: loss = 2.2581\n",
            "Epoch 60:  66% 598/901 [01:09<00:33,  8.94it/s]Step 26850: loss = 2.2388\n",
            "Epoch 60:  67% 600/901 [01:09<00:32,  9.21it/s]Step 26850: loss = 2.2396\n",
            "Epoch 60:  77% 698/901 [01:20<00:29,  6.77it/s]Step 26900: loss = 2.2400\n",
            "Epoch 60:  78% 700/901 [01:20<00:25,  7.79it/s]Step 26900: loss = 2.2402\n",
            "Epoch 60:  89% 799/901 [01:32<00:11,  8.98it/s]Step 26950: loss = 2.2430\n",
            "Step 26950: loss = 2.2435\n",
            "Epoch 60: 100% 899/901 [01:43<00:00,  9.51it/s]Step 27000: loss = 2.2389\n",
            "Checkpoint saved -> checkpoints/model_step_27000.pt\n",
            "Epoch 60: 100% 900/901 [01:44<00:00,  4.44it/s]Step 27000: loss = 2.2387\n",
            "Checkpoint saved -> checkpoints/model_step_27000.pt\n",
            "Epoch 60: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 60 completed. Average training loss: 2.2387\n",
            "Validation loss after epoch 60: 2.4251\n",
            "Checkpoint saved -> checkpoints/model_epoch_60.pt\n",
            "Epoch 61:   0% 0/901 [00:00<?, ?it/s]Step 27000: loss = 2.4065\n",
            "Checkpoint saved -> checkpoints/model_step_27000.pt\n",
            "Epoch 61:  11% 99/901 [00:12<01:27,  9.12it/s]Step 27050: loss = 2.2586\n",
            "Epoch 61:  11% 100/901 [00:12<01:27,  9.16it/s]Step 27050: loss = 2.2505\n",
            "Epoch 61:  22% 198/901 [00:23<01:36,  7.31it/s]Step 27100: loss = 2.2775\n",
            "Epoch 61:  22% 200/901 [00:23<01:21,  8.56it/s]Step 27100: loss = 2.2749\n",
            "Epoch 61:  33% 299/901 [00:35<01:45,  5.73it/s]Step 27150: loss = 2.2357\n",
            "Epoch 61:  33% 300/901 [00:35<01:47,  5.60it/s]Step 27150: loss = 2.2374\n",
            "Epoch 61:  44% 398/901 [00:46<00:59,  8.52it/s]Step 27200: loss = 2.2400\n",
            "Epoch 61:  44% 400/901 [00:46<00:54,  9.21it/s]Step 27200: loss = 2.2403\n",
            "Epoch 61:  55% 499/901 [00:58<00:42,  9.45it/s]Step 27250: loss = 2.2256\n",
            "Epoch 61:  55% 500/901 [00:58<00:45,  8.77it/s]Step 27250: loss = 2.2242\n",
            "Epoch 61:  66% 599/901 [01:09<00:32,  9.32it/s]Step 27300: loss = 2.2313\n",
            "Epoch 61:  67% 600/901 [01:09<00:32,  9.17it/s]Step 27300: loss = 2.2319\n",
            "Epoch 61:  77% 698/901 [01:21<00:23,  8.52it/s]Step 27350: loss = 2.2314\n",
            "Epoch 61:  78% 700/901 [01:21<00:22,  9.10it/s]Step 27350: loss = 2.2307\n",
            "Epoch 61:  89% 798/901 [01:32<00:11,  8.80it/s]Step 27400: loss = 2.2295\n",
            "Epoch 61:  89% 800/901 [01:32<00:10,  9.32it/s]Step 27400: loss = 2.2294\n",
            "Epoch 61: 100% 898/901 [01:44<00:00,  8.69it/s]Step 27450: loss = 2.2234\n",
            "Epoch 61: 100% 900/901 [01:44<00:00,  9.03it/s]Step 27450: loss = 2.2231\n",
            "Epoch 61: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 61 completed. Average training loss: 2.2231\n",
            "Validation loss after epoch 61: 2.4233\n",
            "Checkpoint saved -> checkpoints/model_epoch_61.pt\n",
            "Epoch 62:   0% 0/901 [00:00<?, ?it/s]Step 27450: loss = 1.8499\n",
            "Epoch 62:  11% 98/901 [00:11<01:37,  8.28it/s]Step 27500: loss = 2.2080\n",
            "Checkpoint saved -> checkpoints/model_step_27500.pt\n",
            "Epoch 62:  11% 100/901 [00:12<03:08,  4.26it/s]Step 27500: loss = 2.2122\n",
            "Checkpoint saved -> checkpoints/model_step_27500.pt\n",
            "Epoch 62:  22% 198/901 [00:24<01:22,  8.49it/s]Step 27550: loss = 2.2140\n",
            "Epoch 62:  22% 200/901 [00:24<01:21,  8.58it/s]Step 27550: loss = 2.2122\n",
            "Epoch 62:  33% 299/901 [00:35<01:04,  9.35it/s]Step 27600: loss = 2.2336\n",
            "Epoch 62:  33% 300/901 [00:36<01:05,  9.12it/s]Step 27600: loss = 2.2354\n",
            "Epoch 62:  44% 398/901 [00:47<00:58,  8.59it/s]Step 27650: loss = 2.2431\n",
            "Epoch 62:  44% 400/901 [00:47<01:02,  8.00it/s]Step 27650: loss = 2.2427\n",
            "Epoch 62:  55% 499/901 [00:58<00:41,  9.60it/s]Step 27700: loss = 2.2556\n",
            "Step 27700: loss = 2.2550\n",
            "Epoch 62:  66% 598/901 [01:10<00:38,  7.86it/s]Step 27750: loss = 2.2358\n",
            "Epoch 62:  67% 600/901 [01:10<00:34,  8.71it/s]Step 27750: loss = 2.2364\n",
            "Epoch 62:  77% 698/901 [01:21<00:23,  8.59it/s]Step 27800: loss = 2.2319\n",
            "Epoch 62:  78% 700/901 [01:21<00:22,  9.05it/s]Step 27800: loss = 2.2321\n",
            "Epoch 62:  89% 798/901 [01:33<00:11,  8.82it/s]Step 27850: loss = 2.2356\n",
            "Epoch 62:  89% 800/901 [01:33<00:10,  9.31it/s]Step 27850: loss = 2.2356\n",
            "Epoch 62: 100% 898/901 [01:44<00:00,  7.42it/s]Step 27900: loss = 2.2400\n",
            "Epoch 62: 100% 900/901 [01:44<00:00,  8.28it/s]Step 27900: loss = 2.2409\n",
            "Epoch 62: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 62 completed. Average training loss: 2.2409\n",
            "Validation loss after epoch 62: 2.4216\n",
            "Checkpoint saved -> checkpoints/model_epoch_62.pt\n",
            "Epoch 63:   0% 0/901 [00:00<?, ?it/s]Step 27900: loss = 2.1189\n",
            "Epoch 63:  11% 98/901 [00:11<01:37,  8.27it/s]Step 27950: loss = 2.2614\n",
            "Epoch 63:  11% 100/901 [00:11<01:32,  8.65it/s]Step 27950: loss = 2.2506\n",
            "Epoch 63:  22% 199/901 [00:22<01:32,  7.58it/s]Step 28000: loss = 2.2532\n",
            "Checkpoint saved -> checkpoints/model_step_28000.pt\n",
            "Epoch 63:  22% 200/901 [00:23<03:02,  3.83it/s]Step 28000: loss = 2.2502\n",
            "Checkpoint saved -> checkpoints/model_step_28000.pt\n",
            "Epoch 63:  33% 299/901 [00:35<01:09,  8.68it/s]Step 28050: loss = 2.2426\n",
            "Step 28050: loss = 2.2429\n",
            "Epoch 63:  44% 398/901 [00:47<00:56,  8.94it/s]Step 28100: loss = 2.2286\n",
            "Epoch 63:  44% 400/901 [00:47<00:54,  9.22it/s]Step 28100: loss = 2.2290\n",
            "Epoch 63:  55% 498/901 [00:58<00:47,  8.41it/s]Step 28150: loss = 2.2224\n",
            "Epoch 63:  55% 500/901 [00:59<00:44,  8.94it/s]Step 28150: loss = 2.2239\n",
            "Epoch 63:  66% 598/901 [01:10<00:33,  8.98it/s]Step 28200: loss = 2.2255\n",
            "Epoch 63:  67% 600/901 [01:10<00:32,  9.37it/s]Step 28200: loss = 2.2252\n",
            "Epoch 63:  77% 698/901 [01:21<00:20,  9.83it/s]Step 28250: loss = 2.2282\n",
            "Epoch 63:  78% 700/901 [01:22<00:20,  9.90it/s]Step 28250: loss = 2.2288\n",
            "Epoch 63:  89% 798/901 [01:33<00:12,  8.14it/s]Step 28300: loss = 2.2254\n",
            "Epoch 63:  89% 800/901 [01:33<00:11,  8.52it/s]Step 28300: loss = 2.2252\n",
            "Epoch 63: 100% 898/901 [01:45<00:00,  8.66it/s]Step 28350: loss = 2.2210\n",
            "Epoch 63: 100% 900/901 [01:45<00:00,  9.37it/s]Step 28350: loss = 2.2203\n",
            "Epoch 63: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 63 completed. Average training loss: 2.2203\n",
            "Validation loss after epoch 63: 2.4198\n",
            "Checkpoint saved -> checkpoints/model_epoch_63.pt\n",
            "Epoch 64:   0% 0/901 [00:00<?, ?it/s]Step 28350: loss = 2.2377\n",
            "Epoch 64:  11% 99/901 [00:11<01:30,  8.86it/s]Step 28400: loss = 2.2473\n",
            "Epoch 64:  11% 100/901 [00:11<01:31,  8.76it/s]Step 28400: loss = 2.2537\n",
            "Epoch 64:  22% 199/901 [00:22<01:19,  8.81it/s]Step 28450: loss = 2.2310\n",
            "Epoch 64:  22% 200/901 [00:22<01:30,  7.74it/s]Step 28450: loss = 2.2280\n",
            "Epoch 64:  33% 298/901 [00:34<01:10,  8.58it/s]Step 28500: loss = 2.2467\n",
            "Checkpoint saved -> checkpoints/model_step_28500.pt\n",
            "Epoch 64:  33% 300/901 [00:34<02:09,  4.63it/s]Step 28500: loss = 2.2495\n",
            "Checkpoint saved -> checkpoints/model_step_28500.pt\n",
            "Epoch 64:  44% 398/901 [00:46<00:58,  8.56it/s]Step 28550: loss = 2.2475\n",
            "Epoch 64:  44% 400/901 [00:46<00:58,  8.52it/s]Step 28550: loss = 2.2479\n",
            "Epoch 64:  55% 498/901 [00:58<00:48,  8.25it/s]Step 28600: loss = 2.2489\n",
            "Epoch 64:  55% 500/901 [00:58<00:46,  8.64it/s]Step 28600: loss = 2.2483\n",
            "Epoch 64:  66% 599/901 [01:09<00:36,  8.35it/s]Step 28650: loss = 2.2533\n",
            "Epoch 64:  67% 600/901 [01:09<00:43,  6.96it/s]Step 28650: loss = 2.2539\n",
            "Epoch 64:  78% 699/901 [01:21<00:21,  9.23it/s]Step 28700: loss = 2.2461\n",
            "Step 28700: loss = 2.2465\n",
            "Epoch 64:  89% 799/901 [01:33<00:11,  8.68it/s]Step 28750: loss = 2.2433\n",
            "Epoch 64:  89% 800/901 [01:33<00:11,  8.76it/s]Step 28750: loss = 2.2434\n",
            "Epoch 64: 100% 898/901 [01:44<00:00,  8.11it/s]Step 28800: loss = 2.2321\n",
            "Epoch 64: 100% 900/901 [01:44<00:00,  8.28it/s]Step 28800: loss = 2.2316\n",
            "Epoch 64: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 64 completed. Average training loss: 2.2316\n",
            "Validation loss after epoch 64: 2.4181\n",
            "Checkpoint saved -> checkpoints/model_epoch_64.pt\n",
            "Epoch 65:   0% 0/901 [00:00<?, ?it/s]Step 28800: loss = 1.8278\n",
            "Epoch 65:  11% 99/901 [00:11<01:25,  9.36it/s]Step 28850: loss = 2.1623\n",
            "Step 28850: loss = 2.1635\n",
            "Epoch 65:  22% 198/901 [00:23<01:28,  7.90it/s]Step 28900: loss = 2.2041\n",
            "Epoch 65:  22% 200/901 [00:23<01:25,  8.24it/s]Step 28900: loss = 2.2016\n",
            "Epoch 65:  33% 298/901 [00:34<01:03,  9.53it/s]Step 28950: loss = 2.2214\n",
            "Epoch 65:  33% 300/901 [00:34<01:06,  9.01it/s]Step 28950: loss = 2.2213\n",
            "Epoch 65:  44% 399/901 [00:45<00:52,  9.60it/s]Step 29000: loss = 2.2309\n",
            "Checkpoint saved -> checkpoints/model_step_29000.pt\n",
            "Epoch 65:  44% 400/901 [00:46<01:52,  4.47it/s]Step 29000: loss = 2.2300\n",
            "Checkpoint saved -> checkpoints/model_step_29000.pt\n",
            "Epoch 65:  55% 498/901 [00:58<00:46,  8.69it/s]Step 29050: loss = 2.2380\n",
            "Epoch 65:  55% 500/901 [00:58<00:49,  8.06it/s]Step 29050: loss = 2.2376\n",
            "Epoch 65:  66% 598/901 [01:10<00:44,  6.86it/s]Step 29100: loss = 2.2203\n",
            "Epoch 65:  67% 600/901 [01:10<00:38,  7.80it/s]Step 29100: loss = 2.2210\n",
            "Epoch 65:  77% 698/901 [01:21<00:23,  8.56it/s]Step 29150: loss = 2.2272\n",
            "Epoch 65:  78% 700/901 [01:21<00:22,  9.04it/s]Step 29150: loss = 2.2259\n",
            "Epoch 65:  89% 798/901 [01:33<00:12,  8.42it/s]Step 29200: loss = 2.2217\n",
            "Epoch 65:  89% 800/901 [01:33<00:10,  9.56it/s]Step 29200: loss = 2.2214\n",
            "Epoch 65: 100% 899/901 [01:44<00:00,  8.52it/s]Step 29250: loss = 2.2205\n",
            "Epoch 65: 100% 900/901 [01:45<00:00,  5.49it/s]Step 29250: loss = 2.2203\n",
            "Epoch 65: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 65 completed. Average training loss: 2.2203\n",
            "Validation loss after epoch 65: 2.4164\n",
            "Checkpoint saved -> checkpoints/model_epoch_65.pt\n",
            "Epoch 66:   0% 0/901 [00:00<?, ?it/s]Step 29250: loss = 3.0071\n",
            "Epoch 66:  11% 99/901 [00:10<01:32,  8.72it/s]Step 29300: loss = 2.3035\n",
            "Epoch 66:  11% 100/901 [00:11<01:29,  8.96it/s]Step 29300: loss = 2.2999\n",
            "Epoch 66:  22% 199/901 [00:22<01:19,  8.81it/s]Step 29350: loss = 2.2418\n",
            "Step 29350: loss = 2.2414\n",
            "Epoch 66:  33% 298/901 [00:34<01:06,  9.05it/s]Step 29400: loss = 2.2205\n",
            "Epoch 66:  33% 300/901 [00:34<01:04,  9.29it/s]Step 29400: loss = 2.2216\n",
            "Epoch 66:  44% 399/901 [00:46<00:56,  8.92it/s]Step 29450: loss = 2.2206\n",
            "Epoch 66:  44% 400/901 [00:46<01:03,  7.91it/s]Step 29450: loss = 2.2204\n",
            "Epoch 66:  55% 498/901 [00:57<00:43,  9.24it/s]Step 29500: loss = 2.2204\n",
            "Checkpoint saved -> checkpoints/model_step_29500.pt\n",
            "Epoch 66:  55% 500/901 [00:58<01:19,  5.06it/s]Step 29500: loss = 2.2220\n",
            "Checkpoint saved -> checkpoints/model_step_29500.pt\n",
            "Epoch 66:  66% 599/901 [01:10<00:38,  7.82it/s]Step 29550: loss = 2.2143\n",
            "Epoch 66:  67% 600/901 [01:10<00:37,  8.10it/s]Step 29550: loss = 2.2142\n",
            "Epoch 66:  77% 698/901 [01:22<00:23,  8.77it/s]Step 29600: loss = 2.2107\n",
            "Epoch 66:  78% 700/901 [01:22<00:21,  9.21it/s]Step 29600: loss = 2.2114\n",
            "Epoch 66:  89% 798/901 [01:33<00:15,  6.61it/s]Step 29650: loss = 2.2161\n",
            "Epoch 66:  89% 800/901 [01:34<00:13,  7.48it/s]Step 29650: loss = 2.2159\n",
            "Epoch 66: 100% 899/901 [01:45<00:00, 10.18it/s]Step 29700: loss = 2.2199\n",
            "Step 29700: loss = 2.2201\n",
            "Epoch 66: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 66 completed. Average training loss: 2.2201\n",
            "Validation loss after epoch 66: 2.4148\n",
            "Checkpoint saved -> checkpoints/model_epoch_66.pt\n",
            "Epoch 67:   0% 0/901 [00:00<?, ?it/s]Step 29700: loss = 1.5301\n",
            "Epoch 67:  11% 98/901 [00:11<01:31,  8.82it/s]Step 29750: loss = 2.2523\n",
            "Epoch 67:  11% 100/901 [00:11<01:26,  9.21it/s]Step 29750: loss = 2.2528\n",
            "Epoch 67:  22% 199/901 [00:22<01:12,  9.70it/s]Step 29800: loss = 2.2354\n",
            "Step 29800: loss = 2.2341\n",
            "Epoch 67:  33% 299/901 [00:34<01:08,  8.83it/s]Step 29850: loss = 2.2275\n",
            "Epoch 67:  33% 300/901 [00:34<01:16,  7.86it/s]Step 29850: loss = 2.2269\n",
            "Epoch 67:  44% 399/901 [00:46<00:54,  9.14it/s]Step 29900: loss = 2.2149\n",
            "Epoch 67:  44% 400/901 [00:46<01:12,  6.93it/s]Step 29900: loss = 2.2144\n",
            "Epoch 67:  55% 499/901 [00:58<00:44,  9.11it/s]Step 29950: loss = 2.2201\n",
            "Step 29950: loss = 2.2200\n",
            "Epoch 67:  66% 599/901 [01:09<00:40,  7.43it/s]Step 30000: loss = 2.2114\n",
            "Checkpoint saved -> checkpoints/model_step_30000.pt\n",
            "Epoch 67:  67% 600/901 [01:10<01:22,  3.63it/s]Step 30000: loss = 2.2112\n",
            "Checkpoint saved -> checkpoints/model_step_30000.pt\n",
            "Epoch 67:  77% 698/901 [01:22<00:24,  8.26it/s]Step 30050: loss = 2.2101\n",
            "Epoch 67:  78% 700/901 [01:22<00:22,  8.77it/s]Step 30050: loss = 2.2099\n",
            "Epoch 67:  89% 798/901 [01:33<00:11,  9.09it/s]Step 30100: loss = 2.2138\n",
            "Epoch 67:  89% 800/901 [01:34<00:11,  8.84it/s]Step 30100: loss = 2.2131\n",
            "Epoch 67: 100% 898/901 [01:45<00:00,  9.22it/s]Step 30150: loss = 2.2112\n",
            "Epoch 67: 100% 900/901 [01:45<00:00,  9.05it/s]Step 30150: loss = 2.2109\n",
            "Epoch 67: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 67 completed. Average training loss: 2.2109\n",
            "Validation loss after epoch 67: 2.4132\n",
            "Checkpoint saved -> checkpoints/model_epoch_67.pt\n",
            "Epoch 68:   0% 0/901 [00:00<?, ?it/s]Step 30150: loss = 1.8597\n",
            "Epoch 68:  11% 98/901 [00:10<01:34,  8.47it/s]Step 30200: loss = 2.2887\n",
            "Epoch 68:  11% 100/901 [00:11<01:30,  8.89it/s]Step 30200: loss = 2.2916\n",
            "Epoch 68:  22% 198/901 [00:22<01:28,  7.90it/s]Step 30250: loss = 2.2764\n",
            "Epoch 68:  22% 200/901 [00:22<01:19,  8.80it/s]Step 30250: loss = 2.2747\n",
            "Epoch 68:  33% 299/901 [00:33<01:10,  8.55it/s]Step 30300: loss = 2.2680\n",
            "Epoch 68:  33% 300/901 [00:33<01:14,  8.07it/s]Step 30300: loss = 2.2679\n",
            "Epoch 68:  44% 399/901 [00:45<00:55,  9.09it/s]Step 30350: loss = 2.2629\n",
            "Epoch 68:  44% 400/901 [00:45<00:55,  9.10it/s]Step 30350: loss = 2.2632\n",
            "Epoch 68:  55% 498/901 [00:57<00:51,  7.85it/s]Step 30400: loss = 2.2486\n",
            "Epoch 68:  55% 500/901 [00:57<00:48,  8.35it/s]Step 30400: loss = 2.2480\n",
            "Epoch 68:  66% 599/901 [01:09<00:40,  7.43it/s]Step 30450: loss = 2.2388\n",
            "Epoch 68:  67% 600/901 [01:09<00:39,  7.54it/s]Step 30450: loss = 2.2386\n",
            "Epoch 68:  77% 698/901 [01:20<00:24,  8.13it/s]Step 30500: loss = 2.2358\n",
            "Checkpoint saved -> checkpoints/model_step_30500.pt\n",
            "Epoch 68:  78% 700/901 [01:21<00:41,  4.79it/s]Step 30500: loss = 2.2347\n",
            "Checkpoint saved -> checkpoints/model_step_30500.pt\n",
            "Epoch 68:  89% 798/901 [01:33<00:14,  7.16it/s]Step 30550: loss = 2.2294\n",
            "Epoch 68:  89% 800/901 [01:33<00:12,  8.10it/s]Step 30550: loss = 2.2295\n",
            "Epoch 68: 100% 899/901 [01:45<00:00,  8.66it/s]Step 30600: loss = 2.2231\n",
            "Epoch 68: 100% 900/901 [01:45<00:00,  8.52it/s]Step 30600: loss = 2.2224\n",
            "Epoch 68: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 68 completed. Average training loss: 2.2224\n",
            "Validation loss after epoch 68: 2.4116\n",
            "Checkpoint saved -> checkpoints/model_epoch_68.pt\n",
            "Epoch 69:   0% 0/901 [00:00<?, ?it/s]Step 30600: loss = 1.8840\n",
            "Epoch 69:  11% 98/901 [00:11<01:31,  8.81it/s]Step 30650: loss = 2.2346\n",
            "Epoch 69:  11% 100/901 [00:11<01:27,  9.20it/s]Step 30650: loss = 2.2372\n",
            "Epoch 69:  22% 199/901 [00:23<01:09, 10.15it/s]Step 30700: loss = 2.2262\n",
            "Step 30700: loss = 2.2261\n",
            "Epoch 69:  33% 299/901 [00:34<01:14,  8.07it/s]Step 30750: loss = 2.2047\n",
            "Epoch 69:  33% 300/901 [00:35<01:15,  7.93it/s]Step 30750: loss = 2.2057\n",
            "Epoch 69:  44% 398/901 [00:46<00:50,  9.96it/s]Step 30800: loss = 2.2207\n",
            "Epoch 69:  44% 400/901 [00:46<00:51,  9.66it/s]Step 30800: loss = 2.2225\n",
            "Epoch 69:  55% 499/901 [00:57<00:45,  8.78it/s]Step 30850: loss = 2.2267\n",
            "Epoch 69:  55% 500/901 [00:57<00:47,  8.46it/s]Step 30850: loss = 2.2274\n",
            "Epoch 69:  66% 599/901 [01:09<00:37,  8.13it/s]Step 30900: loss = 2.2265\n",
            "Epoch 69:  67% 600/901 [01:09<00:36,  8.16it/s]Step 30900: loss = 2.2254\n",
            "Epoch 69:  77% 698/901 [01:20<00:24,  8.14it/s]Step 30950: loss = 2.2337\n",
            "Epoch 69:  78% 700/901 [01:20<00:22,  9.00it/s]Step 30950: loss = 2.2332\n",
            "Epoch 69:  89% 798/901 [01:31<00:10,  9.91it/s]Step 31000: loss = 2.2369\n",
            "Checkpoint saved -> checkpoints/model_step_31000.pt\n",
            "Epoch 69:  89% 800/901 [01:32<00:18,  5.54it/s]Step 31000: loss = 2.2368\n",
            "Checkpoint saved -> checkpoints/model_step_31000.pt\n",
            "Epoch 69: 100% 899/901 [01:44<00:00,  8.44it/s]Step 31050: loss = 2.2381\n",
            "Epoch 69: 100% 900/901 [01:44<00:00,  7.54it/s]Step 31050: loss = 2.2379\n",
            "Epoch 69: 100% 901/901 [01:44<00:00,  8.62it/s]\n",
            "Epoch 69 completed. Average training loss: 2.2379\n",
            "Validation loss after epoch 69: 2.4100\n",
            "Checkpoint saved -> checkpoints/model_epoch_69.pt\n",
            "Epoch 70:   0% 0/901 [00:00<?, ?it/s]Step 31050: loss = 2.0172\n",
            "Epoch 70:  11% 98/901 [00:11<02:06,  6.34it/s]Step 31100: loss = 2.2059\n",
            "Epoch 70:  11% 100/901 [00:11<01:54,  7.00it/s]Step 31100: loss = 2.2053\n",
            "Epoch 70:  22% 198/901 [00:22<01:30,  7.73it/s]Step 31150: loss = 2.2060\n",
            "Epoch 70:  22% 200/901 [00:23<01:18,  8.90it/s]Step 31150: loss = 2.2103\n",
            "Epoch 70:  33% 299/901 [00:35<01:24,  7.16it/s]Step 31200: loss = 2.1929\n",
            "Epoch 70:  33% 300/901 [00:35<01:22,  7.31it/s]Step 31200: loss = 2.1904\n",
            "Epoch 70:  44% 398/901 [00:46<00:57,  8.79it/s]Step 31250: loss = 2.1966\n",
            "Epoch 70:  44% 400/901 [00:46<00:53,  9.36it/s]Step 31250: loss = 2.1972\n",
            "Epoch 70:  55% 498/901 [00:58<00:44,  9.12it/s]Step 31300: loss = 2.2002\n",
            "Epoch 70:  55% 500/901 [00:58<00:46,  8.66it/s]Step 31300: loss = 2.2019\n",
            "Epoch 70:  66% 599/901 [01:09<00:31,  9.67it/s]Step 31350: loss = 2.2190\n",
            "Epoch 70:  67% 600/901 [01:09<00:34,  8.80it/s]Step 31350: loss = 2.2194\n",
            "Epoch 70:  78% 699/901 [01:20<00:22,  8.82it/s]Step 31400: loss = 2.2294\n",
            "Step 31400: loss = 2.2295\n",
            "Epoch 70:  89% 799/901 [01:32<00:12,  8.42it/s]Step 31450: loss = 2.2230\n",
            "Epoch 70:  89% 800/901 [01:32<00:11,  8.55it/s]Step 31450: loss = 2.2226\n",
            "Epoch 70: 100% 899/901 [01:43<00:00,  7.55it/s]Step 31500: loss = 2.2184\n",
            "Checkpoint saved -> checkpoints/model_step_31500.pt\n",
            "Epoch 70: 100% 900/901 [01:44<00:00,  3.31it/s]Step 31500: loss = 2.2184\n",
            "Checkpoint saved -> checkpoints/model_step_31500.pt\n",
            "Epoch 70: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 70 completed. Average training loss: 2.2184\n",
            "Validation loss after epoch 70: 2.4084\n",
            "Checkpoint saved -> checkpoints/model_epoch_70.pt\n",
            "Epoch 71:   0% 0/901 [00:00<?, ?it/s]Step 31500: loss = 2.2073\n",
            "Checkpoint saved -> checkpoints/model_step_31500.pt\n",
            "Epoch 71:  11% 99/901 [00:12<01:42,  7.83it/s]Step 31550: loss = 2.1551\n",
            "Epoch 71:  11% 100/901 [00:12<01:39,  8.04it/s]Step 31550: loss = 2.1509\n",
            "Epoch 71:  22% 198/901 [00:23<01:07, 10.45it/s]Step 31600: loss = 2.2068\n",
            "Epoch 71:  22% 200/901 [00:24<01:17,  9.08it/s]Step 31600: loss = 2.2074\n",
            "Epoch 71:  33% 298/901 [00:35<01:07,  8.90it/s]Step 31650: loss = 2.2004\n",
            "Epoch 71:  33% 300/901 [00:35<01:03,  9.41it/s]Step 31650: loss = 2.1989\n",
            "Epoch 71:  44% 399/901 [00:47<00:54,  9.18it/s]Step 31700: loss = 2.1833\n",
            "Epoch 71:  44% 400/901 [00:47<01:03,  7.87it/s]Step 31700: loss = 2.1838\n",
            "Epoch 71:  55% 498/901 [00:59<00:48,  8.35it/s]Step 31750: loss = 2.2109\n",
            "Epoch 71:  55% 500/901 [00:59<00:44,  9.03it/s]Step 31750: loss = 2.2105\n",
            "Epoch 71:  66% 598/901 [01:10<00:38,  7.82it/s]Step 31800: loss = 2.2059\n",
            "Epoch 71:  67% 600/901 [01:11<00:43,  6.90it/s]Step 31800: loss = 2.2057\n",
            "Epoch 71:  78% 699/901 [01:22<00:23,  8.72it/s]Step 31850: loss = 2.2109\n",
            "Epoch 71:  78% 700/901 [01:22<00:29,  6.90it/s]Step 31850: loss = 2.2103\n",
            "Epoch 71:  89% 798/901 [01:33<00:10,  9.97it/s]Step 31900: loss = 2.2108\n",
            "Epoch 71:  89% 800/901 [01:33<00:10,  9.75it/s]Step 31900: loss = 2.2118\n",
            "Epoch 71: 100% 898/901 [01:44<00:00,  9.16it/s]Step 31950: loss = 2.2115\n",
            "Epoch 71: 100% 900/901 [01:45<00:00,  9.85it/s]Step 31950: loss = 2.2115\n",
            "Epoch 71: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 71 completed. Average training loss: 2.2115\n",
            "Validation loss after epoch 71: 2.4069\n",
            "Checkpoint saved -> checkpoints/model_epoch_71.pt\n",
            "Epoch 72:   0% 0/901 [00:00<?, ?it/s]Step 31950: loss = 2.2458\n",
            "Epoch 72:  11% 99/901 [00:11<01:50,  7.26it/s]Step 32000: loss = 2.2159\n",
            "Checkpoint saved -> checkpoints/model_step_32000.pt\n",
            "Epoch 72:  11% 100/901 [00:12<03:23,  3.93it/s]Step 32000: loss = 2.2226\n",
            "Checkpoint saved -> checkpoints/model_step_32000.pt\n",
            "Epoch 72:  22% 199/901 [00:24<01:13,  9.56it/s]Step 32050: loss = 2.2262\n",
            "Epoch 72:  22% 200/901 [00:24<01:13,  9.58it/s]Step 32050: loss = 2.2254\n",
            "Epoch 72:  33% 298/901 [00:35<01:05,  9.22it/s]Step 32100: loss = 2.2230\n",
            "Epoch 72:  33% 300/901 [00:36<01:03,  9.43it/s]Step 32100: loss = 2.2251\n",
            "Epoch 72:  44% 399/901 [00:47<00:57,  8.68it/s]Step 32150: loss = 2.2140\n",
            "Epoch 72:  44% 400/901 [00:47<01:01,  8.20it/s]Step 32150: loss = 2.2138\n",
            "Epoch 72:  55% 499/901 [00:58<00:45,  8.92it/s]Step 32200: loss = 2.2145\n",
            "Step 32200: loss = 2.2139\n",
            "Epoch 72:  66% 599/901 [01:10<00:35,  8.60it/s]Step 32250: loss = 2.2104\n",
            "Epoch 72:  67% 600/901 [01:10<00:34,  8.69it/s]Step 32250: loss = 2.2111\n",
            "Epoch 72:  78% 699/901 [01:22<00:24,  8.35it/s]Step 32300: loss = 2.2003\n",
            "Epoch 72:  78% 700/901 [01:22<00:28,  7.01it/s]Step 32300: loss = 2.1998\n",
            "Epoch 72:  89% 798/901 [01:33<00:12,  8.35it/s]Step 32350: loss = 2.2011\n",
            "Epoch 72:  89% 800/901 [01:33<00:11,  9.04it/s]Step 32350: loss = 2.2007\n",
            "Epoch 72: 100% 898/901 [01:45<00:00,  7.88it/s]Step 32400: loss = 2.1932\n",
            "Epoch 72: 100% 900/901 [01:45<00:00,  8.77it/s]Step 32400: loss = 2.1931\n",
            "Epoch 72: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 72 completed. Average training loss: 2.1931\n",
            "Validation loss after epoch 72: 2.4054\n",
            "Checkpoint saved -> checkpoints/model_epoch_72.pt\n",
            "Epoch 73:   0% 0/901 [00:00<?, ?it/s]Step 32400: loss = 2.2155\n",
            "Epoch 73:  11% 98/901 [00:11<01:33,  8.60it/s]Step 32450: loss = 2.2626\n",
            "Epoch 73:  11% 100/901 [00:11<01:25,  9.41it/s]Step 32450: loss = 2.2613\n",
            "Epoch 73:  22% 199/901 [00:22<01:22,  8.47it/s]Step 32500: loss = 2.2401\n",
            "Checkpoint saved -> checkpoints/model_step_32500.pt\n",
            "Epoch 73:  22% 200/901 [00:23<02:36,  4.49it/s]Step 32500: loss = 2.2374\n",
            "Checkpoint saved -> checkpoints/model_step_32500.pt\n",
            "Epoch 73:  33% 299/901 [00:35<01:11,  8.45it/s]Step 32550: loss = 2.2150\n",
            "Epoch 73:  33% 300/901 [00:35<01:15,  7.98it/s]Step 32550: loss = 2.2182\n",
            "Epoch 73:  44% 399/901 [00:46<00:55,  9.06it/s]Step 32600: loss = 2.2213\n",
            "Epoch 73:  44% 400/901 [00:47<01:01,  8.21it/s]Step 32600: loss = 2.2210\n",
            "Epoch 73:  55% 498/901 [00:58<00:42,  9.58it/s]Step 32650: loss = 2.2260\n",
            "Epoch 73:  55% 500/901 [00:58<00:45,  8.90it/s]Step 32650: loss = 2.2261\n",
            "Epoch 73:  66% 598/901 [01:09<00:32,  9.24it/s]Step 32700: loss = 2.2141\n",
            "Epoch 73:  67% 600/901 [01:09<00:31,  9.46it/s]Step 32700: loss = 2.2144\n",
            "Epoch 73:  77% 698/901 [01:21<00:24,  8.14it/s]Step 32750: loss = 2.2113\n",
            "Epoch 73:  78% 700/901 [01:21<00:24,  8.26it/s]Step 32750: loss = 2.2111\n",
            "Epoch 73:  89% 799/901 [01:33<00:10,  9.53it/s]Step 32800: loss = 2.2048\n",
            "Epoch 73:  89% 800/901 [01:33<00:11,  8.54it/s]Step 32800: loss = 2.2047\n",
            "Epoch 73: 100% 898/901 [01:45<00:00,  8.19it/s]Step 32850: loss = 2.2049\n",
            "Epoch 73: 100% 900/901 [01:45<00:00,  9.11it/s]Step 32850: loss = 2.2050\n",
            "Epoch 73: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 73 completed. Average training loss: 2.2050\n",
            "Validation loss after epoch 73: 2.4039\n",
            "Checkpoint saved -> checkpoints/model_epoch_73.pt\n",
            "Epoch 74:   0% 0/901 [00:00<?, ?it/s]Step 32850: loss = 2.4068\n",
            "Epoch 74:  11% 98/901 [00:11<01:19, 10.13it/s]Step 32900: loss = 2.2242\n",
            "Epoch 74:  11% 100/901 [00:11<01:25,  9.37it/s]Step 32900: loss = 2.2214\n",
            "Epoch 74:  22% 199/901 [00:22<01:44,  6.73it/s]Step 32950: loss = 2.2304\n",
            "Epoch 74:  22% 200/901 [00:23<01:36,  7.26it/s]Step 32950: loss = 2.2287\n",
            "Epoch 74:  33% 298/901 [00:34<01:15,  8.02it/s]Step 33000: loss = 2.2166\n",
            "Checkpoint saved -> checkpoints/model_step_33000.pt\n",
            "Epoch 74:  33% 300/901 [00:35<02:11,  4.56it/s]Step 33000: loss = 2.2172\n",
            "Checkpoint saved -> checkpoints/model_step_33000.pt\n",
            "Epoch 74:  44% 398/901 [00:47<00:58,  8.53it/s]Step 33050: loss = 2.2149\n",
            "Epoch 74:  44% 400/901 [00:47<00:52,  9.48it/s]Step 33050: loss = 2.2142\n",
            "Epoch 74:  55% 498/901 [00:58<00:45,  8.93it/s]Step 33100: loss = 2.2160\n",
            "Epoch 74:  55% 500/901 [00:58<00:41,  9.55it/s]Step 33100: loss = 2.2174\n",
            "Epoch 74:  66% 598/901 [01:09<00:38,  7.91it/s]Step 33150: loss = 2.2284\n",
            "Epoch 74:  67% 600/901 [01:09<00:35,  8.55it/s]Step 33150: loss = 2.2273\n",
            "Epoch 74:  78% 699/901 [01:21<00:24,  8.10it/s]Step 33200: loss = 2.2246\n",
            "Epoch 74:  78% 700/901 [01:21<00:24,  8.12it/s]Step 33200: loss = 2.2238\n",
            "Epoch 74:  89% 799/901 [01:33<00:11,  9.13it/s]Step 33250: loss = 2.2249\n",
            "Epoch 74:  89% 800/901 [01:33<00:11,  8.67it/s]Step 33250: loss = 2.2242\n",
            "Epoch 74: 100% 899/901 [01:44<00:00,  9.40it/s]Step 33300: loss = 2.2175\n",
            "Epoch 74: 100% 900/901 [01:45<00:00,  8.88it/s]Step 33300: loss = 2.2174\n",
            "Epoch 74: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 74 completed. Average training loss: 2.2174\n",
            "Validation loss after epoch 74: 2.4024\n",
            "Checkpoint saved -> checkpoints/model_epoch_74.pt\n",
            "Epoch 75:   0% 0/901 [00:00<?, ?it/s]Step 33300: loss = 2.0528\n",
            "Epoch 75:  11% 99/901 [00:11<01:33,  8.55it/s]Step 33350: loss = 2.1385\n",
            "Epoch 75:  11% 100/901 [00:12<01:41,  7.90it/s]Step 33350: loss = 2.1408\n",
            "Epoch 75:  22% 198/901 [00:23<01:14,  9.43it/s]Step 33400: loss = 2.1878\n",
            "Epoch 75:  22% 200/901 [00:23<01:12,  9.64it/s]Step 33400: loss = 2.1899\n",
            "Epoch 75:  33% 298/901 [00:34<01:08,  8.86it/s]Step 33450: loss = 2.2116\n",
            "Epoch 75:  33% 300/901 [00:34<01:06,  9.02it/s]Step 33450: loss = 2.2126\n",
            "Epoch 75:  44% 399/901 [00:46<01:01,  8.17it/s]Step 33500: loss = 2.1983\n",
            "Checkpoint saved -> checkpoints/model_step_33500.pt\n",
            "Epoch 75:  44% 400/901 [00:46<02:08,  3.91it/s]Step 33500: loss = 2.1958\n",
            "Checkpoint saved -> checkpoints/model_step_33500.pt\n",
            "Epoch 75:  55% 499/901 [00:59<00:48,  8.23it/s]Step 33550: loss = 2.2066\n",
            "Epoch 75:  55% 500/901 [00:59<00:49,  8.08it/s]Step 33550: loss = 2.2066\n",
            "Epoch 75:  66% 599/901 [01:10<00:30,  9.75it/s]Step 33600: loss = 2.2031\n",
            "Epoch 75:  67% 600/901 [01:10<00:31,  9.50it/s]Step 33600: loss = 2.2030\n",
            "Epoch 75:  77% 698/901 [01:21<00:20, 10.03it/s]Step 33650: loss = 2.2076\n",
            "Epoch 75:  78% 700/901 [01:22<00:19, 10.18it/s]Step 33650: loss = 2.2082\n",
            "Epoch 75:  89% 799/901 [01:33<00:11,  9.08it/s]Step 33700: loss = 2.2086\n",
            "Epoch 75:  89% 800/901 [01:33<00:11,  9.08it/s]Step 33700: loss = 2.2081\n",
            "Epoch 75: 100% 898/901 [01:45<00:00,  8.84it/s]Step 33750: loss = 2.2052\n",
            "Epoch 75: 100% 900/901 [01:45<00:00,  9.18it/s]Step 33750: loss = 2.2046\n",
            "Epoch 75: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 75 completed. Average training loss: 2.2046\n",
            "Validation loss after epoch 75: 2.4009\n",
            "Checkpoint saved -> checkpoints/model_epoch_75.pt\n",
            "Epoch 76:   0% 0/901 [00:00<?, ?it/s]Step 33750: loss = 3.0068\n",
            "Epoch 76:  11% 98/901 [00:11<01:26,  9.30it/s]Step 33800: loss = 2.2439\n",
            "Epoch 76:  11% 100/901 [00:11<01:26,  9.29it/s]Step 33800: loss = 2.2421\n",
            "Epoch 76:  22% 198/901 [00:22<01:33,  7.51it/s]Step 33850: loss = 2.2243\n",
            "Epoch 76:  22% 200/901 [00:22<01:19,  8.87it/s]Step 33850: loss = 2.2255\n",
            "Epoch 76:  33% 298/901 [00:34<01:10,  8.56it/s]Step 33900: loss = 2.2255\n",
            "Epoch 76:  33% 300/901 [00:34<01:05,  9.25it/s]Step 33900: loss = 2.2247\n",
            "Epoch 76:  44% 399/901 [00:45<00:58,  8.56it/s]Step 33950: loss = 2.2230\n",
            "Epoch 76:  44% 400/901 [00:45<00:59,  8.48it/s]Step 33950: loss = 2.2243\n",
            "Epoch 76:  55% 498/901 [00:56<00:41,  9.71it/s]Step 34000: loss = 2.2240\n",
            "Checkpoint saved -> checkpoints/model_step_34000.pt\n",
            "Epoch 76:  55% 500/901 [00:57<01:14,  5.35it/s]Step 34000: loss = 2.2244\n",
            "Checkpoint saved -> checkpoints/model_step_34000.pt\n",
            "Epoch 76:  66% 599/901 [01:09<00:36,  8.25it/s]Step 34050: loss = 2.2205\n",
            "Epoch 76:  67% 600/901 [01:09<00:38,  7.85it/s]Step 34050: loss = 2.2202\n",
            "Epoch 76:  77% 698/901 [01:21<00:24,  8.41it/s]Step 34100: loss = 2.2191\n",
            "Epoch 76:  78% 700/901 [01:21<00:21,  9.19it/s]Step 34100: loss = 2.2198\n",
            "Epoch 76:  89% 799/901 [01:32<00:10,  9.65it/s]Step 34150: loss = 2.2227\n",
            "Epoch 76:  89% 800/901 [01:32<00:11,  9.03it/s]Step 34150: loss = 2.2218\n",
            "Epoch 76: 100% 898/901 [01:44<00:00,  8.98it/s]Step 34200: loss = 2.2171\n",
            "Epoch 76: 100% 900/901 [01:44<00:00,  9.82it/s]Step 34200: loss = 2.2178\n",
            "Epoch 76: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 76 completed. Average training loss: 2.2178\n",
            "Validation loss after epoch 76: 2.3995\n",
            "Checkpoint saved -> checkpoints/model_epoch_76.pt\n",
            "Epoch 77:   0% 0/901 [00:00<?, ?it/s]Step 34200: loss = 2.5119\n",
            "Epoch 77:  11% 98/901 [00:11<01:28,  9.06it/s]Step 34250: loss = 2.1978\n",
            "Epoch 77:  11% 100/901 [00:11<01:23,  9.54it/s]Step 34250: loss = 2.1957\n",
            "Epoch 77:  22% 199/901 [00:23<01:31,  7.70it/s]Step 34300: loss = 2.1785\n",
            "Epoch 77:  22% 200/901 [00:23<01:41,  6.92it/s]Step 34300: loss = 2.1775\n",
            "Epoch 77:  33% 298/901 [00:35<01:20,  7.46it/s]Step 34350: loss = 2.1743\n",
            "Epoch 77:  33% 300/901 [00:35<01:13,  8.12it/s]Step 34350: loss = 2.1735\n",
            "Epoch 77:  44% 399/901 [00:46<00:53,  9.33it/s]Step 34400: loss = 2.1755\n",
            "Epoch 77:  44% 400/901 [00:47<01:03,  7.89it/s]Step 34400: loss = 2.1745\n",
            "Epoch 77:  55% 498/901 [00:58<00:41,  9.62it/s]Step 34450: loss = 2.1839\n",
            "Epoch 77:  55% 500/901 [00:58<00:42,  9.33it/s]Step 34450: loss = 2.1842\n",
            "Epoch 77:  66% 598/901 [01:10<00:33,  8.95it/s]Step 34500: loss = 2.1815\n",
            "Checkpoint saved -> checkpoints/model_step_34500.pt\n",
            "Epoch 77:  67% 600/901 [01:10<01:04,  4.69it/s]Step 34500: loss = 2.1825\n",
            "Checkpoint saved -> checkpoints/model_step_34500.pt\n",
            "Epoch 77:  77% 698/901 [01:22<00:26,  7.70it/s]Step 34550: loss = 2.2001\n",
            "Epoch 77:  78% 700/901 [01:22<00:24,  8.27it/s]Step 34550: loss = 2.2008\n",
            "Epoch 77:  89% 798/901 [01:33<00:11,  8.65it/s]Step 34600: loss = 2.2028\n",
            "Epoch 77:  89% 800/901 [01:33<00:11,  8.99it/s]Step 34600: loss = 2.2029\n",
            "Epoch 77: 100% 899/901 [01:44<00:00,  8.54it/s]Step 34650: loss = 2.2011\n",
            "Epoch 77: 100% 900/901 [01:45<00:00,  6.39it/s]Step 34650: loss = 2.2006\n",
            "Epoch 77: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 77 completed. Average training loss: 2.2006\n",
            "Validation loss after epoch 77: 2.3980\n",
            "Checkpoint saved -> checkpoints/model_epoch_77.pt\n",
            "Epoch 78:   0% 0/901 [00:00<?, ?it/s]Step 34650: loss = 2.8299\n",
            "Epoch 78:  11% 99/901 [00:11<02:20,  5.71it/s]Step 34700: loss = 2.2995\n",
            "Epoch 78:  11% 100/901 [00:11<02:08,  6.25it/s]Step 34700: loss = 2.3020\n",
            "Epoch 78:  22% 198/901 [00:22<01:14,  9.40it/s]Step 34750: loss = 2.2122\n",
            "Epoch 78:  22% 200/901 [00:23<01:51,  6.29it/s]Step 34750: loss = 2.2160\n",
            "Epoch 78:  33% 299/901 [00:34<01:09,  8.61it/s]Step 34800: loss = 2.2200\n",
            "Step 34800: loss = 2.2211\n",
            "Epoch 78:  44% 398/901 [00:45<01:06,  7.56it/s]Step 34850: loss = 2.2184\n",
            "Epoch 78:  44% 400/901 [00:45<00:59,  8.38it/s]Step 34850: loss = 2.2180\n",
            "Epoch 78:  55% 498/901 [00:56<00:52,  7.67it/s]Step 34900: loss = 2.2301\n",
            "Epoch 78:  55% 500/901 [00:57<00:48,  8.24it/s]Step 34900: loss = 2.2304\n",
            "Epoch 78:  66% 599/901 [01:08<00:35,  8.62it/s]Step 34950: loss = 2.2325\n",
            "Step 34950: loss = 2.2333\n",
            "Epoch 78:  78% 699/901 [01:20<00:22,  8.82it/s]Step 35000: loss = 2.2240\n",
            "Checkpoint saved -> checkpoints/model_step_35000.pt\n",
            "Epoch 78:  78% 700/901 [01:20<00:44,  4.48it/s]Step 35000: loss = 2.2233\n",
            "Checkpoint saved -> checkpoints/model_step_35000.pt\n",
            "Epoch 78:  89% 798/901 [01:32<00:11,  8.75it/s]Step 35050: loss = 2.2213\n",
            "Epoch 78:  89% 800/901 [01:32<00:10,  9.30it/s]Step 35050: loss = 2.2207\n",
            "Epoch 78: 100% 898/901 [01:44<00:00,  8.92it/s]Step 35100: loss = 2.2113\n",
            "Epoch 78: 100% 900/901 [01:45<00:00,  9.46it/s]Step 35100: loss = 2.2110\n",
            "Epoch 78: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 78 completed. Average training loss: 2.2110\n",
            "Validation loss after epoch 78: 2.3967\n",
            "Checkpoint saved -> checkpoints/model_epoch_78.pt\n",
            "Epoch 79:   0% 0/901 [00:00<?, ?it/s]Step 35100: loss = 2.1118\n",
            "Epoch 79:  11% 98/901 [00:10<01:19, 10.10it/s]Step 35150: loss = 2.2376\n",
            "Epoch 79:  11% 100/901 [00:11<01:29,  8.94it/s]Step 35150: loss = 2.2359\n",
            "Epoch 79:  22% 199/901 [00:23<01:27,  7.99it/s]Step 35200: loss = 2.2076\n",
            "Epoch 79:  22% 200/901 [00:23<01:31,  7.70it/s]Step 35200: loss = 2.2107\n",
            "Epoch 79:  33% 299/901 [00:34<01:16,  7.92it/s]Step 35250: loss = 2.2024\n",
            "Epoch 79:  33% 300/901 [00:34<01:12,  8.27it/s]Step 35250: loss = 2.2006\n",
            "Epoch 79:  44% 398/901 [00:46<00:57,  8.73it/s]Step 35300: loss = 2.2026\n",
            "Epoch 79:  44% 400/901 [00:46<00:55,  9.05it/s]Step 35300: loss = 2.2057\n",
            "Epoch 79:  55% 498/901 [00:57<00:48,  8.36it/s]Step 35350: loss = 2.2112\n",
            "Epoch 79:  55% 500/901 [00:57<00:45,  8.85it/s]Step 35350: loss = 2.2106\n",
            "Epoch 79:  66% 598/901 [01:09<00:35,  8.46it/s]Step 35400: loss = 2.2045\n",
            "Epoch 79:  67% 600/901 [01:09<00:34,  8.76it/s]Step 35400: loss = 2.2050\n",
            "Epoch 79:  77% 698/901 [01:21<00:27,  7.36it/s]Step 35450: loss = 2.1990\n",
            "Epoch 79:  78% 700/901 [01:21<00:27,  7.24it/s]Step 35450: loss = 2.1997\n",
            "Epoch 79:  89% 798/901 [01:32<00:11,  8.65it/s]Step 35500: loss = 2.2015\n",
            "Checkpoint saved -> checkpoints/model_step_35500.pt\n",
            "Epoch 79:  89% 800/901 [01:33<00:20,  4.94it/s]Step 35500: loss = 2.2020\n",
            "Checkpoint saved -> checkpoints/model_step_35500.pt\n",
            "Epoch 79: 100% 898/901 [01:45<00:00, 10.09it/s]Step 35550: loss = 2.2003\n",
            "Epoch 79: 100% 900/901 [01:45<00:00, 10.60it/s]Step 35550: loss = 2.2012\n",
            "Epoch 79: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 79 completed. Average training loss: 2.2012\n",
            "Validation loss after epoch 79: 2.3953\n",
            "Checkpoint saved -> checkpoints/model_epoch_79.pt\n",
            "Epoch 80:   0% 0/901 [00:00<?, ?it/s]Step 35550: loss = 2.3751\n",
            "Epoch 80:  11% 99/901 [00:11<02:13,  6.02it/s]Step 35600: loss = 2.1489\n",
            "Epoch 80:  11% 100/901 [00:12<02:04,  6.45it/s]Step 35600: loss = 2.1495\n",
            "Epoch 80:  22% 198/901 [00:23<01:15,  9.36it/s]Step 35650: loss = 2.1879\n",
            "Epoch 80:  22% 200/901 [00:23<01:13,  9.57it/s]Step 35650: loss = 2.1890\n",
            "Epoch 80:  33% 298/901 [00:35<01:18,  7.68it/s]Step 35700: loss = 2.1654\n",
            "Epoch 80:  33% 300/901 [00:35<01:13,  8.20it/s]Step 35700: loss = 2.1672\n",
            "Epoch 80:  44% 398/901 [00:46<00:51,  9.85it/s]Step 35750: loss = 2.1814\n",
            "Epoch 80:  44% 400/901 [00:46<00:47, 10.44it/s]Step 35750: loss = 2.1801\n",
            "Epoch 80:  55% 499/901 [00:57<00:54,  7.40it/s]Step 35800: loss = 2.1939\n",
            "Epoch 80:  55% 500/901 [00:57<00:54,  7.38it/s]Step 35800: loss = 2.1945\n",
            "Epoch 80:  66% 598/901 [01:09<00:30, 10.06it/s]Step 35850: loss = 2.1953\n",
            "Epoch 80:  67% 600/901 [01:09<00:30, 10.02it/s]Step 35850: loss = 2.1945\n",
            "Epoch 80:  78% 699/901 [01:20<00:23,  8.50it/s]Step 35900: loss = 2.2044\n",
            "Epoch 80:  78% 700/901 [01:20<00:23,  8.70it/s]Step 35900: loss = 2.2049\n",
            "Epoch 80:  89% 798/901 [01:32<00:13,  7.72it/s]Step 35950: loss = 2.2067\n",
            "Epoch 80:  89% 800/901 [01:32<00:11,  8.84it/s]Step 35950: loss = 2.2064\n",
            "Epoch 80: 100% 899/901 [01:43<00:00,  9.60it/s]Step 36000: loss = 2.2061\n",
            "Checkpoint saved -> checkpoints/model_step_36000.pt\n",
            "Epoch 80: 100% 900/901 [01:44<00:00,  4.59it/s]Step 36000: loss = 2.2070\n",
            "Checkpoint saved -> checkpoints/model_step_36000.pt\n",
            "Epoch 80: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 80 completed. Average training loss: 2.2070\n",
            "Validation loss after epoch 80: 2.3939\n",
            "Checkpoint saved -> checkpoints/model_epoch_80.pt\n",
            "Epoch 81:   0% 0/901 [00:00<?, ?it/s]Step 36000: loss = 2.0070\n",
            "Checkpoint saved -> checkpoints/model_step_36000.pt\n",
            "Epoch 81:  11% 99/901 [00:12<01:33,  8.58it/s]Step 36050: loss = 2.1769\n",
            "Epoch 81:  11% 100/901 [00:12<01:31,  8.77it/s]Step 36050: loss = 2.1713\n",
            "Epoch 81:  22% 198/901 [00:23<01:17,  9.02it/s]Step 36100: loss = 2.1944\n",
            "Epoch 81:  22% 200/901 [00:23<01:14,  9.45it/s]Step 36100: loss = 2.1924\n",
            "Epoch 81:  33% 298/901 [00:35<01:04,  9.35it/s]Step 36150: loss = 2.1854\n",
            "Epoch 81:  33% 300/901 [00:35<01:02,  9.65it/s]Step 36150: loss = 2.1846\n",
            "Epoch 81:  44% 398/901 [00:46<00:55,  9.04it/s]Step 36200: loss = 2.1790\n",
            "Epoch 81:  44% 400/901 [00:47<00:54,  9.18it/s]Step 36200: loss = 2.1789\n",
            "Epoch 81:  55% 498/901 [00:58<00:46,  8.70it/s]Step 36250: loss = 2.1647\n",
            "Epoch 81:  55% 500/901 [00:59<00:50,  7.90it/s]Step 36250: loss = 2.1645\n",
            "Epoch 81:  66% 599/901 [01:10<00:31,  9.51it/s]Step 36300: loss = 2.1790\n",
            "Epoch 81:  67% 600/901 [01:10<00:31,  9.59it/s]Step 36300: loss = 2.1784\n",
            "Epoch 81:  78% 699/901 [01:21<00:21,  9.34it/s]Step 36350: loss = 2.1917\n",
            "Epoch 81:  78% 700/901 [01:21<00:21,  9.17it/s]Step 36350: loss = 2.1926\n",
            "Epoch 81:  89% 798/901 [01:33<00:11,  9.30it/s]Step 36400: loss = 2.1934\n",
            "Epoch 81:  89% 800/901 [01:33<00:10,  9.49it/s]Step 36400: loss = 2.1924\n",
            "Epoch 81: 100% 898/901 [01:44<00:00,  7.97it/s]Step 36450: loss = 2.1977\n",
            "Epoch 81: 100% 900/901 [01:44<00:00,  8.91it/s]Step 36450: loss = 2.1970\n",
            "Epoch 81: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 81 completed. Average training loss: 2.1970\n",
            "Validation loss after epoch 81: 2.3925\n",
            "Checkpoint saved -> checkpoints/model_epoch_81.pt\n",
            "Epoch 82:   0% 0/901 [00:00<?, ?it/s]Step 36450: loss = 2.4344\n",
            "Epoch 82:  11% 98/901 [00:11<01:30,  8.88it/s]Step 36500: loss = 2.1649\n",
            "Checkpoint saved -> checkpoints/model_step_36500.pt\n",
            "Epoch 82:  11% 100/901 [00:12<02:53,  4.63it/s]Step 36500: loss = 2.1697\n",
            "Checkpoint saved -> checkpoints/model_step_36500.pt\n",
            "Epoch 82:  22% 198/901 [00:24<01:20,  8.73it/s]Step 36550: loss = 2.1554\n",
            "Epoch 82:  22% 200/901 [00:24<01:25,  8.19it/s]Step 36550: loss = 2.1521\n",
            "Epoch 82:  33% 299/901 [00:36<01:04,  9.26it/s]Step 36600: loss = 2.1635\n",
            "Epoch 82:  33% 300/901 [00:36<01:09,  8.68it/s]Step 36600: loss = 2.1622\n",
            "Epoch 82:  44% 399/901 [00:48<00:58,  8.64it/s]Step 36650: loss = 2.1770\n",
            "Epoch 82:  44% 400/901 [00:48<01:04,  7.80it/s]Step 36650: loss = 2.1763\n",
            "Epoch 82:  55% 498/901 [00:59<00:37, 10.61it/s]Step 36700: loss = 2.1895\n",
            "Epoch 82:  55% 500/901 [00:59<00:41,  9.72it/s]Step 36700: loss = 2.1886\n",
            "Epoch 82:  66% 598/901 [01:10<00:33,  9.11it/s]Step 36750: loss = 2.1994\n",
            "Epoch 82:  67% 600/901 [01:10<00:32,  9.19it/s]Step 36750: loss = 2.1995\n",
            "Epoch 82:  78% 699/901 [01:21<00:21,  9.20it/s]Step 36800: loss = 2.1966\n",
            "Epoch 82:  78% 700/901 [01:22<00:22,  9.05it/s]Step 36800: loss = 2.1969\n",
            "Epoch 82:  89% 799/901 [01:32<00:11,  8.83it/s]Step 36850: loss = 2.2022\n",
            "Epoch 82:  89% 800/901 [01:33<00:18,  5.55it/s]Step 36850: loss = 2.2027\n",
            "Epoch 82: 100% 898/901 [01:44<00:00,  9.14it/s]Step 36900: loss = 2.2038\n",
            "Epoch 82: 100% 900/901 [01:44<00:00,  9.63it/s]Step 36900: loss = 2.2037\n",
            "Epoch 82: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 82 completed. Average training loss: 2.2037\n",
            "Validation loss after epoch 82: 2.3912\n",
            "Checkpoint saved -> checkpoints/model_epoch_82.pt\n",
            "Epoch 83:   0% 0/901 [00:00<?, ?it/s]Step 36900: loss = 1.9622\n",
            "Epoch 83:  11% 98/901 [00:11<01:25,  9.38it/s]Step 36950: loss = 2.1781\n",
            "Epoch 83:  11% 100/901 [00:11<01:23,  9.63it/s]Step 36950: loss = 2.1772\n",
            "Epoch 83:  22% 198/901 [00:23<01:21,  8.58it/s]Step 37000: loss = 2.1885\n",
            "Checkpoint saved -> checkpoints/model_step_37000.pt\n",
            "Epoch 83:  22% 200/901 [00:23<02:16,  5.14it/s]Step 37000: loss = 2.1858\n",
            "Checkpoint saved -> checkpoints/model_step_37000.pt\n",
            "Epoch 83:  33% 298/901 [00:35<01:01,  9.82it/s]Step 37050: loss = 2.2054\n",
            "Epoch 83:  33% 300/901 [00:35<01:04,  9.38it/s]Step 37050: loss = 2.2062\n",
            "Epoch 83:  44% 398/901 [00:47<01:02,  8.00it/s]Step 37100: loss = 2.2002\n",
            "Epoch 83:  44% 400/901 [00:47<00:56,  8.92it/s]Step 37100: loss = 2.2005\n",
            "Epoch 83:  55% 499/901 [00:59<00:51,  7.80it/s]Step 37150: loss = 2.2112\n",
            "Step 37150: loss = 2.2098\n",
            "Epoch 83:  66% 598/901 [01:10<00:32,  9.31it/s]Step 37200: loss = 2.2015\n",
            "Epoch 83:  67% 600/901 [01:10<00:33,  8.97it/s]Step 37200: loss = 2.2013\n",
            "Epoch 83:  78% 699/901 [01:22<00:23,  8.68it/s]Step 37250: loss = 2.2023\n",
            "Epoch 83:  78% 700/901 [01:22<00:24,  8.37it/s]Step 37250: loss = 2.2030\n",
            "Epoch 83:  89% 799/901 [01:33<00:12,  8.27it/s]Step 37300: loss = 2.2016\n",
            "Epoch 83:  89% 800/901 [01:33<00:13,  7.54it/s]Step 37300: loss = 2.2012\n",
            "Epoch 83: 100% 898/901 [01:45<00:00,  9.84it/s]Step 37350: loss = 2.1990\n",
            "Epoch 83: 100% 900/901 [01:45<00:00,  9.16it/s]Step 37350: loss = 2.1990\n",
            "Epoch 83: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 83 completed. Average training loss: 2.1990\n",
            "Validation loss after epoch 83: 2.3898\n",
            "Checkpoint saved -> checkpoints/model_epoch_83.pt\n",
            "Epoch 84:   0% 0/901 [00:00<?, ?it/s]Step 37350: loss = 2.1363\n",
            "Epoch 84:  11% 99/901 [00:11<01:36,  8.30it/s]Step 37400: loss = 2.1940\n",
            "Epoch 84:  11% 100/901 [00:11<01:41,  7.91it/s]Step 37400: loss = 2.1973\n",
            "Epoch 84:  22% 199/901 [00:23<01:29,  7.85it/s]Step 37450: loss = 2.1694\n",
            "Epoch 84:  22% 200/901 [00:23<01:26,  8.11it/s]Step 37450: loss = 2.1688\n",
            "Epoch 84:  33% 299/901 [00:35<01:07,  8.94it/s]Step 37500: loss = 2.1522\n",
            "Checkpoint saved -> checkpoints/model_step_37500.pt\n",
            "Epoch 84:  33% 300/901 [00:35<02:10,  4.62it/s]Step 37500: loss = 2.1525\n",
            "Checkpoint saved -> checkpoints/model_step_37500.pt\n",
            "Epoch 84:  44% 399/901 [00:47<00:52,  9.58it/s]Step 37550: loss = 2.1611\n",
            "Epoch 84:  44% 400/901 [00:47<00:52,  9.62it/s]Step 37550: loss = 2.1591\n",
            "Epoch 84:  55% 498/901 [00:59<00:41,  9.74it/s]Step 37600: loss = 2.1726\n",
            "Epoch 84:  55% 500/901 [00:59<00:39, 10.21it/s]Step 37600: loss = 2.1725\n",
            "Epoch 84:  66% 598/901 [01:11<00:32,  9.36it/s]Step 37650: loss = 2.1695\n",
            "Epoch 84:  67% 600/901 [01:11<00:34,  8.81it/s]Step 37650: loss = 2.1696\n",
            "Epoch 84:  77% 698/901 [01:22<00:26,  7.54it/s]Step 37700: loss = 2.1801\n",
            "Epoch 84:  78% 700/901 [01:23<00:24,  8.31it/s]Step 37700: loss = 2.1808\n",
            "Epoch 84:  89% 798/901 [01:34<00:12,  8.28it/s]Step 37750: loss = 2.1842\n",
            "Epoch 84:  89% 800/901 [01:34<00:11,  8.79it/s]Step 37750: loss = 2.1839\n",
            "Epoch 84: 100% 898/901 [01:45<00:00,  8.85it/s]Step 37800: loss = 2.1889\n",
            "Epoch 84: 100% 900/901 [01:45<00:00,  9.52it/s]Step 37800: loss = 2.1885\n",
            "Epoch 84: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 84 completed. Average training loss: 2.1885\n",
            "Validation loss after epoch 84: 2.3885\n",
            "Checkpoint saved -> checkpoints/model_epoch_84.pt\n",
            "Epoch 85:   0% 0/901 [00:00<?, ?it/s]Step 37800: loss = 2.1354\n",
            "Epoch 85:  11% 98/901 [00:11<01:31,  8.80it/s]Step 37850: loss = 2.2286\n",
            "Epoch 85:  11% 100/901 [00:11<01:24,  9.53it/s]Step 37850: loss = 2.2287\n",
            "Epoch 85:  22% 199/901 [00:22<01:34,  7.40it/s]Step 37900: loss = 2.2394\n",
            "Epoch 85:  22% 200/901 [00:22<01:38,  7.09it/s]Step 37900: loss = 2.2405\n",
            "Epoch 85:  33% 298/901 [00:33<01:12,  8.35it/s]Step 37950: loss = 2.2570\n",
            "Epoch 85:  33% 300/901 [00:33<01:06,  9.04it/s]Step 37950: loss = 2.2580\n",
            "Epoch 85:  44% 398/901 [00:44<00:57,  8.76it/s]Step 38000: loss = 2.2419\n",
            "Checkpoint saved -> checkpoints/model_step_38000.pt\n",
            "Epoch 85:  44% 400/901 [00:45<01:54,  4.38it/s]Step 38000: loss = 2.2414\n",
            "Checkpoint saved -> checkpoints/model_step_38000.pt\n",
            "Epoch 85:  55% 498/901 [00:57<00:44,  8.97it/s]Step 38050: loss = 2.2382\n",
            "Epoch 85:  55% 500/901 [00:57<00:44,  9.07it/s]Step 38050: loss = 2.2378\n",
            "Epoch 85:  66% 599/901 [01:09<00:40,  7.39it/s]Step 38100: loss = 2.2190\n",
            "Epoch 85:  67% 600/901 [01:09<00:38,  7.76it/s]Step 38100: loss = 2.2190\n",
            "Epoch 85:  78% 699/901 [01:20<00:24,  8.29it/s]Step 38150: loss = 2.2109\n",
            "Epoch 85:  78% 700/901 [01:21<00:23,  8.38it/s]Step 38150: loss = 2.2108\n",
            "Epoch 85:  89% 799/901 [01:33<00:11,  8.58it/s]Step 38200: loss = 2.1982\n",
            "Epoch 85:  89% 800/901 [01:33<00:12,  8.26it/s]Step 38200: loss = 2.1991\n",
            "Epoch 85: 100% 898/901 [01:44<00:00,  8.49it/s]Step 38250: loss = 2.2017\n",
            "Epoch 85: 100% 900/901 [01:44<00:00,  8.14it/s]Step 38250: loss = 2.2019\n",
            "Epoch 85: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 85 completed. Average training loss: 2.2019\n",
            "Validation loss after epoch 85: 2.3872\n",
            "Checkpoint saved -> checkpoints/model_epoch_85.pt\n",
            "Epoch 86:   0% 0/901 [00:00<?, ?it/s]Step 38250: loss = 1.8983\n",
            "Epoch 86:  11% 99/901 [00:12<01:57,  6.83it/s]Step 38300: loss = 2.1335\n",
            "Epoch 86:  11% 100/901 [00:12<01:53,  7.04it/s]Step 38300: loss = 2.1392\n",
            "Epoch 86:  22% 198/901 [00:23<01:13,  9.52it/s]Step 38350: loss = 2.1681\n",
            "Epoch 86:  22% 200/901 [00:23<01:10,  9.98it/s]Step 38350: loss = 2.1727\n",
            "Epoch 86:  33% 298/901 [00:35<01:14,  8.08it/s]Step 38400: loss = 2.1655\n",
            "Epoch 86:  33% 300/901 [00:35<01:16,  7.81it/s]Step 38400: loss = 2.1665\n",
            "Epoch 86:  44% 398/901 [00:46<00:58,  8.56it/s]Step 38450: loss = 2.1698\n",
            "Epoch 86:  44% 400/901 [00:47<00:54,  9.21it/s]Step 38450: loss = 2.1716\n",
            "Epoch 86:  55% 499/901 [00:58<00:49,  8.09it/s]Step 38500: loss = 2.1716\n",
            "Checkpoint saved -> checkpoints/model_step_38500.pt\n",
            "Epoch 86:  55% 500/901 [00:59<01:42,  3.89it/s]Step 38500: loss = 2.1716\n",
            "Checkpoint saved -> checkpoints/model_step_38500.pt\n",
            "Epoch 86:  66% 598/901 [01:11<00:31,  9.55it/s]Step 38550: loss = 2.1739\n",
            "Epoch 86:  67% 600/901 [01:11<00:32,  9.18it/s]Step 38550: loss = 2.1741\n",
            "Epoch 86:  77% 698/901 [01:22<00:21,  9.64it/s]Step 38600: loss = 2.1808\n",
            "Epoch 86:  78% 700/901 [01:23<00:20,  9.77it/s]Step 38600: loss = 2.1812\n",
            "Epoch 86:  89% 798/901 [01:33<00:11,  8.68it/s]Step 38650: loss = 2.1883\n",
            "Epoch 86:  89% 800/901 [01:34<00:14,  7.20it/s]Step 38650: loss = 2.1886\n",
            "Epoch 86: 100% 899/901 [01:45<00:00,  9.01it/s]Step 38700: loss = 2.1884\n",
            "Epoch 86: 100% 900/901 [01:45<00:00,  8.87it/s]Step 38700: loss = 2.1889\n",
            "Epoch 86: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 86 completed. Average training loss: 2.1889\n",
            "Validation loss after epoch 86: 2.3859\n",
            "Checkpoint saved -> checkpoints/model_epoch_86.pt\n",
            "Epoch 87:   0% 0/901 [00:00<?, ?it/s]Step 38700: loss = 2.2290\n",
            "Epoch 87:  11% 98/901 [00:11<01:24,  9.55it/s]Step 38750: loss = 2.1986\n",
            "Epoch 87:  11% 100/901 [00:11<01:24,  9.48it/s]Step 38750: loss = 2.1971\n",
            "Epoch 87:  22% 199/901 [00:22<01:16,  9.17it/s]Step 38800: loss = 2.2312\n",
            "Epoch 87:  22% 200/901 [00:22<01:15,  9.25it/s]Step 38800: loss = 2.2361\n",
            "Epoch 87:  33% 299/901 [00:33<01:11,  8.45it/s]Step 38850: loss = 2.2229\n",
            "Epoch 87:  33% 300/901 [00:34<01:09,  8.66it/s]Step 38850: loss = 2.2231\n",
            "Epoch 87:  44% 398/901 [00:45<01:00,  8.38it/s]Step 38900: loss = 2.2135\n",
            "Epoch 87:  44% 400/901 [00:45<00:52,  9.52it/s]Step 38900: loss = 2.2131\n",
            "Epoch 87:  55% 499/901 [00:57<00:43,  9.22it/s]Step 38950: loss = 2.2125\n",
            "Epoch 87:  55% 500/901 [00:57<00:44,  9.07it/s]Step 38950: loss = 2.2138\n",
            "Epoch 87:  66% 599/901 [01:09<00:40,  7.47it/s]Step 39000: loss = 2.1923\n",
            "Checkpoint saved -> checkpoints/model_step_39000.pt\n",
            "Epoch 87:  67% 600/901 [01:10<01:18,  3.85it/s]Step 39000: loss = 2.1920\n",
            "Checkpoint saved -> checkpoints/model_step_39000.pt\n",
            "Epoch 87:  77% 698/901 [01:22<00:22,  8.87it/s]Step 39050: loss = 2.1902\n",
            "Epoch 87:  78% 700/901 [01:23<00:23,  8.48it/s]Step 39050: loss = 2.1905\n",
            "Epoch 87:  89% 798/901 [01:33<00:11,  9.19it/s]Step 39100: loss = 2.1933\n",
            "Epoch 87:  89% 800/901 [01:34<00:10,  9.30it/s]Step 39100: loss = 2.1938\n",
            "Epoch 87: 100% 898/901 [01:45<00:00,  9.24it/s]Step 39150: loss = 2.1900\n",
            "Epoch 87: 100% 900/901 [01:45<00:00,  9.53it/s]Step 39150: loss = 2.1896\n",
            "Epoch 87: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 87 completed. Average training loss: 2.1896\n",
            "Validation loss after epoch 87: 2.3846\n",
            "Checkpoint saved -> checkpoints/model_epoch_87.pt\n",
            "Epoch 88:   0% 0/901 [00:00<?, ?it/s]Step 39150: loss = 1.4964\n",
            "Epoch 88:  11% 99/901 [00:11<01:36,  8.28it/s]Step 39200: loss = 2.1632\n",
            "Epoch 88:  11% 100/901 [00:11<01:36,  8.31it/s]Step 39200: loss = 2.1574\n",
            "Epoch 88:  22% 199/901 [00:23<01:18,  8.98it/s]Step 39250: loss = 2.1483\n",
            "Epoch 88:  22% 200/901 [00:23<01:25,  8.21it/s]Step 39250: loss = 2.1490\n",
            "Epoch 88:  33% 299/901 [00:35<01:06,  9.01it/s]Step 39300: loss = 2.1634\n",
            "Epoch 88:  33% 300/901 [00:35<01:07,  8.86it/s]Step 39300: loss = 2.1631\n",
            "Epoch 88:  44% 399/901 [00:46<01:02,  8.10it/s]Step 39350: loss = 2.1531\n",
            "Epoch 88:  44% 400/901 [00:47<00:58,  8.52it/s]Step 39350: loss = 2.1516\n",
            "Epoch 88:  55% 499/901 [00:58<00:40,  9.89it/s]Step 39400: loss = 2.1680\n",
            "Epoch 88:  55% 500/901 [00:58<00:43,  9.17it/s]Step 39400: loss = 2.1673\n",
            "Epoch 88:  66% 599/901 [01:09<00:33,  9.02it/s]Step 39450: loss = 2.1721\n",
            "Epoch 88:  67% 600/901 [01:10<00:38,  7.73it/s]Step 39450: loss = 2.1724\n",
            "Epoch 88:  78% 699/901 [01:21<00:23,  8.52it/s]Step 39500: loss = 2.1720\n",
            "Checkpoint saved -> checkpoints/model_step_39500.pt\n",
            "Epoch 88:  78% 700/901 [01:22<00:47,  4.21it/s]Step 39500: loss = 2.1712\n",
            "Checkpoint saved -> checkpoints/model_step_39500.pt\n",
            "Epoch 88:  89% 798/901 [01:33<00:13,  7.88it/s]Step 39550: loss = 2.1767\n",
            "Epoch 88:  89% 800/901 [01:34<00:11,  8.94it/s]Step 39550: loss = 2.1761\n",
            "Epoch 88: 100% 898/901 [01:45<00:00,  8.49it/s]Step 39600: loss = 2.1815\n",
            "Epoch 88: 100% 900/901 [01:46<00:00,  8.90it/s]Step 39600: loss = 2.1815\n",
            "Epoch 88: 100% 901/901 [01:46<00:00,  8.49it/s]\n",
            "Epoch 88 completed. Average training loss: 2.1815\n",
            "Validation loss after epoch 88: 2.3833\n",
            "Checkpoint saved -> checkpoints/model_epoch_88.pt\n",
            "Epoch 89:   0% 0/901 [00:00<?, ?it/s]Step 39600: loss = 2.3454\n",
            "Epoch 89:  11% 98/901 [00:11<01:28,  9.08it/s]Step 39650: loss = 2.1562\n",
            "Epoch 89:  11% 100/901 [00:11<01:24,  9.48it/s]Step 39650: loss = 2.1585\n",
            "Epoch 89:  22% 199/901 [00:23<01:20,  8.71it/s]Step 39700: loss = 2.1565\n",
            "Step 39700: loss = 2.1589\n",
            "Epoch 89:  33% 299/901 [00:34<01:05,  9.23it/s]Step 39750: loss = 2.1797\n",
            "Epoch 89:  33% 300/901 [00:34<01:05,  9.18it/s]Step 39750: loss = 2.1812\n",
            "Epoch 89:  44% 399/901 [00:46<01:25,  5.88it/s]Step 39800: loss = 2.1872\n",
            "Epoch 89:  44% 400/901 [00:46<01:23,  6.00it/s]Step 39800: loss = 2.1865\n",
            "Epoch 89:  55% 498/901 [00:57<00:43,  9.29it/s]Step 39850: loss = 2.1963\n",
            "Epoch 89:  55% 500/901 [00:57<00:42,  9.38it/s]Step 39850: loss = 2.1961\n",
            "Epoch 89:  66% 598/901 [01:08<00:32,  9.26it/s]Step 39900: loss = 2.1933\n",
            "Epoch 89:  67% 600/901 [01:09<00:31,  9.41it/s]Step 39900: loss = 2.1926\n",
            "Epoch 89:  77% 698/901 [01:20<00:23,  8.68it/s]Step 39950: loss = 2.1947\n",
            "Epoch 89:  78% 700/901 [01:20<00:21,  9.35it/s]Step 39950: loss = 2.1947\n",
            "Epoch 89:  89% 799/901 [01:32<00:14,  6.84it/s]Step 40000: loss = 2.1925\n",
            "Checkpoint saved -> checkpoints/model_step_40000.pt\n",
            "Epoch 89:  89% 800/901 [01:33<00:33,  2.99it/s]Step 40000: loss = 2.1929\n",
            "Checkpoint saved -> checkpoints/model_step_40000.pt\n",
            "Epoch 89: 100% 898/901 [01:45<00:00,  9.32it/s]Step 40050: loss = 2.1876\n",
            "Epoch 89: 100% 900/901 [01:45<00:00,  9.31it/s]Step 40050: loss = 2.1878\n",
            "Epoch 89: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 89 completed. Average training loss: 2.1878\n",
            "Validation loss after epoch 89: 2.3821\n",
            "Checkpoint saved -> checkpoints/model_epoch_89.pt\n",
            "Epoch 90:   0% 0/901 [00:00<?, ?it/s]Step 40050: loss = 2.1937\n",
            "Epoch 90:  11% 98/901 [00:11<01:36,  8.33it/s]Step 40100: loss = 2.1850\n",
            "Epoch 90:  11% 100/901 [00:11<01:29,  8.92it/s]Step 40100: loss = 2.1877\n",
            "Epoch 90:  22% 198/901 [00:23<01:10, 10.04it/s]Step 40150: loss = 2.1963\n",
            "Epoch 90:  22% 200/901 [00:23<01:07, 10.33it/s]Step 40150: loss = 2.1950\n",
            "Epoch 90:  33% 299/901 [00:34<01:04,  9.36it/s]Step 40200: loss = 2.1911\n",
            "Epoch 90:  33% 300/901 [00:34<01:04,  9.32it/s]Step 40200: loss = 2.1949\n",
            "Epoch 90:  44% 398/901 [00:46<00:57,  8.74it/s]Step 40250: loss = 2.1831\n",
            "Epoch 90:  44% 400/901 [00:46<00:52,  9.54it/s]Step 40250: loss = 2.1837\n",
            "Epoch 90:  55% 499/901 [00:57<00:44,  9.10it/s]Step 40300: loss = 2.1930\n",
            "Epoch 90:  55% 500/901 [00:57<00:44,  8.92it/s]Step 40300: loss = 2.1928\n",
            "Epoch 90:  66% 598/901 [01:09<00:32,  9.32it/s]Step 40350: loss = 2.1943\n",
            "Epoch 90:  67% 600/901 [01:09<00:27, 10.86it/s]Step 40350: loss = 2.1932\n",
            "Epoch 90:  77% 698/901 [01:20<00:22,  8.87it/s]Step 40400: loss = 2.1961\n",
            "Epoch 90:  78% 700/901 [01:20<00:24,  8.09it/s]Step 40400: loss = 2.1964\n",
            "Epoch 90:  89% 799/901 [01:32<00:10, 10.16it/s]Step 40450: loss = 2.2035\n",
            "Step 40450: loss = 2.2028\n",
            "Epoch 90: 100% 898/901 [01:44<00:00,  9.73it/s]Step 40500: loss = 2.1913\n",
            "Checkpoint saved -> checkpoints/model_step_40500.pt\n",
            "Epoch 90: 100% 900/901 [01:44<00:00,  5.24it/s]Step 40500: loss = 2.1917\n",
            "Checkpoint saved -> checkpoints/model_step_40500.pt\n",
            "Epoch 90: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 90 completed. Average training loss: 2.1917\n",
            "Validation loss after epoch 90: 2.3808\n",
            "Checkpoint saved -> checkpoints/model_epoch_90.pt\n",
            "Epoch 91:   0% 0/901 [00:00<?, ?it/s]Step 40500: loss = 2.1055\n",
            "Checkpoint saved -> checkpoints/model_step_40500.pt\n",
            "Epoch 91:  11% 99/901 [00:12<01:37,  8.23it/s]Step 40550: loss = 2.1660\n",
            "Epoch 91:  11% 100/901 [00:12<01:42,  7.84it/s]Step 40550: loss = 2.1690\n",
            "Epoch 91:  22% 199/901 [00:24<01:15,  9.27it/s]Step 40600: loss = 2.1628\n",
            "Epoch 91:  22% 200/901 [00:24<01:17,  9.07it/s]Step 40600: loss = 2.1638\n",
            "Epoch 91:  33% 299/901 [00:36<01:12,  8.32it/s]Step 40650: loss = 2.1605\n",
            "Epoch 91:  33% 300/901 [00:36<01:13,  8.17it/s]Step 40650: loss = 2.1605\n",
            "Epoch 91:  44% 398/901 [00:47<00:47, 10.66it/s]Step 40700: loss = 2.1763\n",
            "Epoch 91:  44% 400/901 [00:47<00:49, 10.14it/s]Step 40700: loss = 2.1748\n",
            "Epoch 91:  55% 499/901 [00:58<00:48,  8.22it/s]Step 40750: loss = 2.1804\n",
            "Epoch 91:  55% 500/901 [00:58<00:51,  7.72it/s]Step 40750: loss = 2.1792\n",
            "Epoch 91:  66% 599/901 [01:10<00:34,  8.88it/s]Step 40800: loss = 2.1818\n",
            "Epoch 91:  67% 600/901 [01:10<00:35,  8.39it/s]Step 40800: loss = 2.1812\n",
            "Epoch 91:  78% 699/901 [01:22<00:21,  9.35it/s]Step 40850: loss = 2.1780\n",
            "Epoch 91:  78% 700/901 [01:22<00:21,  9.18it/s]Step 40850: loss = 2.1781\n",
            "Epoch 91:  89% 798/901 [01:33<00:12,  8.21it/s]Step 40900: loss = 2.1790\n",
            "Epoch 91:  89% 800/901 [01:33<00:11,  8.97it/s]Step 40900: loss = 2.1796\n",
            "Epoch 91: 100% 898/901 [01:45<00:00,  8.87it/s]Step 40950: loss = 2.1789\n",
            "Epoch 91: 100% 900/901 [01:45<00:00,  9.07it/s]Step 40950: loss = 2.1792\n",
            "Epoch 91: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 91 completed. Average training loss: 2.1792\n",
            "Validation loss after epoch 91: 2.3796\n",
            "Checkpoint saved -> checkpoints/model_epoch_91.pt\n",
            "Epoch 92:   0% 0/901 [00:00<?, ?it/s]Step 40950: loss = 2.0703\n",
            "Epoch 92:  11% 98/901 [00:11<01:33,  8.57it/s]Step 41000: loss = 2.2070\n",
            "Checkpoint saved -> checkpoints/model_step_41000.pt\n",
            "Epoch 92:  11% 100/901 [00:11<03:03,  4.37it/s]Step 41000: loss = 2.2096\n",
            "Checkpoint saved -> checkpoints/model_step_41000.pt\n",
            "Epoch 92:  22% 198/901 [00:24<01:21,  8.67it/s]Step 41050: loss = 2.1832\n",
            "Epoch 92:  22% 200/901 [00:24<01:17,  8.99it/s]Step 41050: loss = 2.1835\n",
            "Epoch 92:  33% 298/901 [00:35<01:15,  8.03it/s]Step 41100: loss = 2.2091\n",
            "Epoch 92:  33% 300/901 [00:35<01:11,  8.40it/s]Step 41100: loss = 2.2098\n",
            "Epoch 92:  44% 399/901 [00:47<01:06,  7.52it/s]Step 41150: loss = 2.2016\n",
            "Epoch 92:  44% 400/901 [00:47<01:06,  7.58it/s]Step 41150: loss = 2.2033\n",
            "Epoch 92:  55% 498/901 [00:58<00:46,  8.73it/s]Step 41200: loss = 2.2026\n",
            "Epoch 92:  55% 500/901 [00:58<00:42,  9.50it/s]Step 41200: loss = 2.2013\n",
            "Epoch 92:  66% 599/901 [01:10<00:35,  8.44it/s]Step 41250: loss = 2.2001\n",
            "Step 41250: loss = 2.1996\n",
            "Epoch 92:  78% 699/901 [01:21<00:21,  9.37it/s]Step 41300: loss = 2.2001\n",
            "Epoch 92:  78% 700/901 [01:21<00:22,  9.07it/s]Step 41300: loss = 2.1988\n",
            "Epoch 92:  89% 799/901 [01:33<00:10,  9.46it/s]Step 41350: loss = 2.1935\n",
            "Epoch 92:  89% 800/901 [01:33<00:10,  9.23it/s]Step 41350: loss = 2.1927\n",
            "Epoch 92: 100% 899/901 [01:45<00:00,  8.75it/s]Step 41400: loss = 2.1888\n",
            "Epoch 92: 100% 900/901 [01:45<00:00,  7.82it/s]Step 41400: loss = 2.1892\n",
            "Epoch 92: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 92 completed. Average training loss: 2.1892\n",
            "Validation loss after epoch 92: 2.3783\n",
            "Checkpoint saved -> checkpoints/model_epoch_92.pt\n",
            "Epoch 93:   0% 0/901 [00:00<?, ?it/s]Step 41400: loss = 2.2934\n",
            "Epoch 93:  11% 99/901 [00:11<02:05,  6.38it/s]Step 41450: loss = 2.1432\n",
            "Epoch 93:  11% 100/901 [00:11<01:55,  6.91it/s]Step 41450: loss = 2.1386\n",
            "Epoch 93:  22% 198/901 [00:23<01:20,  8.76it/s]Step 41500: loss = 2.1329\n",
            "Checkpoint saved -> checkpoints/model_step_41500.pt\n",
            "Epoch 93:  22% 200/901 [00:24<02:21,  4.96it/s]Step 41500: loss = 2.1305\n",
            "Checkpoint saved -> checkpoints/model_step_41500.pt\n",
            "Epoch 93:  33% 299/901 [00:36<01:14,  8.07it/s]Step 41550: loss = 2.1428\n",
            "Epoch 93:  33% 300/901 [00:36<01:11,  8.43it/s]Step 41550: loss = 2.1432\n",
            "Epoch 93:  44% 398/901 [00:48<00:56,  8.93it/s]Step 41600: loss = 2.1474\n",
            "Epoch 93:  44% 400/901 [00:48<00:54,  9.18it/s]Step 41600: loss = 2.1481\n",
            "Epoch 93:  55% 498/901 [01:00<00:45,  8.80it/s]Step 41650: loss = 2.1506\n",
            "Epoch 93:  55% 500/901 [01:00<00:45,  8.86it/s]Step 41650: loss = 2.1497\n",
            "Epoch 93:  66% 598/901 [01:11<00:37,  8.12it/s]Step 41700: loss = 2.1522\n",
            "Epoch 93:  67% 600/901 [01:12<00:36,  8.24it/s]Step 41700: loss = 2.1533\n",
            "Epoch 93:  78% 699/901 [01:23<00:24,  8.19it/s]Step 41750: loss = 2.1623\n",
            "Epoch 93:  78% 700/901 [01:23<00:25,  7.91it/s]Step 41750: loss = 2.1625\n",
            "Epoch 93:  89% 798/901 [01:34<00:11,  8.90it/s]Step 41800: loss = 2.1667\n",
            "Epoch 93:  89% 800/901 [01:34<00:11,  8.72it/s]Step 41800: loss = 2.1670\n",
            "Epoch 93: 100% 898/901 [01:45<00:00,  9.73it/s]Step 41850: loss = 2.1708\n",
            "Epoch 93: 100% 900/901 [01:45<00:00,  9.66it/s]Step 41850: loss = 2.1709\n",
            "Epoch 93: 100% 901/901 [01:45<00:00,  8.50it/s]\n",
            "Epoch 93 completed. Average training loss: 2.1709\n",
            "Validation loss after epoch 93: 2.3771\n",
            "Checkpoint saved -> checkpoints/model_epoch_93.pt\n",
            "Epoch 94:   0% 0/901 [00:00<?, ?it/s]Step 41850: loss = 2.2510\n",
            "Epoch 94:  11% 98/901 [00:11<01:19, 10.14it/s]Step 41900: loss = 2.1869\n",
            "Epoch 94:  11% 100/901 [00:11<01:26,  9.30it/s]Step 41900: loss = 2.1888\n",
            "Epoch 94:  22% 199/901 [00:22<01:21,  8.62it/s]Step 41950: loss = 2.1912\n",
            "Epoch 94:  22% 200/901 [00:22<01:23,  8.44it/s]Step 41950: loss = 2.1905\n",
            "Epoch 94:  33% 298/901 [00:34<01:06,  9.13it/s]Step 42000: loss = 2.1831\n",
            "Checkpoint saved -> checkpoints/model_step_42000.pt\n",
            "Epoch 94:  33% 300/901 [00:34<02:02,  4.91it/s]Step 42000: loss = 2.1843\n",
            "Checkpoint saved -> checkpoints/model_step_42000.pt\n",
            "Epoch 94:  44% 399/901 [00:47<00:59,  8.46it/s]Step 42050: loss = 2.1692\n",
            "Epoch 94:  44% 400/901 [00:47<00:57,  8.72it/s]Step 42050: loss = 2.1688\n",
            "Epoch 94:  55% 498/901 [00:58<00:49,  8.16it/s]Step 42100: loss = 2.1782\n",
            "Epoch 94:  55% 500/901 [00:58<00:44,  8.99it/s]Step 42100: loss = 2.1776\n",
            "Epoch 94:  66% 598/901 [01:10<00:32,  9.20it/s]Step 42150: loss = 2.1779\n",
            "Epoch 94:  67% 600/901 [01:10<00:32,  9.18it/s]Step 42150: loss = 2.1784\n",
            "Epoch 94:  78% 699/901 [01:21<00:25,  8.02it/s]Step 42200: loss = 2.1846\n",
            "Epoch 94:  78% 700/901 [01:22<00:24,  8.16it/s]Step 42200: loss = 2.1850\n",
            "Epoch 94:  89% 799/901 [01:33<00:11,  9.12it/s]Step 42250: loss = 2.1804\n",
            "Epoch 94:  89% 800/901 [01:34<00:11,  8.43it/s]Step 42250: loss = 2.1797\n",
            "Epoch 94: 100% 898/901 [01:44<00:00,  9.55it/s]Step 42300: loss = 2.1844\n",
            "Epoch 94: 100% 900/901 [01:45<00:00,  9.69it/s]Step 42300: loss = 2.1844\n",
            "Epoch 94: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 94 completed. Average training loss: 2.1844\n",
            "Validation loss after epoch 94: 2.3759\n",
            "Checkpoint saved -> checkpoints/model_epoch_94.pt\n",
            "Epoch 95:   0% 0/901 [00:00<?, ?it/s]Step 42300: loss = 2.1413\n",
            "Epoch 95:  11% 98/901 [00:11<01:34,  8.46it/s]Step 42350: loss = 2.1273\n",
            "Epoch 95:  11% 100/901 [00:11<01:26,  9.27it/s]Step 42350: loss = 2.1297\n",
            "Epoch 95:  22% 199/901 [00:23<01:21,  8.65it/s]Step 42400: loss = 2.1562\n",
            "Epoch 95:  22% 200/901 [00:23<01:24,  8.32it/s]Step 42400: loss = 2.1534\n",
            "Epoch 95:  33% 298/901 [00:34<00:59, 10.10it/s]Step 42450: loss = 2.1786\n",
            "Epoch 95:  33% 300/901 [00:34<01:00,  9.97it/s]Step 42450: loss = 2.1781\n",
            "Epoch 95:  44% 398/901 [00:45<00:57,  8.68it/s]Step 42500: loss = 2.1882\n",
            "Checkpoint saved -> checkpoints/model_step_42500.pt\n",
            "Epoch 95:  44% 400/901 [00:46<01:48,  4.60it/s]Step 42500: loss = 2.1864\n",
            "Checkpoint saved -> checkpoints/model_step_42500.pt\n",
            "Epoch 95:  55% 499/901 [00:58<00:46,  8.72it/s]Step 42550: loss = 2.1911\n",
            "Epoch 95:  55% 500/901 [00:58<00:45,  8.82it/s]Step 42550: loss = 2.1909\n",
            "Epoch 95:  66% 599/901 [01:10<00:40,  7.37it/s]Step 42600: loss = 2.1809\n",
            "Epoch 95:  67% 600/901 [01:10<00:40,  7.38it/s]Step 42600: loss = 2.1814\n",
            "Epoch 95:  78% 699/901 [01:21<00:24,  8.30it/s]Step 42650: loss = 2.1844\n",
            "Epoch 95:  78% 700/901 [01:22<00:23,  8.40it/s]Step 42650: loss = 2.1845\n",
            "Epoch 95:  89% 798/901 [01:33<00:10,  9.51it/s]Step 42700: loss = 2.1770\n",
            "Epoch 95:  89% 800/901 [01:33<00:10,  9.23it/s]Step 42700: loss = 2.1770\n",
            "Epoch 95: 100% 899/901 [01:45<00:00,  8.94it/s]Step 42750: loss = 2.1723\n",
            "Epoch 95: 100% 900/901 [01:45<00:00,  8.18it/s]Step 42750: loss = 2.1722\n",
            "Epoch 95: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 95 completed. Average training loss: 2.1722\n",
            "Validation loss after epoch 95: 2.3747\n",
            "Checkpoint saved -> checkpoints/model_epoch_95.pt\n",
            "Epoch 96:   0% 0/901 [00:00<?, ?it/s]Step 42750: loss = 1.9316\n",
            "Epoch 96:  11% 99/901 [00:12<01:45,  7.60it/s]Step 42800: loss = 2.1075\n",
            "Epoch 96:  11% 100/901 [00:12<01:41,  7.88it/s]Step 42800: loss = 2.1109\n",
            "Epoch 96:  22% 199/901 [00:23<01:26,  8.14it/s]Step 42850: loss = 2.1487\n",
            "Step 42850: loss = 2.1473\n",
            "Epoch 96:  33% 299/901 [00:34<01:17,  7.78it/s]Step 42900: loss = 2.1678\n",
            "Epoch 96:  33% 300/901 [00:35<01:12,  8.31it/s]Step 42900: loss = 2.1653\n",
            "Epoch 96:  44% 398/901 [00:46<00:55,  9.11it/s]Step 42950: loss = 2.1614\n",
            "Epoch 96:  44% 400/901 [00:46<00:54,  9.17it/s]Step 42950: loss = 2.1620\n",
            "Epoch 96:  55% 498/901 [00:58<00:47,  8.48it/s]Step 43000: loss = 2.1716\n",
            "Checkpoint saved -> checkpoints/model_step_43000.pt\n",
            "Epoch 96:  55% 500/901 [00:58<01:15,  5.28it/s]Step 43000: loss = 2.1698\n",
            "Checkpoint saved -> checkpoints/model_step_43000.pt\n",
            "Epoch 96:  66% 598/901 [01:10<00:32,  9.46it/s]Step 43050: loss = 2.1759\n",
            "Epoch 96:  67% 600/901 [01:11<00:30,  9.86it/s]Step 43050: loss = 2.1766\n",
            "Epoch 96:  77% 698/901 [01:22<00:21,  9.56it/s]Step 43100: loss = 2.1761\n",
            "Epoch 96:  78% 700/901 [01:22<00:21,  9.52it/s]Step 43100: loss = 2.1770\n",
            "Epoch 96:  89% 798/901 [01:33<00:10, 10.13it/s]Step 43150: loss = 2.1757\n",
            "Epoch 96:  89% 800/901 [01:34<00:11,  8.91it/s]Step 43150: loss = 2.1751\n",
            "Epoch 96: 100% 899/901 [01:45<00:00,  6.82it/s]Step 43200: loss = 2.1752\n",
            "Epoch 96: 100% 900/901 [01:45<00:00,  7.25it/s]Step 43200: loss = 2.1755\n",
            "Epoch 96: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 96 completed. Average training loss: 2.1755\n",
            "Validation loss after epoch 96: 2.3735\n",
            "Checkpoint saved -> checkpoints/model_epoch_96.pt\n",
            "Epoch 97:   0% 0/901 [00:00<?, ?it/s]Step 43200: loss = 2.7725\n",
            "Epoch 97:  11% 98/901 [00:11<01:28,  9.12it/s]Step 43250: loss = 2.1993\n",
            "Epoch 97:  11% 100/901 [00:11<01:21,  9.84it/s]Step 43250: loss = 2.1928\n",
            "Epoch 97:  22% 198/901 [00:22<01:28,  7.95it/s]Step 43300: loss = 2.1715\n",
            "Epoch 97:  22% 200/901 [00:23<01:17,  9.07it/s]Step 43300: loss = 2.1689\n",
            "Epoch 97:  33% 299/901 [00:35<01:13,  8.21it/s]Step 43350: loss = 2.1634\n",
            "Epoch 97:  33% 300/901 [00:35<01:16,  7.90it/s]Step 43350: loss = 2.1643\n",
            "Epoch 97:  44% 399/901 [00:46<00:57,  8.67it/s]Step 43400: loss = 2.1646\n",
            "Epoch 97:  44% 400/901 [00:46<01:00,  8.28it/s]Step 43400: loss = 2.1628\n",
            "Epoch 97:  55% 498/901 [00:58<00:51,  7.86it/s]Step 43450: loss = 2.1705\n",
            "Epoch 97:  55% 500/901 [00:58<00:48,  8.35it/s]Step 43450: loss = 2.1718\n",
            "Epoch 97:  66% 598/901 [01:09<00:34,  8.72it/s]Step 43500: loss = 2.1825\n",
            "Checkpoint saved -> checkpoints/model_step_43500.pt\n",
            "Epoch 97:  67% 600/901 [01:10<01:01,  4.89it/s]Step 43500: loss = 2.1831\n",
            "Checkpoint saved -> checkpoints/model_step_43500.pt\n",
            "Epoch 97:  77% 698/901 [01:22<00:22,  9.04it/s]Step 43550: loss = 2.1785\n",
            "Epoch 97:  78% 700/901 [01:22<00:21,  9.14it/s]Step 43550: loss = 2.1778\n",
            "Epoch 97:  89% 798/901 [01:33<00:11,  9.10it/s]Step 43600: loss = 2.1785\n",
            "Epoch 97:  89% 800/901 [01:33<00:10,  9.19it/s]Step 43600: loss = 2.1784\n",
            "Epoch 97: 100% 899/901 [01:45<00:00,  8.14it/s]Step 43650: loss = 2.1707\n",
            "Epoch 97: 100% 900/901 [01:45<00:00,  8.47it/s]Step 43650: loss = 2.1704\n",
            "Epoch 97: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 97 completed. Average training loss: 2.1704\n",
            "Validation loss after epoch 97: 2.3724\n",
            "Checkpoint saved -> checkpoints/model_epoch_97.pt\n",
            "Epoch 98:   0% 0/901 [00:00<?, ?it/s]Step 43650: loss = 1.7971\n",
            "Epoch 98:  11% 98/901 [00:11<01:41,  7.91it/s]Step 43700: loss = 2.1340\n",
            "Epoch 98:  11% 100/901 [00:11<01:31,  8.79it/s]Step 43700: loss = 2.1311\n",
            "Epoch 98:  22% 198/901 [00:23<01:12,  9.69it/s]Step 43750: loss = 2.1544\n",
            "Epoch 98:  22% 200/901 [00:23<01:12,  9.71it/s]Step 43750: loss = 2.1544\n",
            "Epoch 98:  33% 299/901 [00:34<01:07,  8.90it/s]Step 43800: loss = 2.1627\n",
            "Epoch 98:  33% 300/901 [00:34<01:08,  8.78it/s]Step 43800: loss = 2.1617\n",
            "Epoch 98:  44% 399/901 [00:46<00:49, 10.21it/s]Step 43850: loss = 2.1697\n",
            "Step 43850: loss = 2.1694\n",
            "Epoch 98:  55% 498/901 [00:57<00:46,  8.60it/s]Step 43900: loss = 2.1861\n",
            "Epoch 98:  55% 500/901 [00:57<00:42,  9.34it/s]Step 43900: loss = 2.1876\n",
            "Epoch 98:  66% 598/901 [01:09<00:44,  6.75it/s]Step 43950: loss = 2.1770\n",
            "Epoch 98:  67% 600/901 [01:09<00:38,  7.89it/s]Step 43950: loss = 2.1760\n",
            "Epoch 98:  78% 699/901 [01:21<00:23,  8.68it/s]Step 44000: loss = 2.1737\n",
            "Checkpoint saved -> checkpoints/model_step_44000.pt\n",
            "Epoch 98:  78% 700/901 [01:22<00:50,  3.99it/s]Step 44000: loss = 2.1739\n",
            "Checkpoint saved -> checkpoints/model_step_44000.pt\n",
            "Epoch 98:  89% 798/901 [01:33<00:11,  9.01it/s]Step 44050: loss = 2.1764\n",
            "Epoch 98:  89% 800/901 [01:34<00:10,  9.48it/s]Step 44050: loss = 2.1765\n",
            "Epoch 98: 100% 898/901 [01:45<00:00,  8.75it/s]Step 44100: loss = 2.1821\n",
            "Epoch 98: 100% 900/901 [01:45<00:00,  9.50it/s]Step 44100: loss = 2.1818\n",
            "Epoch 98: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 98 completed. Average training loss: 2.1818\n",
            "Validation loss after epoch 98: 2.3712\n",
            "Checkpoint saved -> checkpoints/model_epoch_98.pt\n",
            "Epoch 99:   0% 0/901 [00:00<?, ?it/s]Step 44100: loss = 2.6461\n",
            "Epoch 99:  11% 99/901 [00:11<01:30,  8.82it/s]Step 44150: loss = 2.1918\n",
            "Epoch 99:  11% 100/901 [00:11<01:37,  8.19it/s]Step 44150: loss = 2.1866\n",
            "Epoch 99:  22% 199/901 [00:22<01:27,  7.98it/s]Step 44200: loss = 2.1860\n",
            "Epoch 99:  22% 200/901 [00:23<01:37,  7.18it/s]Step 44200: loss = 2.1859\n",
            "Epoch 99:  33% 298/901 [00:33<01:06,  9.05it/s]Step 44250: loss = 2.2036\n",
            "Epoch 99:  33% 300/901 [00:34<01:03,  9.51it/s]Step 44250: loss = 2.2049\n",
            "Epoch 99:  44% 398/901 [00:45<00:59,  8.41it/s]Step 44300: loss = 2.1854\n",
            "Epoch 99:  44% 400/901 [00:45<00:56,  8.84it/s]Step 44300: loss = 2.1866\n",
            "Epoch 99:  55% 499/901 [00:57<00:50,  7.96it/s]Step 44350: loss = 2.1743\n",
            "Epoch 99:  55% 500/901 [00:57<00:50,  7.87it/s]Step 44350: loss = 2.1747\n",
            "Epoch 99:  66% 599/901 [01:09<00:38,  7.77it/s]Step 44400: loss = 2.1721\n",
            "Epoch 99:  67% 600/901 [01:09<00:40,  7.41it/s]Step 44400: loss = 2.1716\n",
            "Epoch 99:  78% 699/901 [01:21<00:22,  8.81it/s]Step 44450: loss = 2.1723\n",
            "Epoch 99:  78% 700/901 [01:21<00:22,  8.86it/s]Step 44450: loss = 2.1718\n",
            "Epoch 99:  89% 798/901 [01:32<00:12,  8.46it/s]Step 44500: loss = 2.1771\n",
            "Checkpoint saved -> checkpoints/model_step_44500.pt\n",
            "Epoch 99:  89% 800/901 [01:33<00:24,  4.08it/s]Step 44500: loss = 2.1772\n",
            "Checkpoint saved -> checkpoints/model_step_44500.pt\n",
            "Epoch 99: 100% 898/901 [01:45<00:00,  8.19it/s]Step 44550: loss = 2.1749\n",
            "Epoch 99: 100% 900/901 [01:45<00:00,  8.80it/s]Step 44550: loss = 2.1746\n",
            "Epoch 99: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 99 completed. Average training loss: 2.1746\n",
            "Validation loss after epoch 99: 2.3701\n",
            "Checkpoint saved -> checkpoints/model_epoch_99.pt\n",
            "Epoch 100:   0% 0/901 [00:00<?, ?it/s]Step 44550: loss = 2.6732\n",
            "Epoch 100:  11% 98/901 [00:11<01:39,  8.11it/s]Step 44600: loss = 2.1953\n",
            "Epoch 100:  11% 100/901 [00:12<01:36,  8.31it/s]Step 44600: loss = 2.1982\n",
            "Epoch 100:  22% 199/901 [00:23<01:13,  9.51it/s]Step 44650: loss = 2.2086\n",
            "Epoch 100:  22% 200/901 [00:23<01:16,  9.21it/s]Step 44650: loss = 2.2098\n",
            "Epoch 100:  33% 299/901 [00:34<01:08,  8.73it/s]Step 44700: loss = 2.1952\n",
            "Step 44700: loss = 2.1975\n",
            "Epoch 100:  44% 398/901 [00:46<00:56,  8.87it/s]Step 44750: loss = 2.1999\n",
            "Epoch 100:  44% 400/901 [00:46<00:53,  9.44it/s]Step 44750: loss = 2.2012\n",
            "Epoch 100:  55% 499/901 [00:57<00:51,  7.78it/s]Step 44800: loss = 2.1914\n",
            "Epoch 100:  55% 500/901 [00:57<00:54,  7.33it/s]Step 44800: loss = 2.1909\n",
            "Epoch 100:  66% 599/901 [01:09<00:34,  8.67it/s]Step 44850: loss = 2.1862\n",
            "Epoch 100:  67% 600/901 [01:09<00:34,  8.75it/s]Step 44850: loss = 2.1854\n",
            "Epoch 100:  78% 699/901 [01:20<00:22,  8.79it/s]Step 44900: loss = 2.1970\n",
            "Epoch 100:  78% 700/901 [01:20<00:22,  8.98it/s]Step 44900: loss = 2.1975\n",
            "Epoch 100:  89% 799/901 [01:31<00:11,  9.09it/s]Step 44950: loss = 2.1922\n",
            "Epoch 100:  89% 800/901 [01:31<00:11,  9.08it/s]Step 44950: loss = 2.1931\n",
            "Epoch 100: 100% 899/901 [01:44<00:00,  8.72it/s]Step 45000: loss = 2.1792\n",
            "Checkpoint saved -> checkpoints/model_step_45000.pt\n",
            "Epoch 100: 100% 900/901 [01:44<00:00,  4.01it/s]Step 45000: loss = 2.1788\n",
            "Checkpoint saved -> checkpoints/model_step_45000.pt\n",
            "Epoch 100: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 100 completed. Average training loss: 2.1788\n",
            "Validation loss after epoch 100: 2.3689\n",
            "Checkpoint saved -> checkpoints/model_epoch_100.pt\n",
            "Epoch 101:   0% 0/901 [00:00<?, ?it/s]Step 45000: loss = 2.6602\n",
            "Checkpoint saved -> checkpoints/model_step_45000.pt\n",
            "Epoch 101:  11% 98/901 [00:12<01:15, 10.57it/s]Step 45050: loss = 2.1183\n",
            "Epoch 101:  11% 100/901 [00:12<01:22,  9.70it/s]Step 45050: loss = 2.1160\n",
            "Epoch 101:  22% 199/901 [00:23<01:18,  8.89it/s]Step 45100: loss = 2.1485\n",
            "Epoch 101:  22% 200/901 [00:23<01:20,  8.68it/s]Step 45100: loss = 2.1486\n",
            "Epoch 101:  33% 298/901 [00:35<01:20,  7.47it/s]Step 45150: loss = 2.1537\n",
            "Epoch 101:  33% 300/901 [00:35<01:10,  8.57it/s]Step 45150: loss = 2.1556\n",
            "Epoch 101:  44% 398/901 [00:47<00:55,  9.08it/s]Step 45200: loss = 2.1531\n",
            "Epoch 101:  44% 400/901 [00:47<00:58,  8.60it/s]Step 45200: loss = 2.1541\n",
            "Epoch 101:  55% 499/901 [00:58<00:42,  9.52it/s]Step 45250: loss = 2.1734\n",
            "Epoch 101:  55% 500/901 [00:58<00:42,  9.37it/s]Step 45250: loss = 2.1748\n",
            "Epoch 101:  66% 598/901 [01:09<00:33,  9.05it/s]Step 45300: loss = 2.1828\n",
            "Epoch 101:  67% 600/901 [01:09<00:34,  8.80it/s]Step 45300: loss = 2.1833\n",
            "Epoch 101:  77% 698/901 [01:20<00:21,  9.24it/s]Step 45350: loss = 2.1808\n",
            "Epoch 101:  78% 700/901 [01:21<00:21,  9.51it/s]Step 45350: loss = 2.1803\n",
            "Epoch 101:  89% 798/901 [01:32<00:11,  9.00it/s]Step 45400: loss = 2.1782\n",
            "Epoch 101:  89% 800/901 [01:32<00:11,  8.53it/s]Step 45400: loss = 2.1794\n",
            "Epoch 101: 100% 898/901 [01:44<00:00,  9.31it/s]Step 45450: loss = 2.1750\n",
            "Epoch 101: 100% 900/901 [01:44<00:00,  9.42it/s]Step 45450: loss = 2.1749\n",
            "Epoch 101: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 101 completed. Average training loss: 2.1749\n",
            "Validation loss after epoch 101: 2.3678\n",
            "Checkpoint saved -> checkpoints/model_epoch_101.pt\n",
            "Epoch 102:   0% 0/901 [00:00<?, ?it/s]Step 45450: loss = 1.7490\n",
            "Epoch 102:  11% 98/901 [00:11<01:49,  7.34it/s]Step 45500: loss = 2.1463\n",
            "Checkpoint saved -> checkpoints/model_step_45500.pt\n",
            "Epoch 102:  11% 100/901 [00:12<03:25,  3.90it/s]Step 45500: loss = 2.1465\n",
            "Checkpoint saved -> checkpoints/model_step_45500.pt\n",
            "Epoch 102:  22% 198/901 [00:23<01:29,  7.85it/s]Step 45550: loss = 2.1738\n",
            "Epoch 102:  22% 200/901 [00:24<01:23,  8.38it/s]Step 45550: loss = 2.1746\n",
            "Epoch 102:  33% 299/901 [00:35<01:06,  9.08it/s]Step 45600: loss = 2.1655\n",
            "Epoch 102:  33% 300/901 [00:35<01:11,  8.43it/s]Step 45600: loss = 2.1659\n",
            "Epoch 102:  44% 399/901 [00:47<00:59,  8.50it/s]Step 45650: loss = 2.1512\n",
            "Epoch 102:  44% 400/901 [00:47<00:59,  8.45it/s]Step 45650: loss = 2.1493\n",
            "Epoch 102:  55% 498/901 [00:58<00:40,  9.96it/s]Step 45700: loss = 2.1636\n",
            "Epoch 102:  55% 500/901 [00:59<00:39, 10.15it/s]Step 45700: loss = 2.1638\n",
            "Epoch 102:  66% 598/901 [01:10<00:42,  7.09it/s]Step 45750: loss = 2.1579\n",
            "Epoch 102:  67% 600/901 [01:10<00:37,  8.03it/s]Step 45750: loss = 2.1573\n",
            "Epoch 102:  77% 698/901 [01:22<00:26,  7.57it/s]Step 45800: loss = 2.1554\n",
            "Epoch 102:  78% 700/901 [01:22<00:25,  7.95it/s]Step 45800: loss = 2.1557\n",
            "Epoch 102:  89% 799/901 [01:33<00:11,  9.10it/s]Step 45850: loss = 2.1659\n",
            "Epoch 102:  89% 800/901 [01:33<00:12,  8.30it/s]Step 45850: loss = 2.1658\n",
            "Epoch 102: 100% 898/901 [01:45<00:00,  8.31it/s]Step 45900: loss = 2.1609\n",
            "Epoch 102: 100% 900/901 [01:45<00:00,  8.98it/s]Step 45900: loss = 2.1611\n",
            "Epoch 102: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 102 completed. Average training loss: 2.1611\n",
            "Validation loss after epoch 102: 2.3666\n",
            "Checkpoint saved -> checkpoints/model_epoch_102.pt\n",
            "Epoch 103:   0% 0/901 [00:00<?, ?it/s]Step 45900: loss = 2.5747\n",
            "Epoch 103:  11% 99/901 [00:11<01:34,  8.47it/s]Step 45950: loss = 2.1291\n",
            "Epoch 103:  11% 100/901 [00:11<01:35,  8.36it/s]Step 45950: loss = 2.1286\n",
            "Epoch 103:  22% 198/901 [00:22<01:23,  8.45it/s]Step 46000: loss = 2.1657\n",
            "Checkpoint saved -> checkpoints/model_step_46000.pt\n",
            "Epoch 103:  22% 200/901 [00:23<02:26,  4.77it/s]Step 46000: loss = 2.1646\n",
            "Checkpoint saved -> checkpoints/model_step_46000.pt\n",
            "Epoch 103:  33% 298/901 [00:35<01:09,  8.62it/s]Step 46050: loss = 2.1707\n",
            "Epoch 103:  33% 300/901 [00:35<01:06,  9.09it/s]Step 46050: loss = 2.1704\n",
            "Epoch 103:  44% 398/901 [00:47<00:57,  8.74it/s]Step 46100: loss = 2.1718\n",
            "Epoch 103:  44% 400/901 [00:47<00:53,  9.43it/s]Step 46100: loss = 2.1727\n",
            "Epoch 103:  55% 498/901 [00:58<00:45,  8.87it/s]Step 46150: loss = 2.1822\n",
            "Epoch 103:  55% 500/901 [00:58<00:50,  7.92it/s]Step 46150: loss = 2.1817\n",
            "Epoch 103:  66% 598/901 [01:09<00:29, 10.16it/s]Step 46200: loss = 2.1825\n",
            "Epoch 103:  67% 600/901 [01:10<00:30,  9.89it/s]Step 46200: loss = 2.1830\n",
            "Epoch 103:  78% 699/901 [01:21<00:27,  7.48it/s]Step 46250: loss = 2.1854\n",
            "Epoch 103:  78% 700/901 [01:21<00:25,  7.88it/s]Step 46250: loss = 2.1856\n",
            "Epoch 103:  89% 799/901 [01:33<00:14,  6.91it/s]Step 46300: loss = 2.1859\n",
            "Step 46300: loss = 2.1862\n",
            "Epoch 103: 100% 898/901 [01:44<00:00,  7.69it/s]Step 46350: loss = 2.1828\n",
            "Epoch 103: 100% 900/901 [01:44<00:00,  7.99it/s]Step 46350: loss = 2.1822\n",
            "Epoch 103: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 103 completed. Average training loss: 2.1822\n",
            "Validation loss after epoch 103: 2.3655\n",
            "Checkpoint saved -> checkpoints/model_epoch_103.pt\n",
            "Epoch 104:   0% 0/901 [00:00<?, ?it/s]Step 46350: loss = 2.4096\n",
            "Epoch 104:  11% 98/901 [00:11<02:20,  5.71it/s]Step 46400: loss = 2.2319\n",
            "Epoch 104:  11% 100/901 [00:11<01:57,  6.84it/s]Step 46400: loss = 2.2277\n",
            "Epoch 104:  22% 198/901 [00:22<01:17,  9.05it/s]Step 46450: loss = 2.2117\n",
            "Epoch 104:  22% 200/901 [00:23<01:15,  9.24it/s]Step 46450: loss = 2.2115\n",
            "Epoch 104:  33% 298/901 [00:34<01:18,  7.67it/s]Step 46500: loss = 2.1959\n",
            "Checkpoint saved -> checkpoints/model_step_46500.pt\n",
            "Epoch 104:  33% 300/901 [00:35<02:10,  4.61it/s]Step 46500: loss = 2.1941\n",
            "Checkpoint saved -> checkpoints/model_step_46500.pt\n",
            "Epoch 104:  44% 398/901 [00:47<00:59,  8.44it/s]Step 46550: loss = 2.1833\n",
            "Epoch 104:  44% 400/901 [00:47<00:58,  8.53it/s]Step 46550: loss = 2.1823\n",
            "Epoch 104:  55% 499/901 [00:59<00:45,  8.81it/s]Step 46600: loss = 2.1709\n",
            "Epoch 104:  55% 500/901 [00:59<00:45,  8.82it/s]Step 46600: loss = 2.1710\n",
            "Epoch 104:  66% 598/901 [01:11<00:31,  9.52it/s]Step 46650: loss = 2.1651\n",
            "Epoch 104:  67% 600/901 [01:11<00:31,  9.61it/s]Step 46650: loss = 2.1651\n",
            "Epoch 104:  77% 698/901 [01:22<00:20, 10.11it/s]Step 46700: loss = 2.1677\n",
            "Epoch 104:  78% 700/901 [01:22<00:20, 10.00it/s]Step 46700: loss = 2.1669\n",
            "Epoch 104:  89% 798/901 [01:33<00:12,  8.17it/s]Step 46750: loss = 2.1738\n",
            "Epoch 104:  89% 800/901 [01:33<00:11,  8.51it/s]Step 46750: loss = 2.1732\n",
            "Epoch 104: 100% 898/901 [01:45<00:00,  7.96it/s]Step 46800: loss = 2.1739\n",
            "Epoch 104: 100% 900/901 [01:45<00:00,  8.35it/s]Step 46800: loss = 2.1738\n",
            "Epoch 104: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 104 completed. Average training loss: 2.1738\n",
            "Validation loss after epoch 104: 2.3644\n",
            "Checkpoint saved -> checkpoints/model_epoch_104.pt\n",
            "Epoch 105:   0% 0/901 [00:00<?, ?it/s]Step 46800: loss = 2.4064\n",
            "Epoch 105:  11% 99/901 [00:11<01:30,  8.89it/s]Step 46850: loss = 2.2040\n",
            "Epoch 105:  11% 100/901 [00:11<01:29,  8.90it/s]Step 46850: loss = 2.2022\n",
            "Epoch 105:  22% 198/901 [00:22<01:15,  9.30it/s]Step 46900: loss = 2.2236\n",
            "Epoch 105:  22% 200/901 [00:22<01:10,  9.98it/s]Step 46900: loss = 2.2223\n",
            "Epoch 105:  33% 298/901 [00:34<01:17,  7.75it/s]Step 46950: loss = 2.2046\n",
            "Epoch 105:  33% 300/901 [00:34<01:09,  8.66it/s]Step 46950: loss = 2.2060\n",
            "Epoch 105:  44% 398/901 [00:45<01:00,  8.28it/s]Step 47000: loss = 2.2095\n",
            "Checkpoint saved -> checkpoints/model_step_47000.pt\n",
            "Epoch 105:  44% 400/901 [00:45<01:37,  5.15it/s]Step 47000: loss = 2.2091\n",
            "Checkpoint saved -> checkpoints/model_step_47000.pt\n",
            "Epoch 105:  55% 499/901 [00:57<00:52,  7.59it/s]Step 47050: loss = 2.2031\n",
            "Epoch 105:  55% 500/901 [00:57<00:53,  7.53it/s]Step 47050: loss = 2.2041\n",
            "Epoch 105:  66% 598/901 [01:09<00:44,  6.83it/s]Step 47100: loss = 2.1915\n",
            "Epoch 105:  67% 600/901 [01:10<00:42,  7.16it/s]Step 47100: loss = 2.1916\n",
            "Epoch 105:  77% 698/901 [01:21<00:24,  8.23it/s]Step 47150: loss = 2.1865\n",
            "Epoch 105:  78% 700/901 [01:21<00:22,  8.96it/s]Step 47150: loss = 2.1861\n",
            "Epoch 105:  89% 798/901 [01:33<00:11,  8.88it/s]Step 47200: loss = 2.1823\n",
            "Epoch 105:  89% 800/901 [01:33<00:10,  9.25it/s]Step 47200: loss = 2.1820\n",
            "Epoch 105: 100% 898/901 [01:44<00:00,  8.63it/s]Step 47250: loss = 2.1845\n",
            "Epoch 105: 100% 900/901 [01:44<00:00,  9.56it/s]Step 47250: loss = 2.1842\n",
            "Epoch 105: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 105 completed. Average training loss: 2.1842\n",
            "Validation loss after epoch 105: 2.3633\n",
            "Checkpoint saved -> checkpoints/model_epoch_105.pt\n",
            "Epoch 106:   0% 0/901 [00:00<?, ?it/s]Step 47250: loss = 2.4730\n",
            "Epoch 106:  11% 98/901 [00:11<01:42,  7.83it/s]Step 47300: loss = 2.1380\n",
            "Epoch 106:  11% 100/901 [00:11<01:31,  8.72it/s]Step 47300: loss = 2.1445\n",
            "Epoch 106:  22% 199/901 [00:23<01:27,  8.07it/s]Step 47350: loss = 2.1372\n",
            "Epoch 106:  22% 200/901 [00:23<01:26,  8.07it/s]Step 47350: loss = 2.1397\n",
            "Epoch 106:  33% 299/901 [00:35<01:02,  9.63it/s]Step 47400: loss = 2.1591\n",
            "Step 47400: loss = 2.1599\n",
            "Epoch 106:  44% 398/901 [00:46<01:00,  8.31it/s]Step 47450: loss = 2.1688\n",
            "Epoch 106:  44% 400/901 [00:46<00:58,  8.60it/s]Step 47450: loss = 2.1678\n",
            "Epoch 106:  55% 499/901 [00:57<00:50,  7.90it/s]Step 47500: loss = 2.1665\n",
            "Checkpoint saved -> checkpoints/model_step_47500.pt\n",
            "Epoch 106:  55% 500/901 [00:58<01:37,  4.12it/s]Step 47500: loss = 2.1654\n",
            "Checkpoint saved -> checkpoints/model_step_47500.pt\n",
            "Epoch 106:  66% 599/901 [01:10<00:34,  8.83it/s]Step 47550: loss = 2.1689\n",
            "Epoch 106:  67% 600/901 [01:10<00:37,  7.97it/s]Step 47550: loss = 2.1685\n",
            "Epoch 106:  77% 698/901 [01:22<00:23,  8.61it/s]Step 47600: loss = 2.1590\n",
            "Epoch 106:  78% 700/901 [01:22<00:22,  8.98it/s]Step 47600: loss = 2.1598\n",
            "Epoch 106:  89% 799/901 [01:33<00:12,  8.47it/s]Step 47650: loss = 2.1655\n",
            "Epoch 106:  89% 800/901 [01:34<00:12,  8.04it/s]Step 47650: loss = 2.1660\n",
            "Epoch 106: 100% 899/901 [01:45<00:00,  7.30it/s]Step 47700: loss = 2.1670\n",
            "Epoch 106: 100% 900/901 [01:45<00:00,  7.37it/s]Step 47700: loss = 2.1669\n",
            "Epoch 106: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 106 completed. Average training loss: 2.1669\n",
            "Validation loss after epoch 106: 2.3622\n",
            "Checkpoint saved -> checkpoints/model_epoch_106.pt\n",
            "Epoch 107:   0% 0/901 [00:00<?, ?it/s]Step 47700: loss = 1.6359\n",
            "Epoch 107:  11% 98/901 [00:11<01:27,  9.15it/s]Step 47750: loss = 2.1143\n",
            "Epoch 107:  11% 100/901 [00:11<01:20,  9.89it/s]Step 47750: loss = 2.1164\n",
            "Epoch 107:  22% 198/901 [00:22<01:09, 10.19it/s]Step 47800: loss = 2.1903\n",
            "Epoch 107:  22% 200/901 [00:22<01:13,  9.60it/s]Step 47800: loss = 2.1905\n",
            "Epoch 107:  33% 299/901 [00:34<01:18,  7.71it/s]Step 47850: loss = 2.1801\n",
            "Epoch 107:  33% 300/901 [00:34<01:26,  6.96it/s]Step 47850: loss = 2.1796\n",
            "Epoch 107:  44% 399/901 [00:45<01:00,  8.34it/s]Step 47900: loss = 2.1767\n",
            "Epoch 107:  44% 400/901 [00:45<01:00,  8.31it/s]Step 47900: loss = 2.1784\n",
            "Epoch 107:  55% 498/901 [00:56<00:48,  8.32it/s]Step 47950: loss = 2.1826\n",
            "Epoch 107:  55% 500/901 [00:57<00:46,  8.60it/s]Step 47950: loss = 2.1824\n",
            "Epoch 107:  66% 599/901 [01:08<00:33,  9.01it/s]Step 48000: loss = 2.1801\n",
            "Checkpoint saved -> checkpoints/model_step_48000.pt\n",
            "Epoch 107:  67% 600/901 [01:09<01:06,  4.50it/s]Step 48000: loss = 2.1794\n",
            "Checkpoint saved -> checkpoints/model_step_48000.pt\n",
            "Epoch 107:  77% 698/901 [01:21<00:21,  9.25it/s]Step 48050: loss = 2.1765\n",
            "Epoch 107:  78% 700/901 [01:21<00:22,  9.02it/s]Step 48050: loss = 2.1761\n",
            "Epoch 107:  89% 799/901 [01:33<00:13,  7.70it/s]Step 48100: loss = 2.1687\n",
            "Epoch 107:  89% 800/901 [01:33<00:12,  8.10it/s]Step 48100: loss = 2.1680\n",
            "Epoch 107: 100% 899/901 [01:45<00:00,  8.03it/s]Step 48150: loss = 2.1679\n",
            "Epoch 107: 100% 900/901 [01:45<00:00,  8.18it/s]Step 48150: loss = 2.1677\n",
            "Epoch 107: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 107 completed. Average training loss: 2.1677\n",
            "Validation loss after epoch 107: 2.3612\n",
            "Checkpoint saved -> checkpoints/model_epoch_107.pt\n",
            "Epoch 108:   0% 0/901 [00:00<?, ?it/s]Step 48150: loss = 1.4316\n",
            "Epoch 108:  11% 98/901 [00:11<01:34,  8.46it/s]Step 48200: loss = 2.2039\n",
            "Epoch 108:  11% 100/901 [00:11<01:34,  8.43it/s]Step 48200: loss = 2.2115\n",
            "Epoch 108:  22% 198/901 [00:22<01:39,  7.04it/s]Step 48250: loss = 2.2013\n",
            "Epoch 108:  22% 200/901 [00:22<01:26,  8.08it/s]Step 48250: loss = 2.1997\n",
            "Epoch 108:  33% 299/901 [00:33<01:05,  9.12it/s]Step 48300: loss = 2.2097\n",
            "Epoch 108:  33% 300/901 [00:34<01:05,  9.19it/s]Step 48300: loss = 2.2095\n",
            "Epoch 108:  44% 398/901 [00:45<00:54,  9.15it/s]Step 48350: loss = 2.2044\n",
            "Epoch 108:  44% 400/901 [00:45<00:53,  9.34it/s]Step 48350: loss = 2.2043\n",
            "Epoch 108:  55% 498/901 [00:56<00:50,  8.00it/s]Step 48400: loss = 2.1985\n",
            "Epoch 108:  55% 500/901 [00:57<00:48,  8.24it/s]Step 48400: loss = 2.1976\n",
            "Epoch 108:  66% 599/901 [01:08<00:32,  9.28it/s]Step 48450: loss = 2.1891\n",
            "Epoch 108:  67% 600/901 [01:08<00:32,  9.21it/s]Step 48450: loss = 2.1893\n",
            "Epoch 108:  78% 699/901 [01:20<00:25,  8.01it/s]Step 48500: loss = 2.1784\n",
            "Checkpoint saved -> checkpoints/model_step_48500.pt\n",
            "Epoch 108:  78% 700/901 [01:21<00:57,  3.47it/s]Step 48500: loss = 2.1789\n",
            "Checkpoint saved -> checkpoints/model_step_48500.pt\n",
            "Epoch 108:  89% 799/901 [01:33<00:15,  6.70it/s]Step 48550: loss = 2.1757\n",
            "Epoch 108:  89% 800/901 [01:33<00:14,  7.19it/s]Step 48550: loss = 2.1755\n",
            "Epoch 108: 100% 898/901 [01:45<00:00,  9.09it/s]Step 48600: loss = 2.1729\n",
            "Epoch 108: 100% 900/901 [01:45<00:00,  9.77it/s]Step 48600: loss = 2.1727\n",
            "Epoch 108: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 108 completed. Average training loss: 2.1727\n",
            "Validation loss after epoch 108: 2.3601\n",
            "Checkpoint saved -> checkpoints/model_epoch_108.pt\n",
            "Epoch 109:   0% 0/901 [00:00<?, ?it/s]Step 48600: loss = 2.5268\n",
            "Epoch 109:  11% 98/901 [00:11<01:43,  7.75it/s]Step 48650: loss = 2.1469\n",
            "Epoch 109:  11% 100/901 [00:11<01:32,  8.67it/s]Step 48650: loss = 2.1550\n",
            "Epoch 109:  22% 198/901 [00:22<01:20,  8.75it/s]Step 48700: loss = 2.1825\n",
            "Epoch 109:  22% 200/901 [00:22<01:13,  9.48it/s]Step 48700: loss = 2.1840\n",
            "Epoch 109:  33% 299/901 [00:34<01:13,  8.17it/s]Step 48750: loss = 2.1675\n",
            "Epoch 109:  33% 300/901 [00:34<01:19,  7.52it/s]Step 48750: loss = 2.1698\n",
            "Epoch 109:  44% 399/901 [00:45<01:00,  8.30it/s]Step 48800: loss = 2.1801\n",
            "Step 48800: loss = 2.1810\n",
            "Epoch 109:  55% 498/901 [00:57<00:47,  8.57it/s]Step 48850: loss = 2.1725\n",
            "Epoch 109:  55% 500/901 [00:57<00:43,  9.21it/s]Step 48850: loss = 2.1723\n",
            "Epoch 109:  66% 598/901 [01:08<00:29, 10.10it/s]Step 48900: loss = 2.1766\n",
            "Epoch 109:  67% 600/901 [01:09<00:28, 10.46it/s]Step 48900: loss = 2.1760\n",
            "Epoch 109:  77% 698/901 [01:20<00:22,  9.06it/s]Step 48950: loss = 2.1746\n",
            "Epoch 109:  78% 700/901 [01:20<00:22,  8.96it/s]Step 48950: loss = 2.1752\n",
            "Epoch 109:  89% 798/901 [01:31<00:13,  7.44it/s]Step 49000: loss = 2.1798\n",
            "Checkpoint saved -> checkpoints/model_step_49000.pt\n",
            "Epoch 109:  89% 800/901 [01:32<00:23,  4.29it/s]Step 49000: loss = 2.1797\n",
            "Checkpoint saved -> checkpoints/model_step_49000.pt\n",
            "Epoch 109: 100% 899/901 [01:44<00:00,  7.97it/s]Step 49050: loss = 2.1767\n",
            "Epoch 109: 100% 900/901 [01:44<00:00,  7.88it/s]Step 49050: loss = 2.1771\n",
            "Epoch 109: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 109 completed. Average training loss: 2.1771\n",
            "Validation loss after epoch 109: 2.3590\n",
            "Checkpoint saved -> checkpoints/model_epoch_109.pt\n",
            "Epoch 110:   0% 0/901 [00:00<?, ?it/s]Step 49050: loss = 2.3904\n",
            "Epoch 110:  11% 99/901 [00:11<01:26,  9.23it/s]Step 49100: loss = 2.1637\n",
            "Epoch 110:  11% 100/901 [00:11<01:30,  8.85it/s]Step 49100: loss = 2.1718\n",
            "Epoch 110:  22% 199/901 [00:23<01:14,  9.48it/s]Step 49150: loss = 2.1590\n",
            "Epoch 110:  22% 200/901 [00:23<01:14,  9.36it/s]Step 49150: loss = 2.1577\n",
            "Epoch 110:  33% 298/901 [00:34<01:06,  9.02it/s]Step 49200: loss = 2.1532\n",
            "Epoch 110:  33% 300/901 [00:34<01:03,  9.44it/s]Step 49200: loss = 2.1528\n",
            "Epoch 110:  44% 398/901 [00:46<00:54,  9.21it/s]Step 49250: loss = 2.1659\n",
            "Epoch 110:  44% 400/901 [00:46<00:52,  9.59it/s]Step 49250: loss = 2.1665\n",
            "Epoch 110:  55% 498/901 [00:58<00:40,  9.86it/s]Step 49300: loss = 2.1543\n",
            "Epoch 110:  55% 500/901 [00:58<00:43,  9.24it/s]Step 49300: loss = 2.1545\n",
            "Epoch 110:  66% 599/901 [01:10<00:33,  9.08it/s]Step 49350: loss = 2.1500\n",
            "Epoch 110:  67% 600/901 [01:10<00:32,  9.18it/s]Step 49350: loss = 2.1499\n",
            "Epoch 110:  77% 698/901 [01:21<00:22,  9.13it/s]Step 49400: loss = 2.1565\n",
            "Epoch 110:  78% 700/901 [01:21<00:21,  9.24it/s]Step 49400: loss = 2.1563\n",
            "Epoch 110:  89% 798/901 [01:32<00:11,  9.19it/s]Step 49450: loss = 2.1696\n",
            "Epoch 110:  89% 800/901 [01:32<00:10,  9.78it/s]Step 49450: loss = 2.1699\n",
            "Epoch 110: 100% 898/901 [01:44<00:00,  7.28it/s]Step 49500: loss = 2.1641\n",
            "Checkpoint saved -> checkpoints/model_step_49500.pt\n",
            "Epoch 110: 100% 900/901 [01:44<00:00,  4.68it/s]Step 49500: loss = 2.1640\n",
            "Checkpoint saved -> checkpoints/model_step_49500.pt\n",
            "Epoch 110: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 110 completed. Average training loss: 2.1640\n",
            "Validation loss after epoch 110: 2.3580\n",
            "Checkpoint saved -> checkpoints/model_epoch_110.pt\n",
            "Epoch 111:   0% 0/901 [00:00<?, ?it/s]Step 49500: loss = 2.4869\n",
            "Checkpoint saved -> checkpoints/model_step_49500.pt\n",
            "Epoch 111:  11% 99/901 [00:12<01:26,  9.26it/s]Step 49550: loss = 2.1341\n",
            "Epoch 111:  11% 100/901 [00:12<01:28,  9.04it/s]Step 49550: loss = 2.1290\n",
            "Epoch 111:  22% 199/901 [00:23<01:16,  9.15it/s]Step 49600: loss = 2.1630\n",
            "Step 49600: loss = 2.1628\n",
            "Epoch 111:  33% 298/901 [00:35<01:08,  8.79it/s]Step 49650: loss = 2.1415\n",
            "Epoch 111:  33% 300/901 [00:35<01:02,  9.63it/s]Step 49650: loss = 2.1416\n",
            "Epoch 111:  44% 398/901 [00:47<00:51,  9.85it/s]Step 49700: loss = 2.1483\n",
            "Epoch 111:  44% 400/901 [00:47<00:49, 10.21it/s]Step 49700: loss = 2.1489\n",
            "Epoch 111:  55% 499/901 [00:58<00:38, 10.33it/s]Step 49750: loss = 2.1648\n",
            "Step 49750: loss = 2.1662\n",
            "Epoch 111:  66% 599/901 [01:09<00:38,  7.83it/s]Step 49800: loss = 2.1699\n",
            "Epoch 111:  67% 600/901 [01:10<00:36,  8.26it/s]Step 49800: loss = 2.1704\n",
            "Epoch 111:  78% 699/901 [01:21<00:26,  7.76it/s]Step 49850: loss = 2.1671\n",
            "Epoch 111:  78% 700/901 [01:21<00:27,  7.40it/s]Step 49850: loss = 2.1677\n",
            "Epoch 111:  89% 798/901 [01:32<00:10,  9.60it/s]Step 49900: loss = 2.1676\n",
            "Epoch 111:  89% 800/901 [01:33<00:10,  9.19it/s]Step 49900: loss = 2.1677\n",
            "Epoch 111: 100% 899/901 [01:44<00:00,  7.78it/s]Step 49950: loss = 2.1651\n",
            "Epoch 111: 100% 900/901 [01:44<00:00,  7.63it/s]Step 49950: loss = 2.1648\n",
            "Epoch 111: 100% 901/901 [01:44<00:00,  8.61it/s]\n",
            "Epoch 111 completed. Average training loss: 2.1648\n",
            "Validation loss after epoch 111: 2.3569\n",
            "Checkpoint saved -> checkpoints/model_epoch_111.pt\n",
            "Epoch 112:   0% 0/901 [00:00<?, ?it/s]Step 49950: loss = 2.5797\n",
            "Epoch 112:  11% 98/901 [00:11<01:19, 10.11it/s]Step 50000: loss = 2.1791\n",
            "Checkpoint saved -> checkpoints/model_step_50000.pt\n",
            "Epoch 112:  11% 100/901 [00:11<02:24,  5.54it/s]Step 50000: loss = 2.1776\n",
            "Checkpoint saved -> checkpoints/model_step_50000.pt\n",
            "Epoch 112:  22% 199/901 [00:24<01:33,  7.50it/s]Step 50050: loss = 2.1674\n",
            "Epoch 112:  22% 200/901 [00:24<01:33,  7.48it/s]Step 50050: loss = 2.1653\n",
            "Epoch 112:  33% 299/901 [00:35<01:05,  9.20it/s]Step 50100: loss = 2.1667\n",
            "Epoch 112:  33% 300/901 [00:35<01:07,  8.95it/s]Step 50100: loss = 2.1653\n",
            "Epoch 112:  44% 398/901 [00:47<00:58,  8.67it/s]Step 50150: loss = 2.1716\n",
            "Epoch 112:  44% 400/901 [00:47<00:51,  9.76it/s]Step 50150: loss = 2.1709\n",
            "Epoch 112:  55% 498/901 [00:58<00:40, 10.00it/s]Step 50200: loss = 2.1766\n",
            "Epoch 112:  55% 500/901 [00:58<00:38, 10.36it/s]Step 50200: loss = 2.1756\n",
            "Epoch 112:  66% 598/901 [01:09<00:32,  9.41it/s]Step 50250: loss = 2.1748\n",
            "Epoch 112:  67% 600/901 [01:09<00:31,  9.53it/s]Step 50250: loss = 2.1750\n",
            "Epoch 112:  77% 698/901 [01:21<00:20,  9.82it/s]Step 50300: loss = 2.1742\n",
            "Epoch 112:  78% 700/901 [01:21<00:20,  9.86it/s]Step 50300: loss = 2.1733\n",
            "Epoch 112:  89% 798/901 [01:33<00:13,  7.61it/s]Step 50350: loss = 2.1636\n",
            "Epoch 112:  89% 800/901 [01:33<00:14,  7.13it/s]Step 50350: loss = 2.1632\n",
            "Epoch 112: 100% 898/901 [01:45<00:00,  8.89it/s]Step 50400: loss = 2.1573\n",
            "Epoch 112: 100% 900/901 [01:45<00:00,  9.53it/s]Step 50400: loss = 2.1574\n",
            "Epoch 112: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 112 completed. Average training loss: 2.1574\n",
            "Validation loss after epoch 112: 2.3559\n",
            "Checkpoint saved -> checkpoints/model_epoch_112.pt\n",
            "Epoch 113:   0% 0/901 [00:00<?, ?it/s]Step 50400: loss = 1.6514\n",
            "Epoch 113:  11% 98/901 [00:11<01:27,  9.15it/s]Step 50450: loss = 2.1953\n",
            "Epoch 113:  11% 100/901 [00:11<01:23,  9.60it/s]Step 50450: loss = 2.1939\n",
            "Epoch 113:  22% 198/901 [00:23<01:21,  8.60it/s]Step 50500: loss = 2.1429\n",
            "Checkpoint saved -> checkpoints/model_step_50500.pt\n",
            "Epoch 113:  22% 200/901 [00:24<02:16,  5.12it/s]Step 50500: loss = 2.1421\n",
            "Checkpoint saved -> checkpoints/model_step_50500.pt\n",
            "Epoch 113:  33% 298/901 [00:36<01:12,  8.28it/s]Step 50550: loss = 2.1458\n",
            "Epoch 113:  33% 300/901 [00:36<01:08,  8.79it/s]Step 50550: loss = 2.1451\n",
            "Epoch 113:  44% 398/901 [00:47<00:55,  9.02it/s]Step 50600: loss = 2.1494\n",
            "Epoch 113:  44% 400/901 [00:47<01:02,  8.02it/s]Step 50600: loss = 2.1498\n",
            "Epoch 113:  55% 498/901 [00:59<00:41,  9.69it/s]Step 50650: loss = 2.1441\n",
            "Epoch 113:  55% 500/901 [00:59<00:41,  9.55it/s]Step 50650: loss = 2.1443\n",
            "Epoch 113:  66% 598/901 [01:10<00:35,  8.59it/s]Step 50700: loss = 2.1556\n",
            "Epoch 113:  67% 600/901 [01:10<00:35,  8.39it/s]Step 50700: loss = 2.1555\n",
            "Epoch 113:  77% 698/901 [01:21<00:23,  8.47it/s]Step 50750: loss = 2.1645\n",
            "Epoch 113:  78% 700/901 [01:21<00:22,  9.06it/s]Step 50750: loss = 2.1647\n",
            "Epoch 113:  89% 799/901 [01:33<00:11,  8.55it/s]Step 50800: loss = 2.1618\n",
            "Epoch 113:  89% 800/901 [01:33<00:12,  7.87it/s]Step 50800: loss = 2.1618\n",
            "Epoch 113: 100% 898/901 [01:45<00:00,  9.01it/s]Step 50850: loss = 2.1611\n",
            "Epoch 113: 100% 900/901 [01:45<00:00,  8.96it/s]Step 50850: loss = 2.1609\n",
            "Epoch 113: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 113 completed. Average training loss: 2.1609\n",
            "Validation loss after epoch 113: 2.3548\n",
            "Checkpoint saved -> checkpoints/model_epoch_113.pt\n",
            "Epoch 114:   0% 0/901 [00:00<?, ?it/s]Step 50850: loss = 2.4952\n",
            "Epoch 114:  11% 99/901 [00:11<01:51,  7.20it/s]Step 50900: loss = 2.1321\n",
            "Step 50900: loss = 2.1314\n",
            "Epoch 114:  22% 199/901 [00:23<01:20,  8.68it/s]Step 50950: loss = 2.1421\n",
            "Epoch 114:  22% 200/901 [00:23<01:26,  8.08it/s]Step 50950: loss = 2.1424\n",
            "Epoch 114:  33% 298/901 [00:35<01:12,  8.35it/s]Step 51000: loss = 2.1306\n",
            "Checkpoint saved -> checkpoints/model_step_51000.pt\n",
            "Epoch 114:  33% 300/901 [00:35<02:03,  4.85it/s]Step 51000: loss = 2.1297\n",
            "Checkpoint saved -> checkpoints/model_step_51000.pt\n",
            "Epoch 114:  44% 399/901 [00:47<00:53,  9.35it/s]Step 51050: loss = 2.1541\n",
            "Epoch 114:  44% 400/901 [00:47<00:55,  9.03it/s]Step 51050: loss = 2.1536\n",
            "Epoch 114:  55% 499/901 [00:59<00:43,  9.27it/s]Step 51100: loss = 2.1480\n",
            "Epoch 114:  55% 500/901 [00:59<00:44,  8.95it/s]Step 51100: loss = 2.1474\n",
            "Epoch 114:  66% 598/901 [01:10<00:35,  8.64it/s]Step 51150: loss = 2.1513\n",
            "Epoch 114:  67% 600/901 [01:10<00:34,  8.85it/s]Step 51150: loss = 2.1514\n",
            "Epoch 114:  77% 698/901 [01:21<00:24,  8.30it/s]Step 51200: loss = 2.1640\n",
            "Epoch 114:  78% 700/901 [01:21<00:21,  9.20it/s]Step 51200: loss = 2.1634\n",
            "Epoch 114:  89% 798/901 [01:33<00:11,  9.13it/s]Step 51250: loss = 2.1604\n",
            "Epoch 114:  89% 800/901 [01:34<00:10,  9.37it/s]Step 51250: loss = 2.1597\n",
            "Epoch 114: 100% 899/901 [01:45<00:00,  9.26it/s]Step 51300: loss = 2.1656\n",
            "Step 51300: loss = 2.1655\n",
            "Epoch 114: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 114 completed. Average training loss: 2.1655\n",
            "Validation loss after epoch 114: 2.3538\n",
            "Checkpoint saved -> checkpoints/model_epoch_114.pt\n",
            "Epoch 115:   0% 0/901 [00:00<?, ?it/s]Step 51300: loss = 1.6986\n",
            "Epoch 115:  11% 99/901 [00:11<01:23,  9.57it/s]Step 51350: loss = 2.1517\n",
            "Epoch 115:  11% 100/901 [00:11<01:31,  8.78it/s]Step 51350: loss = 2.1459\n",
            "Epoch 115:  22% 199/901 [00:23<01:20,  8.68it/s]Step 51400: loss = 2.1343\n",
            "Epoch 115:  22% 200/901 [00:23<01:24,  8.26it/s]Step 51400: loss = 2.1326\n",
            "Epoch 115:  33% 299/901 [00:35<01:26,  6.95it/s]Step 51450: loss = 2.1236\n",
            "Epoch 115:  33% 300/901 [00:35<01:25,  7.04it/s]Step 51450: loss = 2.1238\n",
            "Epoch 115:  44% 398/901 [00:47<01:01,  8.23it/s]Step 51500: loss = 2.1498\n",
            "Checkpoint saved -> checkpoints/model_step_51500.pt\n",
            "Epoch 115:  44% 400/901 [00:47<01:45,  4.74it/s]Step 51500: loss = 2.1507\n",
            "Checkpoint saved -> checkpoints/model_step_51500.pt\n",
            "Epoch 115:  55% 498/901 [00:58<00:45,  8.86it/s]Step 51550: loss = 2.1701\n",
            "Epoch 115:  55% 500/901 [00:59<00:43,  9.12it/s]Step 51550: loss = 2.1701\n",
            "Epoch 115:  66% 598/901 [01:10<00:40,  7.51it/s]Step 51600: loss = 2.1605\n",
            "Epoch 115:  67% 600/901 [01:11<00:37,  8.11it/s]Step 51600: loss = 2.1610\n",
            "Epoch 115:  77% 698/901 [01:22<00:21,  9.47it/s]Step 51650: loss = 2.1621\n",
            "Epoch 115:  78% 700/901 [01:22<00:24,  8.26it/s]Step 51650: loss = 2.1618\n",
            "Epoch 115:  89% 798/901 [01:33<00:11,  9.02it/s]Step 51700: loss = 2.1651\n",
            "Epoch 115:  89% 800/901 [01:33<00:10,  9.34it/s]Step 51700: loss = 2.1653\n",
            "Epoch 115: 100% 899/901 [01:44<00:00,  9.60it/s]Step 51750: loss = 2.1697\n",
            "Epoch 115: 100% 900/901 [01:44<00:00,  9.64it/s]Step 51750: loss = 2.1707\n",
            "Epoch 115: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 115 completed. Average training loss: 2.1707\n",
            "Validation loss after epoch 115: 2.3528\n",
            "Checkpoint saved -> checkpoints/model_epoch_115.pt\n",
            "Epoch 116:   0% 0/901 [00:00<?, ?it/s]Step 51750: loss = 2.5073\n",
            "Epoch 116:  11% 99/901 [00:11<01:39,  8.03it/s]Step 51800: loss = 2.1901\n",
            "Epoch 116:  11% 100/901 [00:11<01:43,  7.74it/s]Step 51800: loss = 2.1881\n",
            "Epoch 116:  22% 198/901 [00:22<01:20,  8.72it/s]Step 51850: loss = 2.1562\n",
            "Epoch 116:  22% 200/901 [00:23<01:18,  8.96it/s]Step 51850: loss = 2.1547\n",
            "Epoch 116:  33% 299/901 [00:34<01:11,  8.45it/s]Step 51900: loss = 2.1544\n",
            "Epoch 116:  33% 300/901 [00:35<01:12,  8.32it/s]Step 51900: loss = 2.1525\n",
            "Epoch 116:  44% 398/901 [00:46<01:04,  7.82it/s]Step 51950: loss = 2.1577\n",
            "Epoch 116:  44% 400/901 [00:46<00:58,  8.53it/s]Step 51950: loss = 2.1605\n",
            "Epoch 116:  55% 498/901 [00:57<00:41,  9.71it/s]Step 52000: loss = 2.1638\n",
            "Checkpoint saved -> checkpoints/model_step_52000.pt\n",
            "Epoch 116:  55% 500/901 [00:58<01:12,  5.53it/s]Step 52000: loss = 2.1643\n",
            "Checkpoint saved -> checkpoints/model_step_52000.pt\n",
            "Epoch 116:  66% 599/901 [01:10<00:37,  8.07it/s]Step 52050: loss = 2.1605\n",
            "Step 52050: loss = 2.1607\n",
            "Epoch 116:  77% 698/901 [01:22<00:24,  8.32it/s]Step 52100: loss = 2.1523\n",
            "Epoch 116:  78% 700/901 [01:22<00:22,  8.77it/s]Step 52100: loss = 2.1527\n",
            "Epoch 116:  89% 798/901 [01:33<00:11,  8.83it/s]Step 52150: loss = 2.1585\n",
            "Epoch 116:  89% 800/901 [01:33<00:11,  9.12it/s]Step 52150: loss = 2.1597\n",
            "Epoch 116: 100% 899/901 [01:44<00:00,  9.06it/s]Step 52200: loss = 2.1621\n",
            "Epoch 116: 100% 900/901 [01:45<00:00,  8.47it/s]Step 52200: loss = 2.1628\n",
            "Epoch 116: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 116 completed. Average training loss: 2.1628\n",
            "Validation loss after epoch 116: 2.3518\n",
            "Checkpoint saved -> checkpoints/model_epoch_116.pt\n",
            "Epoch 117:   0% 0/901 [00:00<?, ?it/s]Step 52200: loss = 1.9864\n",
            "Epoch 117:  11% 98/901 [00:11<01:48,  7.43it/s]Step 52250: loss = 2.1311\n",
            "Epoch 117:  11% 100/901 [00:11<01:41,  7.86it/s]Step 52250: loss = 2.1365\n",
            "Epoch 117:  22% 199/901 [00:23<01:24,  8.31it/s]Step 52300: loss = 2.1449\n",
            "Epoch 117:  22% 200/901 [00:23<01:25,  8.20it/s]Step 52300: loss = 2.1442\n",
            "Epoch 117:  33% 299/901 [00:34<01:04,  9.29it/s]Step 52350: loss = 2.1370\n",
            "Epoch 117:  33% 300/901 [00:34<01:06,  9.08it/s]Step 52350: loss = 2.1377\n",
            "Epoch 117:  44% 399/901 [00:46<01:02,  8.08it/s]Step 52400: loss = 2.1510\n",
            "Epoch 117:  44% 400/901 [00:46<00:59,  8.35it/s]Step 52400: loss = 2.1499\n",
            "Epoch 117:  55% 499/901 [00:57<00:51,  7.75it/s]Step 52450: loss = 2.1490\n",
            "Epoch 117:  55% 500/901 [00:57<00:49,  8.08it/s]Step 52450: loss = 2.1501\n",
            "Epoch 117:  66% 599/901 [01:09<00:36,  8.28it/s]Step 52500: loss = 2.1497\n",
            "Checkpoint saved -> checkpoints/model_step_52500.pt\n",
            "Epoch 117:  67% 600/901 [01:09<01:13,  4.12it/s]Step 52500: loss = 2.1498\n",
            "Checkpoint saved -> checkpoints/model_step_52500.pt\n",
            "Epoch 117:  77% 698/901 [01:21<00:20, 10.05it/s]Step 52550: loss = 2.1498\n",
            "Epoch 117:  78% 700/901 [01:22<00:21,  9.43it/s]Step 52550: loss = 2.1505\n",
            "Epoch 117:  89% 799/901 [01:33<00:11,  9.02it/s]Step 52600: loss = 2.1521\n",
            "Epoch 117:  89% 800/901 [01:33<00:11,  8.79it/s]Step 52600: loss = 2.1526\n",
            "Epoch 117: 100% 898/901 [01:45<00:00,  8.82it/s]Step 52650: loss = 2.1533\n",
            "Epoch 117: 100% 900/901 [01:45<00:00,  9.66it/s]Step 52650: loss = 2.1530\n",
            "Epoch 117: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 117 completed. Average training loss: 2.1530\n",
            "Validation loss after epoch 117: 2.3508\n",
            "Checkpoint saved -> checkpoints/model_epoch_117.pt\n",
            "Epoch 118:   0% 0/901 [00:00<?, ?it/s]Step 52650: loss = 2.1214\n",
            "Epoch 118:  11% 99/901 [00:11<01:34,  8.52it/s]Step 52700: loss = 2.1425\n",
            "Epoch 118:  11% 100/901 [00:12<01:34,  8.48it/s]Step 52700: loss = 2.1370\n",
            "Epoch 118:  22% 199/901 [00:23<01:21,  8.62it/s]Step 52750: loss = 2.1735\n",
            "Epoch 118:  22% 200/901 [00:23<01:19,  8.85it/s]Step 52750: loss = 2.1711\n",
            "Epoch 118:  33% 298/901 [00:34<01:14,  8.09it/s]Step 52800: loss = 2.1726\n",
            "Epoch 118:  33% 300/901 [00:34<01:08,  8.77it/s]Step 52800: loss = 2.1720\n",
            "Epoch 118:  44% 399/901 [00:46<01:03,  7.91it/s]Step 52850: loss = 2.1697\n",
            "Epoch 118:  44% 400/901 [00:46<01:00,  8.22it/s]Step 52850: loss = 2.1705\n",
            "Epoch 118:  55% 498/901 [00:57<00:43,  9.36it/s]Step 52900: loss = 2.1749\n",
            "Epoch 118:  55% 500/901 [00:57<00:41,  9.72it/s]Step 52900: loss = 2.1750\n",
            "Epoch 118:  66% 599/901 [01:09<00:36,  8.37it/s]Step 52950: loss = 2.1624\n",
            "Epoch 118:  67% 600/901 [01:09<00:35,  8.52it/s]Step 52950: loss = 2.1633\n",
            "Epoch 118:  78% 699/901 [01:21<00:22,  8.91it/s]Step 53000: loss = 2.1702\n",
            "Checkpoint saved -> checkpoints/model_step_53000.pt\n",
            "Epoch 118:  78% 700/901 [01:21<00:46,  4.29it/s]Step 53000: loss = 2.1699\n",
            "Checkpoint saved -> checkpoints/model_step_53000.pt\n",
            "Epoch 118:  89% 799/901 [01:33<00:13,  7.50it/s]Step 53050: loss = 2.1703\n",
            "Epoch 118:  89% 800/901 [01:33<00:13,  7.62it/s]Step 53050: loss = 2.1705\n",
            "Epoch 118: 100% 899/901 [01:44<00:00,  9.17it/s]Step 53100: loss = 2.1738\n",
            "Step 53100: loss = 2.1731\n",
            "Epoch 118: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 118 completed. Average training loss: 2.1731\n",
            "Validation loss after epoch 118: 2.3498\n",
            "Checkpoint saved -> checkpoints/model_epoch_118.pt\n",
            "Epoch 119:   0% 0/901 [00:00<?, ?it/s]Step 53100: loss = 1.8188\n",
            "Epoch 119:  11% 99/901 [00:11<01:34,  8.48it/s]Step 53150: loss = 2.1453\n",
            "Epoch 119:  11% 100/901 [00:11<01:31,  8.74it/s]Step 53150: loss = 2.1453\n",
            "Epoch 119:  22% 199/901 [00:23<01:18,  8.99it/s]Step 53200: loss = 2.1377\n",
            "Epoch 119:  22% 200/901 [00:23<01:18,  8.89it/s]Step 53200: loss = 2.1390\n",
            "Epoch 119:  33% 299/901 [00:35<01:11,  8.41it/s]Step 53250: loss = 2.1256\n",
            "Epoch 119:  33% 300/901 [00:35<01:11,  8.35it/s]Step 53250: loss = 2.1246\n",
            "Epoch 119:  44% 398/901 [00:45<00:50, 10.04it/s]Step 53300: loss = 2.1450\n",
            "Epoch 119:  44% 400/901 [00:46<00:57,  8.74it/s]Step 53300: loss = 2.1441\n",
            "Epoch 119:  55% 498/901 [00:57<00:41,  9.60it/s]Step 53350: loss = 2.1486\n",
            "Epoch 119:  55% 500/901 [00:57<00:42,  9.42it/s]Step 53350: loss = 2.1498\n",
            "Epoch 119:  66% 599/901 [01:08<00:34,  8.68it/s]Step 53400: loss = 2.1574\n",
            "Epoch 119:  67% 600/901 [01:08<00:34,  8.67it/s]Step 53400: loss = 2.1575\n",
            "Epoch 119:  78% 699/901 [01:20<00:22,  9.08it/s]Step 53450: loss = 2.1484\n",
            "Epoch 119:  78% 700/901 [01:20<00:23,  8.68it/s]Step 53450: loss = 2.1477\n",
            "Epoch 119:  89% 799/901 [01:32<00:10,  9.75it/s]Step 53500: loss = 2.1470\n",
            "Checkpoint saved -> checkpoints/model_step_53500.pt\n",
            "Epoch 119:  89% 800/901 [01:33<00:22,  4.42it/s]Step 53500: loss = 2.1477\n",
            "Checkpoint saved -> checkpoints/model_step_53500.pt\n",
            "Epoch 119: 100% 898/901 [01:44<00:00,  8.54it/s]Step 53550: loss = 2.1512\n",
            "Epoch 119: 100% 900/901 [01:44<00:00,  8.91it/s]Step 53550: loss = 2.1512\n",
            "Epoch 119: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 119 completed. Average training loss: 2.1512\n",
            "Validation loss after epoch 119: 2.3488\n",
            "Checkpoint saved -> checkpoints/model_epoch_119.pt\n",
            "Epoch 120:   0% 0/901 [00:00<?, ?it/s]Step 53550: loss = 2.1214\n",
            "Epoch 120:  11% 98/901 [00:11<01:26,  9.26it/s]Step 53600: loss = 2.1422\n",
            "Epoch 120:  11% 100/901 [00:11<01:26,  9.30it/s]Step 53600: loss = 2.1401\n",
            "Epoch 120:  22% 199/901 [00:23<01:13,  9.57it/s]Step 53650: loss = 2.1606\n",
            "Step 53650: loss = 2.1584\n",
            "Epoch 120:  33% 299/901 [00:34<01:22,  7.33it/s]Step 53700: loss = 2.1526\n",
            "Epoch 120:  33% 300/901 [00:35<01:21,  7.40it/s]Step 53700: loss = 2.1523\n",
            "Epoch 120:  44% 399/901 [00:46<00:50,  9.87it/s]Step 53750: loss = 2.1519\n",
            "Epoch 120:  44% 400/901 [00:46<00:50,  9.84it/s]Step 53750: loss = 2.1503\n",
            "Epoch 120:  55% 498/901 [00:57<00:47,  8.45it/s]Step 53800: loss = 2.1601\n",
            "Epoch 120:  55% 500/901 [00:57<00:46,  8.66it/s]Step 53800: loss = 2.1601\n",
            "Epoch 120:  66% 599/901 [01:09<00:35,  8.51it/s]Step 53850: loss = 2.1532\n",
            "Epoch 120:  67% 600/901 [01:09<00:43,  6.85it/s]Step 53850: loss = 2.1535\n",
            "Epoch 120:  77% 698/901 [01:20<00:22,  8.87it/s]Step 53900: loss = 2.1600\n",
            "Epoch 120:  78% 700/901 [01:20<00:22,  8.88it/s]Step 53900: loss = 2.1596\n",
            "Epoch 120:  89% 798/901 [01:31<00:11,  8.85it/s]Step 53950: loss = 2.1662\n",
            "Epoch 120:  89% 800/901 [01:31<00:10,  9.19it/s]Step 53950: loss = 2.1652\n",
            "Epoch 120: 100% 899/901 [01:44<00:00,  8.17it/s]Step 54000: loss = 2.1532\n",
            "Checkpoint saved -> checkpoints/model_step_54000.pt\n",
            "Epoch 120: 100% 900/901 [01:45<00:00,  3.76it/s]Step 54000: loss = 2.1539\n",
            "Checkpoint saved -> checkpoints/model_step_54000.pt\n",
            "Epoch 120: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 120 completed. Average training loss: 2.1539\n",
            "Validation loss after epoch 120: 2.3478\n",
            "Checkpoint saved -> checkpoints/model_epoch_120.pt\n",
            "Epoch 121:   0% 0/901 [00:00<?, ?it/s]Step 54000: loss = 2.2684\n",
            "Checkpoint saved -> checkpoints/model_step_54000.pt\n",
            "Epoch 121:  11% 99/901 [00:11<01:42,  7.81it/s]Step 54050: loss = 2.1640\n",
            "Epoch 121:  11% 100/901 [00:11<01:40,  7.96it/s]Step 54050: loss = 2.1607\n",
            "Epoch 121:  22% 198/901 [00:23<01:40,  7.02it/s]Step 54100: loss = 2.1681\n",
            "Epoch 121:  22% 200/901 [00:23<01:25,  8.15it/s]Step 54100: loss = 2.1670\n",
            "Epoch 121:  33% 298/901 [00:35<01:33,  6.48it/s]Step 54150: loss = 2.1458\n",
            "Epoch 121:  33% 300/901 [00:35<01:17,  7.72it/s]Step 54150: loss = 2.1451\n",
            "Epoch 121:  44% 398/901 [00:47<01:09,  7.28it/s]Step 54200: loss = 2.1369\n",
            "Epoch 121:  44% 400/901 [00:47<01:01,  8.18it/s]Step 54200: loss = 2.1363\n",
            "Epoch 121:  55% 499/901 [00:59<00:42,  9.55it/s]Step 54250: loss = 2.1285\n",
            "Epoch 121:  55% 500/901 [00:59<00:49,  8.15it/s]Step 54250: loss = 2.1289\n",
            "Epoch 121:  66% 599/901 [01:10<00:31,  9.50it/s]Step 54300: loss = 2.1314\n",
            "Epoch 121:  67% 600/901 [01:10<00:34,  8.75it/s]Step 54300: loss = 2.1303\n",
            "Epoch 121:  77% 698/901 [01:21<00:20,  9.86it/s]Step 54350: loss = 2.1386\n",
            "Epoch 121:  78% 700/901 [01:22<00:22,  8.84it/s]Step 54350: loss = 2.1386\n",
            "Epoch 121:  89% 799/901 [01:33<00:11,  8.57it/s]Step 54400: loss = 2.1436\n",
            "Epoch 121:  89% 800/901 [01:33<00:11,  8.44it/s]Step 54400: loss = 2.1445\n",
            "Epoch 121: 100% 898/901 [01:44<00:00,  8.16it/s]Step 54450: loss = 2.1409\n",
            "Epoch 121: 100% 900/901 [01:45<00:00,  8.03it/s]Step 54450: loss = 2.1410\n",
            "Epoch 121: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 121 completed. Average training loss: 2.1410\n",
            "Validation loss after epoch 121: 2.3468\n",
            "Checkpoint saved -> checkpoints/model_epoch_121.pt\n",
            "Epoch 122:   0% 0/901 [00:00<?, ?it/s]Step 54450: loss = 2.0302\n",
            "Epoch 122:  11% 99/901 [00:10<01:34,  8.47it/s]Step 54500: loss = 2.2118\n",
            "Checkpoint saved -> checkpoints/model_step_54500.pt\n",
            "Epoch 122:  11% 100/901 [00:11<03:00,  4.44it/s]Step 54500: loss = 2.2110\n",
            "Checkpoint saved -> checkpoints/model_step_54500.pt\n",
            "Epoch 122:  22% 199/901 [00:23<01:14,  9.44it/s]Step 54550: loss = 2.1967\n",
            "Epoch 122:  22% 200/901 [00:23<01:14,  9.43it/s]Step 54550: loss = 2.1969\n",
            "Epoch 122:  33% 298/901 [00:35<01:13,  8.25it/s]Step 54600: loss = 2.1827\n",
            "Epoch 122:  33% 300/901 [00:35<01:10,  8.58it/s]Step 54600: loss = 2.1845\n",
            "Epoch 122:  44% 398/901 [00:46<01:03,  7.92it/s]Step 54650: loss = 2.1803\n",
            "Epoch 122:  44% 400/901 [00:46<00:56,  8.91it/s]Step 54650: loss = 2.1795\n",
            "Epoch 122:  55% 498/901 [00:58<00:51,  7.76it/s]Step 54700: loss = 2.1707\n",
            "Epoch 122:  55% 500/901 [00:58<00:48,  8.19it/s]Step 54700: loss = 2.1697\n",
            "Epoch 122:  66% 598/901 [01:10<00:30, 10.09it/s]Step 54750: loss = 2.1700\n",
            "Epoch 122:  67% 600/901 [01:10<00:31,  9.53it/s]Step 54750: loss = 2.1715\n",
            "Epoch 122:  78% 699/901 [01:21<00:21,  9.28it/s]Step 54800: loss = 2.1726\n",
            "Epoch 122:  78% 700/901 [01:21<00:26,  7.65it/s]Step 54800: loss = 2.1730\n",
            "Epoch 122:  89% 799/901 [01:32<00:10,  9.31it/s]Step 54850: loss = 2.1729\n",
            "Epoch 122:  89% 800/901 [01:33<00:10,  9.27it/s]Step 54850: loss = 2.1724\n",
            "Epoch 122: 100% 899/901 [01:44<00:00,  8.14it/s]Step 54900: loss = 2.1631\n",
            "Epoch 122: 100% 900/901 [01:44<00:00,  8.03it/s]Step 54900: loss = 2.1634\n",
            "Epoch 122: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 122 completed. Average training loss: 2.1634\n",
            "Validation loss after epoch 122: 2.3458\n",
            "Checkpoint saved -> checkpoints/model_epoch_122.pt\n",
            "Epoch 123:   0% 0/901 [00:00<?, ?it/s]Step 54900: loss = 1.6478\n",
            "Epoch 123:  11% 99/901 [00:11<01:26,  9.27it/s]Step 54950: loss = 2.1348\n",
            "Epoch 123:  11% 100/901 [00:11<01:43,  7.77it/s]Step 54950: loss = 2.1338\n",
            "Epoch 123:  22% 199/901 [00:22<01:18,  8.93it/s]Step 55000: loss = 2.1415\n",
            "Checkpoint saved -> checkpoints/model_step_55000.pt\n",
            "Epoch 123:  22% 200/901 [00:23<02:51,  4.10it/s]Step 55000: loss = 2.1417\n",
            "Checkpoint saved -> checkpoints/model_step_55000.pt\n",
            "Epoch 123:  33% 298/901 [00:35<01:14,  8.10it/s]Step 55050: loss = 2.1562\n",
            "Epoch 123:  33% 300/901 [00:35<01:17,  7.79it/s]Step 55050: loss = 2.1547\n",
            "Epoch 123:  44% 398/901 [00:46<00:51,  9.81it/s]Step 55100: loss = 2.1617\n",
            "Epoch 123:  44% 400/901 [00:46<00:49, 10.13it/s]Step 55100: loss = 2.1611\n",
            "Epoch 123:  55% 498/901 [00:58<00:51,  7.85it/s]Step 55150: loss = 2.1591\n",
            "Epoch 123:  55% 500/901 [00:58<00:49,  8.12it/s]Step 55150: loss = 2.1592\n",
            "Epoch 123:  66% 598/901 [01:10<00:33,  9.17it/s]Step 55200: loss = 2.1594\n",
            "Epoch 123:  67% 600/901 [01:10<00:31,  9.70it/s]Step 55200: loss = 2.1606\n",
            "Epoch 123:  77% 698/901 [01:21<00:23,  8.63it/s]Step 55250: loss = 2.1654\n",
            "Epoch 123:  78% 700/901 [01:21<00:23,  8.47it/s]Step 55250: loss = 2.1649\n",
            "Epoch 123:  89% 799/901 [01:33<00:11,  8.58it/s]Step 55300: loss = 2.1635\n",
            "Epoch 123:  89% 800/901 [01:33<00:12,  8.06it/s]Step 55300: loss = 2.1627\n",
            "Epoch 123: 100% 899/901 [01:44<00:00,  9.10it/s]Step 55350: loss = 2.1690\n",
            "Epoch 123: 100% 900/901 [01:44<00:00,  9.11it/s]Step 55350: loss = 2.1696\n",
            "Epoch 123: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 123 completed. Average training loss: 2.1696\n",
            "Validation loss after epoch 123: 2.3448\n",
            "Checkpoint saved -> checkpoints/model_epoch_123.pt\n",
            "Epoch 124:   0% 0/901 [00:00<?, ?it/s]Step 55350: loss = 2.6057\n",
            "Epoch 124:  11% 99/901 [00:11<01:23,  9.56it/s]Step 55400: loss = 2.1105\n",
            "Epoch 124:  11% 100/901 [00:12<01:25,  9.33it/s]Step 55400: loss = 2.1123\n",
            "Epoch 124:  22% 199/901 [00:23<01:14,  9.48it/s]Step 55450: loss = 2.1210\n",
            "Epoch 124:  22% 200/901 [00:23<01:14,  9.40it/s]Step 55450: loss = 2.1155\n",
            "Epoch 124:  33% 299/901 [00:34<01:10,  8.54it/s]Step 55500: loss = 2.1393\n",
            "Checkpoint saved -> checkpoints/model_step_55500.pt\n",
            "Epoch 124:  33% 300/901 [00:35<02:34,  3.90it/s]Step 55500: loss = 2.1403\n",
            "Checkpoint saved -> checkpoints/model_step_55500.pt\n",
            "Epoch 124:  44% 399/901 [00:47<01:04,  7.73it/s]Step 55550: loss = 2.1369\n",
            "Epoch 124:  44% 400/901 [00:47<01:05,  7.62it/s]Step 55550: loss = 2.1349\n",
            "Epoch 124:  55% 498/901 [00:59<00:52,  7.64it/s]Step 55600: loss = 2.1352\n",
            "Epoch 124:  55% 500/901 [00:59<00:49,  8.11it/s]Step 55600: loss = 2.1356\n",
            "Epoch 124:  66% 598/901 [01:10<00:32,  9.21it/s]Step 55650: loss = 2.1395\n",
            "Epoch 124:  67% 600/901 [01:10<00:31,  9.58it/s]Step 55650: loss = 2.1410\n",
            "Epoch 124:  78% 699/901 [01:23<00:24,  8.37it/s]Step 55700: loss = 2.1293\n",
            "Epoch 124:  78% 700/901 [01:23<00:23,  8.62it/s]Step 55700: loss = 2.1299\n",
            "Epoch 124:  89% 798/901 [01:34<00:11,  8.78it/s]Step 55750: loss = 2.1421\n",
            "Epoch 124:  89% 800/901 [01:34<00:11,  8.81it/s]Step 55750: loss = 2.1422\n",
            "Epoch 124: 100% 898/901 [01:45<00:00,  7.71it/s]Step 55800: loss = 2.1482\n",
            "Epoch 124: 100% 900/901 [01:45<00:00,  8.20it/s]Step 55800: loss = 2.1479\n",
            "Epoch 124: 100% 901/901 [01:46<00:00,  8.50it/s]\n",
            "Epoch 124 completed. Average training loss: 2.1479\n",
            "Validation loss after epoch 124: 2.3438\n",
            "Checkpoint saved -> checkpoints/model_epoch_124.pt\n",
            "Epoch 125:   0% 0/901 [00:00<?, ?it/s]Step 55800: loss = 1.9974\n",
            "Epoch 125:  11% 98/901 [00:11<01:26,  9.26it/s]Step 55850: loss = 2.1303\n",
            "Epoch 125:  11% 100/901 [00:11<01:26,  9.23it/s]Step 55850: loss = 2.1316\n",
            "Epoch 125:  22% 198/901 [00:23<01:34,  7.45it/s]Step 55900: loss = 2.1036\n",
            "Epoch 125:  22% 200/901 [00:23<01:25,  8.19it/s]Step 55900: loss = 2.1079\n",
            "Epoch 125:  33% 298/901 [00:34<01:15,  8.01it/s]Step 55950: loss = 2.1549\n",
            "Epoch 125:  33% 300/901 [00:34<01:05,  9.19it/s]Step 55950: loss = 2.1561\n",
            "Epoch 125:  44% 398/901 [00:45<01:03,  7.90it/s]Step 56000: loss = 2.1604\n",
            "Checkpoint saved -> checkpoints/model_step_56000.pt\n",
            "Epoch 125:  44% 400/901 [00:46<01:49,  4.59it/s]Step 56000: loss = 2.1608\n",
            "Checkpoint saved -> checkpoints/model_step_56000.pt\n",
            "Epoch 125:  55% 499/901 [00:58<00:42,  9.54it/s]Step 56050: loss = 2.1508\n",
            "Epoch 125:  55% 500/901 [00:58<00:43,  9.33it/s]Step 56050: loss = 2.1515\n",
            "Epoch 125:  66% 599/901 [01:10<00:45,  6.60it/s]Step 56100: loss = 2.1471\n",
            "Epoch 125:  67% 600/901 [01:10<00:43,  6.97it/s]Step 56100: loss = 2.1475\n",
            "Epoch 125:  78% 699/901 [01:22<00:25,  7.97it/s]Step 56150: loss = 2.1448\n",
            "Epoch 125:  78% 700/901 [01:22<00:25,  8.00it/s]Step 56150: loss = 2.1444\n",
            "Epoch 125:  89% 799/901 [01:33<00:11,  8.60it/s]Step 56200: loss = 2.1465\n",
            "Epoch 125:  89% 800/901 [01:33<00:12,  8.11it/s]Step 56200: loss = 2.1467\n",
            "Epoch 125: 100% 898/901 [01:44<00:00,  7.86it/s]Step 56250: loss = 2.1537\n",
            "Epoch 125: 100% 900/901 [01:45<00:00,  6.27it/s]Step 56250: loss = 2.1527\n",
            "Epoch 125: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 125 completed. Average training loss: 2.1527\n",
            "Validation loss after epoch 125: 2.3429\n",
            "Checkpoint saved -> checkpoints/model_epoch_125.pt\n",
            "Epoch 126:   0% 0/901 [00:00<?, ?it/s]Step 56250: loss = 2.9323\n",
            "Epoch 126:  11% 98/901 [00:10<01:35,  8.37it/s]Step 56300: loss = 2.2421\n",
            "Epoch 126:  11% 100/901 [00:11<01:33,  8.58it/s]Step 56300: loss = 2.2433\n",
            "Epoch 126:  22% 199/901 [00:22<01:19,  8.79it/s]Step 56350: loss = 2.1924\n",
            "Epoch 126:  22% 200/901 [00:22<01:25,  8.19it/s]Step 56350: loss = 2.1925\n",
            "Epoch 126:  33% 298/901 [00:34<00:59, 10.15it/s]Step 56400: loss = 2.1716\n",
            "Epoch 126:  33% 300/901 [00:34<01:01,  9.78it/s]Step 56400: loss = 2.1705\n",
            "Epoch 126:  44% 399/901 [00:46<00:54,  9.16it/s]Step 56450: loss = 2.1528\n",
            "Epoch 126:  44% 400/901 [00:46<00:57,  8.64it/s]Step 56450: loss = 2.1536\n",
            "Epoch 126:  55% 499/901 [00:57<00:38, 10.52it/s]Step 56500: loss = 2.1561\n",
            "Checkpoint saved -> checkpoints/model_step_56500.pt\n",
            "Step 56500: loss = 2.1561\n",
            "Checkpoint saved -> checkpoints/model_step_56500.pt\n",
            "Epoch 126:  66% 598/901 [01:10<00:39,  7.72it/s]Step 56550: loss = 2.1569\n",
            "Epoch 126:  67% 600/901 [01:10<00:40,  7.35it/s]Step 56550: loss = 2.1571\n",
            "Epoch 126:  77% 698/901 [01:21<00:24,  8.44it/s]Step 56600: loss = 2.1574\n",
            "Epoch 126:  78% 700/901 [01:21<00:24,  8.07it/s]Step 56600: loss = 2.1569\n",
            "Epoch 126:  89% 798/901 [01:33<00:16,  6.10it/s]Step 56650: loss = 2.1478\n",
            "Epoch 126:  89% 800/901 [01:33<00:13,  7.62it/s]Step 56650: loss = 2.1479\n",
            "Epoch 126: 100% 898/901 [01:45<00:00,  8.61it/s]Step 56700: loss = 2.1428\n",
            "Epoch 126: 100% 900/901 [01:45<00:00,  8.79it/s]Step 56700: loss = 2.1435\n",
            "Epoch 126: 100% 901/901 [01:46<00:00,  8.50it/s]\n",
            "Epoch 126 completed. Average training loss: 2.1435\n",
            "Validation loss after epoch 126: 2.3419\n",
            "Checkpoint saved -> checkpoints/model_epoch_126.pt\n",
            "Epoch 127:   0% 0/901 [00:00<?, ?it/s]Step 56700: loss = 2.4935\n",
            "Epoch 127:  11% 99/901 [00:11<01:28,  9.07it/s]Step 56750: loss = 2.2203\n",
            "Epoch 127:  11% 100/901 [00:11<01:27,  9.16it/s]Step 56750: loss = 2.2122\n",
            "Epoch 127:  22% 199/901 [00:22<01:20,  8.73it/s]Step 56800: loss = 2.1791\n",
            "Epoch 127:  22% 200/901 [00:22<01:29,  7.82it/s]Step 56800: loss = 2.1768\n",
            "Epoch 127:  33% 299/901 [00:34<01:17,  7.76it/s]Step 56850: loss = 2.1547\n",
            "Epoch 127:  33% 300/901 [00:34<01:15,  7.96it/s]Step 56850: loss = 2.1546\n",
            "Epoch 127:  44% 398/901 [00:45<00:57,  8.73it/s]Step 56900: loss = 2.1611\n",
            "Epoch 127:  44% 400/901 [00:45<01:02,  7.97it/s]Step 56900: loss = 2.1611\n",
            "Epoch 127:  55% 499/901 [00:57<00:46,  8.68it/s]Step 56950: loss = 2.1619\n",
            "Epoch 127:  55% 500/901 [00:57<00:45,  8.74it/s]Step 56950: loss = 2.1624\n",
            "Epoch 127:  66% 599/901 [01:09<00:37,  8.01it/s]Step 57000: loss = 2.1599\n",
            "Checkpoint saved -> checkpoints/model_step_57000.pt\n",
            "Epoch 127:  67% 600/901 [01:09<01:16,  3.95it/s]Step 57000: loss = 2.1597\n",
            "Checkpoint saved -> checkpoints/model_step_57000.pt\n",
            "Epoch 127:  78% 699/901 [01:21<00:28,  7.13it/s]Step 57050: loss = 2.1575\n",
            "Epoch 127:  78% 700/901 [01:22<00:28,  7.08it/s]Step 57050: loss = 2.1575\n",
            "Epoch 127:  89% 798/901 [01:33<00:11,  8.77it/s]Step 57100: loss = 2.1524\n",
            "Epoch 127:  89% 800/901 [01:33<00:11,  8.43it/s]Step 57100: loss = 2.1525\n",
            "Epoch 127: 100% 899/901 [01:45<00:00,  9.44it/s]Step 57150: loss = 2.1458\n",
            "Epoch 127: 100% 900/901 [01:45<00:00,  8.51it/s]Step 57150: loss = 2.1466\n",
            "Epoch 127: 100% 901/901 [01:46<00:00,  8.50it/s]\n",
            "Epoch 127 completed. Average training loss: 2.1466\n",
            "Validation loss after epoch 127: 2.3410\n",
            "Checkpoint saved -> checkpoints/model_epoch_127.pt\n",
            "Epoch 128:   0% 0/901 [00:00<?, ?it/s]Step 57150: loss = 2.0825\n",
            "Epoch 128:  11% 98/901 [00:11<01:41,  7.92it/s]Step 57200: loss = 2.1093\n",
            "Epoch 128:  11% 100/901 [00:11<01:32,  8.62it/s]Step 57200: loss = 2.1161\n",
            "Epoch 128:  22% 199/901 [00:22<01:17,  9.02it/s]Step 57250: loss = 2.1505\n",
            "Step 57250: loss = 2.1486\n",
            "Epoch 128:  33% 298/901 [00:34<01:05,  9.17it/s]Step 57300: loss = 2.1495\n",
            "Epoch 128:  33% 300/901 [00:34<01:08,  8.83it/s]Step 57300: loss = 2.1480\n",
            "Epoch 128:  44% 399/901 [00:46<01:14,  6.74it/s]Step 57350: loss = 2.1395\n",
            "Epoch 128:  44% 400/901 [00:46<01:09,  7.19it/s]Step 57350: loss = 2.1398\n",
            "Epoch 128:  55% 498/901 [00:57<00:46,  8.71it/s]Step 57400: loss = 2.1531\n",
            "Epoch 128:  55% 500/901 [00:58<00:44,  8.93it/s]Step 57400: loss = 2.1535\n",
            "Epoch 128:  66% 599/901 [01:09<00:32,  9.39it/s]Step 57450: loss = 2.1565\n",
            "Epoch 128:  67% 600/901 [01:09<00:34,  8.73it/s]Step 57450: loss = 2.1560\n",
            "Epoch 128:  78% 699/901 [01:21<00:20,  9.85it/s]Step 57500: loss = 2.1527\n",
            "Checkpoint saved -> checkpoints/model_step_57500.pt\n",
            "Epoch 128:  78% 700/901 [01:21<00:43,  4.58it/s]Step 57500: loss = 2.1522\n",
            "Checkpoint saved -> checkpoints/model_step_57500.pt\n",
            "Epoch 128:  89% 798/901 [01:33<00:12,  8.34it/s]Step 57550: loss = 2.1530\n",
            "Epoch 128:  89% 800/901 [01:33<00:11,  8.98it/s]Step 57550: loss = 2.1528\n",
            "Epoch 128: 100% 899/901 [01:45<00:00,  8.70it/s]Step 57600: loss = 2.1529\n",
            "Epoch 128: 100% 900/901 [01:45<00:00,  8.39it/s]Step 57600: loss = 2.1531\n",
            "Epoch 128: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 128 completed. Average training loss: 2.1531\n",
            "Validation loss after epoch 128: 2.3400\n",
            "Checkpoint saved -> checkpoints/model_epoch_128.pt\n",
            "Epoch 129:   0% 0/901 [00:00<?, ?it/s]Step 57600: loss = 1.5026\n",
            "Epoch 129:  11% 98/901 [00:11<01:30,  8.84it/s]Step 57650: loss = 2.1417\n",
            "Epoch 129:  11% 100/901 [00:11<01:26,  9.26it/s]Step 57650: loss = 2.1354\n",
            "Epoch 129:  22% 199/901 [00:22<01:24,  8.31it/s]Step 57700: loss = 2.1503\n",
            "Epoch 129:  22% 200/901 [00:22<01:26,  8.14it/s]Step 57700: loss = 2.1493\n",
            "Epoch 129:  33% 298/901 [00:34<01:15,  7.98it/s]Step 57750: loss = 2.1429\n",
            "Epoch 129:  33% 300/901 [00:34<01:13,  8.20it/s]Step 57750: loss = 2.1413\n",
            "Epoch 129:  44% 398/901 [00:46<00:56,  8.94it/s]Step 57800: loss = 2.1276\n",
            "Epoch 129:  44% 400/901 [00:46<00:52,  9.47it/s]Step 57800: loss = 2.1266\n",
            "Epoch 129:  55% 498/901 [00:58<00:49,  8.19it/s]Step 57850: loss = 2.1248\n",
            "Epoch 129:  55% 500/901 [00:58<00:46,  8.54it/s]Step 57850: loss = 2.1245\n",
            "Epoch 129:  66% 598/901 [01:10<00:32,  9.40it/s]Step 57900: loss = 2.1186\n",
            "Epoch 129:  67% 600/901 [01:10<00:32,  9.35it/s]Step 57900: loss = 2.1190\n",
            "Epoch 129:  77% 698/901 [01:21<00:21,  9.28it/s]Step 57950: loss = 2.1292\n",
            "Epoch 129:  78% 700/901 [01:21<00:20,  9.65it/s]Step 57950: loss = 2.1288\n",
            "Epoch 129:  89% 799/901 [01:32<00:10,  9.58it/s]Step 58000: loss = 2.1346\n",
            "Checkpoint saved -> checkpoints/model_step_58000.pt\n",
            "Epoch 129:  89% 800/901 [01:33<00:24,  4.20it/s]Step 58000: loss = 2.1342\n",
            "Checkpoint saved -> checkpoints/model_step_58000.pt\n",
            "Epoch 129: 100% 898/901 [01:45<00:00,  7.82it/s]Step 58050: loss = 2.1337\n",
            "Epoch 129: 100% 900/901 [01:45<00:00,  8.48it/s]Step 58050: loss = 2.1339\n",
            "Epoch 129: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 129 completed. Average training loss: 2.1339\n",
            "Validation loss after epoch 129: 2.3391\n",
            "Checkpoint saved -> checkpoints/model_epoch_129.pt\n",
            "Epoch 130:   0% 0/901 [00:00<?, ?it/s]Step 58050: loss = 2.0380\n",
            "Epoch 130:  11% 98/901 [00:11<01:39,  8.09it/s]Step 58100: loss = 2.1391\n",
            "Epoch 130:  11% 100/901 [00:11<01:28,  9.04it/s]Step 58100: loss = 2.1338\n",
            "Epoch 130:  22% 198/901 [00:22<01:13,  9.51it/s]Step 58150: loss = 2.1353\n",
            "Epoch 130:  22% 200/901 [00:22<01:08, 10.19it/s]Step 58150: loss = 2.1372\n",
            "Epoch 130:  33% 298/901 [00:33<01:06,  9.09it/s]Step 58200: loss = 2.1389\n",
            "Epoch 130:  33% 300/901 [00:34<01:04,  9.37it/s]Step 58200: loss = 2.1388\n",
            "Epoch 130:  44% 399/901 [00:45<00:58,  8.60it/s]Step 58250: loss = 2.1691\n",
            "Epoch 130:  44% 400/901 [00:45<00:56,  8.86it/s]Step 58250: loss = 2.1682\n",
            "Epoch 130:  55% 498/901 [00:56<01:02,  6.48it/s]Step 58300: loss = 2.1663\n",
            "Epoch 130:  55% 500/901 [00:57<00:53,  7.46it/s]Step 58300: loss = 2.1666\n",
            "Epoch 130:  66% 598/901 [01:08<00:36,  8.29it/s]Step 58350: loss = 2.1626\n",
            "Epoch 130:  67% 600/901 [01:08<00:37,  7.96it/s]Step 58350: loss = 2.1618\n",
            "Epoch 130:  78% 699/901 [01:20<00:23,  8.42it/s]Step 58400: loss = 2.1502\n",
            "Step 58400: loss = 2.1495\n",
            "Epoch 130:  89% 799/901 [01:32<00:11,  8.89it/s]Step 58450: loss = 2.1447\n",
            "Epoch 130:  89% 800/901 [01:32<00:13,  7.60it/s]Step 58450: loss = 2.1445\n",
            "Epoch 130: 100% 899/901 [01:43<00:00,  8.86it/s]Step 58500: loss = 2.1401\n",
            "Checkpoint saved -> checkpoints/model_step_58500.pt\n",
            "Epoch 130: 100% 900/901 [01:44<00:00,  2.93it/s]Step 58500: loss = 2.1403\n",
            "Checkpoint saved -> checkpoints/model_step_58500.pt\n",
            "Epoch 130: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 130 completed. Average training loss: 2.1403\n",
            "Validation loss after epoch 130: 2.3382\n",
            "Checkpoint saved -> checkpoints/model_epoch_130.pt\n",
            "Epoch 131:   0% 0/901 [00:00<?, ?it/s]Step 58500: loss = 1.4647\n",
            "Checkpoint saved -> checkpoints/model_step_58500.pt\n",
            "Epoch 131:  11% 99/901 [00:12<01:48,  7.40it/s]Step 58550: loss = 2.0808\n",
            "Epoch 131:  11% 100/901 [00:12<01:42,  7.82it/s]Step 58550: loss = 2.0889\n",
            "Epoch 131:  22% 198/901 [00:23<01:28,  7.92it/s]Step 58600: loss = 2.1091\n",
            "Epoch 131:  22% 200/901 [00:24<01:22,  8.47it/s]Step 58600: loss = 2.1116\n",
            "Epoch 131:  33% 298/901 [00:35<01:02,  9.58it/s]Step 58650: loss = 2.1071\n",
            "Epoch 131:  33% 300/901 [00:35<01:11,  8.35it/s]Step 58650: loss = 2.1046\n",
            "Epoch 131:  44% 398/901 [00:47<01:00,  8.28it/s]Step 58700: loss = 2.1214\n",
            "Epoch 131:  44% 400/901 [00:47<00:56,  8.89it/s]Step 58700: loss = 2.1218\n",
            "Epoch 131:  55% 498/901 [00:58<00:45,  8.92it/s]Step 58750: loss = 2.1377\n",
            "Epoch 131:  55% 500/901 [00:58<00:43,  9.13it/s]Step 58750: loss = 2.1382\n",
            "Epoch 131:  66% 598/901 [01:10<00:37,  8.14it/s]Step 58800: loss = 2.1350\n",
            "Epoch 131:  67% 600/901 [01:10<00:34,  8.72it/s]Step 58800: loss = 2.1350\n",
            "Epoch 131:  77% 698/901 [01:21<00:20,  9.76it/s]Step 58850: loss = 2.1371\n",
            "Epoch 131:  78% 700/901 [01:21<00:21,  9.20it/s]Step 58850: loss = 2.1366\n",
            "Epoch 131:  89% 799/901 [01:33<00:11,  9.22it/s]Step 58900: loss = 2.1321\n",
            "Epoch 131:  89% 800/901 [01:33<00:11,  9.07it/s]Step 58900: loss = 2.1329\n",
            "Epoch 131: 100% 899/901 [01:44<00:00,  9.45it/s]Step 58950: loss = 2.1365\n",
            "Epoch 131: 100% 900/901 [01:45<00:00,  9.15it/s]Step 58950: loss = 2.1361\n",
            "Epoch 131: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 131 completed. Average training loss: 2.1361\n",
            "Validation loss after epoch 131: 2.3372\n",
            "Checkpoint saved -> checkpoints/model_epoch_131.pt\n",
            "Epoch 132:   0% 0/901 [00:00<?, ?it/s]Step 58950: loss = 2.6270\n",
            "Epoch 132:  11% 98/901 [00:11<01:28,  9.09it/s]Step 59000: loss = 2.1442\n",
            "Checkpoint saved -> checkpoints/model_step_59000.pt\n",
            "Epoch 132:  11% 100/901 [00:12<02:30,  5.31it/s]Step 59000: loss = 2.1447\n",
            "Checkpoint saved -> checkpoints/model_step_59000.pt\n",
            "Epoch 132:  22% 199/901 [00:23<01:12,  9.66it/s]Step 59050: loss = 2.1832\n",
            "Epoch 132:  22% 200/901 [00:24<01:13,  9.56it/s]Step 59050: loss = 2.1849\n",
            "Epoch 132:  33% 299/901 [00:35<01:05,  9.22it/s]Step 59100: loss = 2.1666\n",
            "Epoch 132:  33% 300/901 [00:35<01:06,  9.06it/s]Step 59100: loss = 2.1674\n",
            "Epoch 132:  44% 399/901 [00:47<00:57,  8.73it/s]Step 59150: loss = 2.1668\n",
            "Epoch 132:  44% 400/901 [00:47<01:01,  8.14it/s]Step 59150: loss = 2.1671\n",
            "Epoch 132:  55% 499/901 [00:58<00:49,  8.11it/s]Step 59200: loss = 2.1624\n",
            "Step 59200: loss = 2.1625\n",
            "Epoch 132:  66% 599/901 [01:09<00:40,  7.39it/s]Step 59250: loss = 2.1586\n",
            "Epoch 132:  67% 600/901 [01:10<00:40,  7.52it/s]Step 59250: loss = 2.1584\n",
            "Epoch 132:  78% 699/901 [01:21<00:23,  8.61it/s]Step 59300: loss = 2.1551\n",
            "Epoch 132:  78% 700/901 [01:22<00:23,  8.56it/s]Step 59300: loss = 2.1547\n",
            "Epoch 132:  89% 799/901 [01:33<00:10,  9.83it/s]Step 59350: loss = 2.1580\n",
            "Epoch 132:  89% 800/901 [01:33<00:10,  9.50it/s]Step 59350: loss = 2.1580\n",
            "Epoch 132: 100% 898/901 [01:44<00:00,  9.07it/s]Step 59400: loss = 2.1512\n",
            "Epoch 132: 100% 900/901 [01:44<00:00,  9.51it/s]Step 59400: loss = 2.1513\n",
            "Epoch 132: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 132 completed. Average training loss: 2.1513\n",
            "Validation loss after epoch 132: 2.3363\n",
            "Checkpoint saved -> checkpoints/model_epoch_132.pt\n",
            "Epoch 133:   0% 0/901 [00:00<?, ?it/s]Step 59400: loss = 1.5971\n",
            "Epoch 133:  11% 99/901 [00:11<01:32,  8.67it/s]Step 59450: loss = 2.1276\n",
            "Epoch 133:  11% 100/901 [00:11<01:32,  8.62it/s]Step 59450: loss = 2.1201\n",
            "Epoch 133:  22% 199/901 [00:23<01:15,  9.32it/s]Step 59500: loss = 2.0918\n",
            "Checkpoint saved -> checkpoints/model_step_59500.pt\n",
            "Epoch 133:  22% 200/901 [00:24<02:50,  4.11it/s]Step 59500: loss = 2.0902\n",
            "Checkpoint saved -> checkpoints/model_step_59500.pt\n",
            "Epoch 133:  33% 299/901 [00:36<01:04,  9.38it/s]Step 59550: loss = 2.0958\n",
            "Epoch 133:  33% 300/901 [00:36<01:04,  9.35it/s]Step 59550: loss = 2.0950\n",
            "Epoch 133:  44% 398/901 [00:47<00:52,  9.51it/s]Step 59600: loss = 2.1057\n",
            "Epoch 133:  44% 400/901 [00:48<00:53,  9.42it/s]Step 59600: loss = 2.1047\n",
            "Epoch 133:  55% 498/901 [00:59<00:47,  8.56it/s]Step 59650: loss = 2.1099\n",
            "Epoch 133:  55% 500/901 [00:59<00:44,  9.04it/s]Step 59650: loss = 2.1107\n",
            "Epoch 133:  66% 598/901 [01:10<00:33,  8.97it/s]Step 59700: loss = 2.1338\n",
            "Epoch 133:  67% 600/901 [01:10<00:31,  9.43it/s]Step 59700: loss = 2.1345\n",
            "Epoch 133:  78% 699/901 [01:22<00:23,  8.52it/s]Step 59750: loss = 2.1416\n",
            "Epoch 133:  78% 700/901 [01:22<00:23,  8.59it/s]Step 59750: loss = 2.1413\n",
            "Epoch 133:  89% 798/901 [01:33<00:12,  8.48it/s]Step 59800: loss = 2.1407\n",
            "Epoch 133:  89% 800/901 [01:33<00:11,  9.02it/s]Step 59800: loss = 2.1414\n",
            "Epoch 133: 100% 898/901 [01:45<00:00,  8.44it/s]Step 59850: loss = 2.1401\n",
            "Epoch 133: 100% 900/901 [01:45<00:00,  8.82it/s]Step 59850: loss = 2.1405\n",
            "Epoch 133: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 133 completed. Average training loss: 2.1405\n",
            "Validation loss after epoch 133: 2.3353\n",
            "Checkpoint saved -> checkpoints/model_epoch_133.pt\n",
            "Epoch 134:   0% 0/901 [00:00<?, ?it/s]Step 59850: loss = 1.3913\n",
            "Epoch 134:  11% 99/901 [00:11<01:22,  9.69it/s]Step 59900: loss = 2.1356\n",
            "Step 59900: loss = 2.1475\n",
            "Epoch 134:  22% 199/901 [00:22<01:16,  9.21it/s]Step 59950: loss = 2.1494\n",
            "Epoch 134:  22% 200/901 [00:23<01:17,  8.99it/s]Step 59950: loss = 2.1508\n",
            "Epoch 134:  33% 299/901 [00:34<01:10,  8.48it/s]Step 60000: loss = 2.1500\n",
            "Checkpoint saved -> checkpoints/model_step_60000.pt\n",
            "Epoch 134:  33% 300/901 [00:35<02:21,  4.24it/s]Step 60000: loss = 2.1513\n",
            "Checkpoint saved -> checkpoints/model_step_60000.pt\n",
            "Epoch 134:  44% 399/901 [00:47<00:55,  9.04it/s]Step 60050: loss = 2.1249\n",
            "Epoch 134:  44% 400/901 [00:47<00:54,  9.22it/s]Step 60050: loss = 2.1250\n",
            "Epoch 134:  55% 499/901 [00:58<01:01,  6.57it/s]Step 60100: loss = 2.1179\n",
            "Epoch 134:  55% 500/901 [00:59<01:02,  6.40it/s]Step 60100: loss = 2.1184\n",
            "Epoch 134:  66% 599/901 [01:10<00:36,  8.29it/s]Step 60150: loss = 2.1211\n",
            "Epoch 134:  67% 600/901 [01:10<00:36,  8.33it/s]Step 60150: loss = 2.1220\n",
            "Epoch 134:  78% 699/901 [01:21<00:20,  9.65it/s]Step 60200: loss = 2.1301\n",
            "Epoch 134:  78% 700/901 [01:22<00:21,  9.15it/s]Step 60200: loss = 2.1301\n",
            "Epoch 134:  89% 798/901 [01:33<00:12,  8.53it/s]Step 60250: loss = 2.1347\n",
            "Epoch 134:  89% 800/901 [01:33<00:11,  8.81it/s]Step 60250: loss = 2.1344\n",
            "Epoch 134: 100% 899/901 [01:45<00:00,  9.48it/s]Step 60300: loss = 2.1299\n",
            "Epoch 134: 100% 900/901 [01:45<00:00,  8.86it/s]Step 60300: loss = 2.1294\n",
            "Epoch 134: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 134 completed. Average training loss: 2.1294\n",
            "Validation loss after epoch 134: 2.3344\n",
            "Checkpoint saved -> checkpoints/model_epoch_134.pt\n",
            "Epoch 135:   0% 0/901 [00:00<?, ?it/s]Step 60300: loss = 2.0525\n",
            "Epoch 135:  11% 99/901 [00:11<01:36,  8.34it/s]Step 60350: loss = 2.0864\n",
            "Epoch 135:  11% 100/901 [00:11<01:39,  8.03it/s]Step 60350: loss = 2.0826\n",
            "Epoch 135:  22% 199/901 [00:22<01:18,  8.93it/s]Step 60400: loss = 2.1189\n",
            "Epoch 135:  22% 200/901 [00:23<01:19,  8.87it/s]Step 60400: loss = 2.1155\n",
            "Epoch 135:  33% 299/901 [00:34<01:13,  8.14it/s]Step 60450: loss = 2.1334\n",
            "Epoch 135:  33% 300/901 [00:34<01:16,  7.83it/s]Step 60450: loss = 2.1331\n",
            "Epoch 135:  44% 399/901 [00:46<00:55,  9.07it/s]Step 60500: loss = 2.1216\n",
            "Checkpoint saved -> checkpoints/model_step_60500.pt\n",
            "Epoch 135:  44% 400/901 [00:47<01:54,  4.38it/s]Step 60500: loss = 2.1220\n",
            "Checkpoint saved -> checkpoints/model_step_60500.pt\n",
            "Epoch 135:  55% 498/901 [00:59<00:46,  8.69it/s]Step 60550: loss = 2.1191\n",
            "Epoch 135:  55% 500/901 [00:59<00:43,  9.21it/s]Step 60550: loss = 2.1195\n",
            "Epoch 135:  66% 598/901 [01:11<00:46,  6.51it/s]Step 60600: loss = 2.1261\n",
            "Epoch 135:  67% 600/901 [01:11<00:39,  7.58it/s]Step 60600: loss = 2.1256\n",
            "Epoch 135:  78% 699/901 [01:22<00:24,  8.37it/s]Step 60650: loss = 2.1309\n",
            "Epoch 135:  78% 700/901 [01:22<00:23,  8.38it/s]Step 60650: loss = 2.1310\n",
            "Epoch 135:  89% 799/901 [01:34<00:12,  8.44it/s]Step 60700: loss = 2.1243\n",
            "Epoch 135:  89% 800/901 [01:34<00:13,  7.75it/s]Step 60700: loss = 2.1242\n",
            "Epoch 135: 100% 899/901 [01:45<00:00,  9.13it/s]Step 60750: loss = 2.1239\n",
            "Step 60750: loss = 2.1237\n",
            "Epoch 135: 100% 901/901 [01:46<00:00,  8.49it/s]\n",
            "Epoch 135 completed. Average training loss: 2.1237\n",
            "Validation loss after epoch 135: 2.3335\n",
            "Checkpoint saved -> checkpoints/model_epoch_135.pt\n",
            "Epoch 136:   0% 0/901 [00:00<?, ?it/s]Step 60750: loss = 2.8471\n",
            "Epoch 136:  11% 99/901 [00:11<01:31,  8.73it/s]Step 60800: loss = 2.1265\n",
            "Epoch 136:  11% 100/901 [00:11<01:28,  9.03it/s]Step 60800: loss = 2.1242\n",
            "Epoch 136:  22% 199/901 [00:22<01:19,  8.84it/s]Step 60850: loss = 2.1239\n",
            "Epoch 136:  22% 200/901 [00:22<01:21,  8.58it/s]Step 60850: loss = 2.1230\n",
            "Epoch 136:  33% 298/901 [00:34<01:08,  8.79it/s]Step 60900: loss = 2.0962\n",
            "Epoch 136:  33% 300/901 [00:35<01:05,  9.16it/s]Step 60900: loss = 2.0987\n",
            "Epoch 136:  44% 399/901 [00:46<01:05,  7.64it/s]Step 60950: loss = 2.1188\n",
            "Epoch 136:  44% 400/901 [00:46<01:13,  6.78it/s]Step 60950: loss = 2.1194\n",
            "Epoch 136:  55% 499/901 [00:57<00:47,  8.44it/s]Step 61000: loss = 2.1240\n",
            "Checkpoint saved -> checkpoints/model_step_61000.pt\n",
            "Epoch 136:  55% 500/901 [00:58<01:42,  3.92it/s]Step 61000: loss = 2.1249\n",
            "Checkpoint saved -> checkpoints/model_step_61000.pt\n",
            "Epoch 136:  66% 599/901 [01:11<00:37,  8.05it/s]Step 61050: loss = 2.1220\n",
            "Epoch 136:  67% 600/901 [01:11<00:37,  8.06it/s]Step 61050: loss = 2.1235\n",
            "Epoch 136:  78% 699/901 [01:22<00:22,  9.17it/s]Step 61100: loss = 2.1315\n",
            "Epoch 136:  78% 700/901 [01:22<00:24,  8.32it/s]Step 61100: loss = 2.1312\n",
            "Epoch 136:  89% 799/901 [01:33<00:12,  8.42it/s]Step 61150: loss = 2.1308\n",
            "Epoch 136:  89% 800/901 [01:33<00:12,  7.84it/s]Step 61150: loss = 2.1306\n",
            "Epoch 136: 100% 898/901 [01:45<00:00,  8.55it/s]Step 61200: loss = 2.1313\n",
            "Epoch 136: 100% 900/901 [01:45<00:00,  9.33it/s]Step 61200: loss = 2.1316\n",
            "Epoch 136: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 136 completed. Average training loss: 2.1316\n",
            "Validation loss after epoch 136: 2.3326\n",
            "Checkpoint saved -> checkpoints/model_epoch_136.pt\n",
            "Epoch 137:   0% 0/901 [00:00<?, ?it/s]Step 61200: loss = 1.8814\n",
            "Epoch 137:  11% 98/901 [00:11<01:24,  9.45it/s]Step 61250: loss = 2.1345\n",
            "Epoch 137:  11% 100/901 [00:11<01:25,  9.35it/s]Step 61250: loss = 2.1264\n",
            "Epoch 137:  22% 198/901 [00:23<01:08, 10.22it/s]Step 61300: loss = 2.1096\n",
            "Epoch 137:  22% 200/901 [00:23<01:12,  9.66it/s]Step 61300: loss = 2.1106\n",
            "Epoch 137:  33% 298/901 [00:34<01:16,  7.91it/s]Step 61350: loss = 2.1231\n",
            "Epoch 137:  33% 300/901 [00:35<01:13,  8.12it/s]Step 61350: loss = 2.1213\n",
            "Epoch 137:  44% 398/901 [00:46<01:01,  8.22it/s]Step 61400: loss = 2.1206\n",
            "Epoch 137:  44% 400/901 [00:46<00:56,  8.85it/s]Step 61400: loss = 2.1199\n",
            "Epoch 137:  55% 498/901 [00:57<00:54,  7.45it/s]Step 61450: loss = 2.1440\n",
            "Epoch 137:  55% 500/901 [00:58<00:57,  7.02it/s]Step 61450: loss = 2.1445\n",
            "Epoch 137:  66% 599/901 [01:09<00:36,  8.23it/s]Step 61500: loss = 2.1420\n",
            "Checkpoint saved -> checkpoints/model_step_61500.pt\n",
            "Epoch 137:  67% 600/901 [01:10<01:12,  4.15it/s]Step 61500: loss = 2.1428\n",
            "Checkpoint saved -> checkpoints/model_step_61500.pt\n",
            "Epoch 137:  77% 698/901 [01:22<00:23,  8.71it/s]Step 61550: loss = 2.1370\n",
            "Epoch 137:  78% 700/901 [01:22<00:21,  9.31it/s]Step 61550: loss = 2.1368\n",
            "Epoch 137:  89% 799/901 [01:34<00:11,  8.83it/s]Step 61600: loss = 2.1351\n",
            "Step 61600: loss = 2.1350\n",
            "Epoch 137: 100% 898/901 [01:45<00:00,  9.94it/s]Step 61650: loss = 2.1394\n",
            "Epoch 137: 100% 900/901 [01:45<00:00,  9.35it/s]Step 61650: loss = 2.1395\n",
            "Epoch 137: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 137 completed. Average training loss: 2.1395\n",
            "Validation loss after epoch 137: 2.3317\n",
            "Checkpoint saved -> checkpoints/model_epoch_137.pt\n",
            "Epoch 138:   0% 0/901 [00:00<?, ?it/s]Step 61650: loss = 1.7052\n",
            "Epoch 138:  11% 99/901 [00:11<01:40,  7.94it/s]Step 61700: loss = 2.1370\n",
            "Epoch 138:  11% 100/901 [00:11<01:50,  7.27it/s]Step 61700: loss = 2.1331\n",
            "Epoch 138:  22% 199/901 [00:23<01:24,  8.29it/s]Step 61750: loss = 2.1038\n",
            "Epoch 138:  22% 200/901 [00:23<01:28,  7.94it/s]Step 61750: loss = 2.1069\n",
            "Epoch 138:  33% 298/901 [00:34<01:02,  9.58it/s]Step 61800: loss = 2.1144\n",
            "Epoch 138:  33% 300/901 [00:34<01:02,  9.54it/s]Step 61800: loss = 2.1138\n",
            "Epoch 138:  44% 399/901 [00:46<00:59,  8.41it/s]Step 61850: loss = 2.1218\n",
            "Step 61850: loss = 2.1230\n",
            "Epoch 138:  55% 499/901 [00:58<00:47,  8.38it/s]Step 61900: loss = 2.1239\n",
            "Epoch 138:  55% 500/901 [00:58<00:46,  8.68it/s]Step 61900: loss = 2.1233\n",
            "Epoch 138:  66% 599/901 [01:09<00:32,  9.25it/s]Step 61950: loss = 2.1286\n",
            "Epoch 138:  67% 600/901 [01:09<00:41,  7.24it/s]Step 61950: loss = 2.1281\n",
            "Epoch 138:  77% 698/901 [01:21<00:25,  8.01it/s]Step 62000: loss = 2.1250\n",
            "Checkpoint saved -> checkpoints/model_step_62000.pt\n",
            "Epoch 138:  78% 700/901 [01:22<00:41,  4.86it/s]Step 62000: loss = 2.1253\n",
            "Checkpoint saved -> checkpoints/model_step_62000.pt\n",
            "Epoch 138:  89% 798/901 [01:34<00:10,  9.70it/s]Step 62050: loss = 2.1287\n",
            "Epoch 138:  89% 800/901 [01:34<00:11,  8.86it/s]Step 62050: loss = 2.1289\n",
            "Epoch 138: 100% 898/901 [01:45<00:00,  9.69it/s]Step 62100: loss = 2.1364\n",
            "Epoch 138: 100% 900/901 [01:45<00:00,  9.73it/s]Step 62100: loss = 2.1364\n",
            "Epoch 138: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 138 completed. Average training loss: 2.1364\n",
            "Validation loss after epoch 138: 2.3308\n",
            "Checkpoint saved -> checkpoints/model_epoch_138.pt\n",
            "Epoch 139:   0% 0/901 [00:00<?, ?it/s]Step 62100: loss = 1.7688\n",
            "Epoch 139:  11% 98/901 [00:11<01:21,  9.82it/s]Step 62150: loss = 2.1063\n",
            "Epoch 139:  11% 100/901 [00:11<01:18, 10.24it/s]Step 62150: loss = 2.1053\n",
            "Epoch 139:  22% 198/901 [00:22<01:16,  9.20it/s]Step 62200: loss = 2.1222\n",
            "Epoch 139:  22% 200/901 [00:22<01:21,  8.55it/s]Step 62200: loss = 2.1250\n",
            "Epoch 139:  33% 299/901 [00:34<01:11,  8.45it/s]Step 62250: loss = 2.1251\n",
            "Epoch 139:  33% 300/901 [00:34<01:10,  8.52it/s]Step 62250: loss = 2.1246\n",
            "Epoch 139:  44% 398/901 [00:46<00:53,  9.34it/s]Step 62300: loss = 2.1183\n",
            "Epoch 139:  44% 400/901 [00:46<00:53,  9.32it/s]Step 62300: loss = 2.1158\n",
            "Epoch 139:  55% 498/901 [00:57<00:45,  8.80it/s]Step 62350: loss = 2.1238\n",
            "Epoch 139:  55% 500/901 [00:57<00:41,  9.61it/s]Step 62350: loss = 2.1225\n",
            "Epoch 139:  66% 598/901 [01:09<00:34,  8.89it/s]Step 62400: loss = 2.1142\n",
            "Epoch 139:  67% 600/901 [01:10<00:35,  8.43it/s]Step 62400: loss = 2.1136\n",
            "Epoch 139:  78% 699/901 [01:21<00:20,  9.96it/s]Step 62450: loss = 2.1268\n",
            "Epoch 139:  78% 700/901 [01:21<00:20,  9.66it/s]Step 62450: loss = 2.1263\n",
            "Epoch 139:  89% 798/901 [01:32<00:15,  6.60it/s]Step 62500: loss = 2.1287\n",
            "Checkpoint saved -> checkpoints/model_step_62500.pt\n",
            "Epoch 139:  89% 800/901 [01:33<00:24,  4.17it/s]Step 62500: loss = 2.1283\n",
            "Checkpoint saved -> checkpoints/model_step_62500.pt\n",
            "Epoch 139: 100% 899/901 [01:45<00:00,  7.85it/s]Step 62550: loss = 2.1287\n",
            "Epoch 139: 100% 900/901 [01:45<00:00,  6.57it/s]Step 62550: loss = 2.1289\n",
            "Epoch 139: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 139 completed. Average training loss: 2.1289\n",
            "Validation loss after epoch 139: 2.3299\n",
            "Checkpoint saved -> checkpoints/model_epoch_139.pt\n",
            "Epoch 140:   0% 0/901 [00:00<?, ?it/s]Step 62550: loss = 2.3462\n",
            "Epoch 140:  11% 98/901 [00:11<01:43,  7.79it/s]Step 62600: loss = 2.1458\n",
            "Epoch 140:  11% 100/901 [00:11<01:41,  7.89it/s]Step 62600: loss = 2.1504\n",
            "Epoch 140:  22% 198/901 [00:22<01:21,  8.67it/s]Step 62650: loss = 2.1518\n",
            "Epoch 140:  22% 200/901 [00:23<01:13,  9.49it/s]Step 62650: loss = 2.1512\n",
            "Epoch 140:  33% 299/901 [00:34<01:12,  8.32it/s]Step 62700: loss = 2.1328\n",
            "Epoch 140:  33% 300/901 [00:34<01:14,  8.10it/s]Step 62700: loss = 2.1331\n",
            "Epoch 140:  44% 398/901 [00:47<01:00,  8.31it/s]Step 62750: loss = 2.0999\n",
            "Epoch 140:  44% 400/901 [00:47<00:56,  8.87it/s]Step 62750: loss = 2.0996\n",
            "Epoch 140:  55% 498/901 [00:58<00:42,  9.49it/s]Step 62800: loss = 2.1070\n",
            "Epoch 140:  55% 500/901 [00:58<00:41,  9.64it/s]Step 62800: loss = 2.1060\n",
            "Epoch 140:  66% 598/901 [01:10<00:33,  9.11it/s]Step 62850: loss = 2.1113\n",
            "Epoch 140:  67% 600/901 [01:10<00:33,  9.09it/s]Step 62850: loss = 2.1101\n",
            "Epoch 140:  78% 699/901 [01:21<00:21,  9.60it/s]Step 62900: loss = 2.1170\n",
            "Epoch 140:  78% 700/901 [01:22<00:23,  8.40it/s]Step 62900: loss = 2.1172\n",
            "Epoch 140:  89% 798/901 [01:32<00:10, 10.02it/s]Step 62950: loss = 2.1263\n",
            "Epoch 140:  89% 800/901 [01:33<00:10, 10.06it/s]Step 62950: loss = 2.1265\n",
            "Epoch 140: 100% 899/901 [01:44<00:00,  9.25it/s]Step 63000: loss = 2.1294\n",
            "Checkpoint saved -> checkpoints/model_step_63000.pt\n",
            "Epoch 140: 100% 900/901 [01:45<00:00,  4.28it/s]Step 63000: loss = 2.1298\n",
            "Checkpoint saved -> checkpoints/model_step_63000.pt\n",
            "Epoch 140: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 140 completed. Average training loss: 2.1298\n",
            "Validation loss after epoch 140: 2.3291\n",
            "Checkpoint saved -> checkpoints/model_epoch_140.pt\n",
            "Epoch 141:   0% 0/901 [00:00<?, ?it/s]Step 63000: loss = 1.9885\n",
            "Checkpoint saved -> checkpoints/model_step_63000.pt\n",
            "Epoch 141:  11% 99/901 [00:11<01:23,  9.58it/s]Step 63050: loss = 2.1615\n",
            "Epoch 141:  11% 100/901 [00:12<01:25,  9.36it/s]Step 63050: loss = 2.1588\n",
            "Epoch 141:  22% 198/901 [00:23<01:29,  7.89it/s]Step 63100: loss = 2.1387\n",
            "Epoch 141:  22% 200/901 [00:24<01:23,  8.43it/s]Step 63100: loss = 2.1366\n",
            "Epoch 141:  33% 298/901 [00:35<01:08,  8.76it/s]Step 63150: loss = 2.1147\n",
            "Epoch 141:  33% 300/901 [00:35<01:06,  9.06it/s]Step 63150: loss = 2.1181\n",
            "Epoch 141:  44% 398/901 [00:47<00:57,  8.68it/s]Step 63200: loss = 2.1066\n",
            "Epoch 141:  44% 400/901 [00:47<01:00,  8.22it/s]Step 63200: loss = 2.1048\n",
            "Epoch 141:  55% 498/901 [00:59<00:43,  9.19it/s]Step 63250: loss = 2.1130\n",
            "Epoch 141:  55% 500/901 [00:59<00:39, 10.20it/s]Step 63250: loss = 2.1143\n",
            "Epoch 141:  66% 599/901 [01:11<00:42,  7.16it/s]Step 63300: loss = 2.1168\n",
            "Epoch 141:  67% 600/901 [01:11<00:41,  7.24it/s]Step 63300: loss = 2.1158\n",
            "Epoch 141:  77% 698/901 [01:22<00:24,  8.14it/s]Step 63350: loss = 2.1177\n",
            "Epoch 141:  78% 700/901 [01:22<00:22,  8.74it/s]Step 63350: loss = 2.1180\n",
            "Epoch 141:  89% 798/901 [01:33<00:10, 10.14it/s]Step 63400: loss = 2.1295\n",
            "Epoch 141:  89% 800/901 [01:33<00:10,  9.74it/s]Step 63400: loss = 2.1299\n",
            "Epoch 141: 100% 898/901 [01:44<00:00,  8.21it/s]Step 63450: loss = 2.1348\n",
            "Epoch 141: 100% 900/901 [01:44<00:00,  8.37it/s]Step 63450: loss = 2.1350\n",
            "Epoch 141: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 141 completed. Average training loss: 2.1350\n",
            "Validation loss after epoch 141: 2.3282\n",
            "Checkpoint saved -> checkpoints/model_epoch_141.pt\n",
            "Epoch 142:   0% 0/901 [00:00<?, ?it/s]Step 63450: loss = 2.4788\n",
            "Epoch 142:  11% 99/901 [00:12<01:40,  7.94it/s]Step 63500: loss = 2.0221\n",
            "Checkpoint saved -> checkpoints/model_step_63500.pt\n",
            "Epoch 142:  11% 100/901 [00:12<03:10,  4.20it/s]Step 63500: loss = 2.0268\n",
            "Checkpoint saved -> checkpoints/model_step_63500.pt\n",
            "Epoch 142:  22% 198/901 [00:24<01:39,  7.06it/s]Step 63550: loss = 2.0688\n",
            "Epoch 142:  22% 200/901 [00:25<01:28,  7.94it/s]Step 63550: loss = 2.0668\n",
            "Epoch 142:  33% 299/901 [00:36<01:08,  8.73it/s]Step 63600: loss = 2.0553\n",
            "Epoch 142:  33% 300/901 [00:36<01:08,  8.80it/s]Step 63600: loss = 2.0563\n",
            "Epoch 142:  44% 399/901 [00:47<00:52,  9.65it/s]Step 63650: loss = 2.0873\n",
            "Epoch 142:  44% 400/901 [00:47<00:52,  9.52it/s]Step 63650: loss = 2.0871\n",
            "Epoch 142:  55% 499/901 [00:59<00:45,  8.75it/s]Step 63700: loss = 2.1108\n",
            "Epoch 142:  55% 500/901 [00:59<00:46,  8.67it/s]Step 63700: loss = 2.1105\n",
            "Epoch 142:  66% 599/901 [01:10<00:33,  8.97it/s]Step 63750: loss = 2.1213\n",
            "Epoch 142:  67% 600/901 [01:10<00:35,  8.43it/s]Step 63750: loss = 2.1227\n",
            "Epoch 142:  78% 699/901 [01:22<00:25,  7.82it/s]Step 63800: loss = 2.1201\n",
            "Epoch 142:  78% 700/901 [01:22<00:34,  5.77it/s]Step 63800: loss = 2.1204\n",
            "Epoch 142:  89% 798/901 [01:33<00:11,  8.95it/s]Step 63850: loss = 2.1259\n",
            "Epoch 142:  89% 800/901 [01:33<00:11,  8.49it/s]Step 63850: loss = 2.1266\n",
            "Epoch 142: 100% 898/901 [01:45<00:00,  9.27it/s]Step 63900: loss = 2.1272\n",
            "Epoch 142: 100% 900/901 [01:45<00:00,  9.58it/s]Step 63900: loss = 2.1271\n",
            "Epoch 142: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 142 completed. Average training loss: 2.1271\n",
            "Validation loss after epoch 142: 2.3273\n",
            "Checkpoint saved -> checkpoints/model_epoch_142.pt\n",
            "Epoch 143:   0% 0/901 [00:00<?, ?it/s]Step 63900: loss = 2.5103\n",
            "Epoch 143:  11% 99/901 [00:11<01:32,  8.64it/s]Step 63950: loss = 2.1563\n",
            "Epoch 143:  11% 100/901 [00:11<01:34,  8.51it/s]Step 63950: loss = 2.1540\n",
            "Epoch 143:  22% 198/901 [00:22<01:20,  8.71it/s]Step 64000: loss = 2.1624\n",
            "Checkpoint saved -> checkpoints/model_step_64000.pt\n",
            "Epoch 143:  22% 200/901 [00:23<02:17,  5.11it/s]Step 64000: loss = 2.1577\n",
            "Checkpoint saved -> checkpoints/model_step_64000.pt\n",
            "Epoch 143:  33% 298/901 [00:35<01:09,  8.72it/s]Step 64050: loss = 2.1548\n",
            "Epoch 143:  33% 300/901 [00:35<01:04,  9.31it/s]Step 64050: loss = 2.1567\n",
            "Epoch 143:  44% 399/901 [00:46<00:52,  9.58it/s]Step 64100: loss = 2.1564\n",
            "Epoch 143:  44% 400/901 [00:46<00:53,  9.39it/s]Step 64100: loss = 2.1567\n",
            "Epoch 143:  55% 499/901 [00:58<00:42,  9.44it/s]Step 64150: loss = 2.1589\n",
            "Epoch 143:  55% 500/901 [00:58<00:42,  9.51it/s]Step 64150: loss = 2.1599\n",
            "Epoch 143:  66% 598/901 [01:09<00:36,  8.30it/s]Step 64200: loss = 2.1594\n",
            "Epoch 143:  67% 600/901 [01:09<00:35,  8.47it/s]Step 64200: loss = 2.1601\n",
            "Epoch 143:  78% 699/901 [01:20<00:25,  7.97it/s]Step 64250: loss = 2.1669\n",
            "Step 64250: loss = 2.1669\n",
            "Epoch 143:  89% 798/901 [01:32<00:11,  9.29it/s]Step 64300: loss = 2.1555\n",
            "Epoch 143:  89% 800/901 [01:32<00:11,  8.72it/s]Step 64300: loss = 2.1555\n",
            "Epoch 143: 100% 898/901 [01:45<00:00,  8.22it/s]Step 64350: loss = 2.1415\n",
            "Epoch 143: 100% 900/901 [01:45<00:00,  8.62it/s]Step 64350: loss = 2.1422\n",
            "Epoch 143: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 143 completed. Average training loss: 2.1422\n",
            "Validation loss after epoch 143: 2.3264\n",
            "Checkpoint saved -> checkpoints/model_epoch_143.pt\n",
            "Epoch 144:   0% 0/901 [00:00<?, ?it/s]Step 64350: loss = 2.0682\n",
            "Epoch 144:  11% 98/901 [00:11<01:26,  9.24it/s]Step 64400: loss = 2.1661\n",
            "Epoch 144:  11% 100/901 [00:11<01:29,  8.98it/s]Step 64400: loss = 2.1717\n",
            "Epoch 144:  22% 198/901 [00:23<01:14,  9.45it/s]Step 64450: loss = 2.1392\n",
            "Epoch 144:  22% 200/901 [00:23<01:14,  9.41it/s]Step 64450: loss = 2.1389\n",
            "Epoch 144:  33% 298/901 [00:34<01:05,  9.18it/s]Step 64500: loss = 2.1275\n",
            "Checkpoint saved -> checkpoints/model_step_64500.pt\n",
            "Epoch 144:  33% 300/901 [00:35<01:58,  5.07it/s]Step 64500: loss = 2.1304\n",
            "Checkpoint saved -> checkpoints/model_step_64500.pt\n",
            "Epoch 144:  44% 399/901 [00:47<01:04,  7.73it/s]Step 64550: loss = 2.1347\n",
            "Epoch 144:  44% 400/901 [00:47<01:00,  8.22it/s]Step 64550: loss = 2.1337\n",
            "Epoch 144:  55% 498/901 [00:58<00:43,  9.35it/s]Step 64600: loss = 2.1336\n",
            "Epoch 144:  55% 500/901 [00:59<00:46,  8.59it/s]Step 64600: loss = 2.1336\n",
            "Epoch 144:  66% 598/901 [01:11<00:32,  9.46it/s]Step 64650: loss = 2.1259\n",
            "Epoch 144:  67% 600/901 [01:11<00:30,  9.81it/s]Step 64650: loss = 2.1275\n",
            "Epoch 144:  77% 698/901 [01:22<00:21,  9.50it/s]Step 64700: loss = 2.1342\n",
            "Epoch 144:  78% 700/901 [01:22<00:20, 10.03it/s]Step 64700: loss = 2.1344\n",
            "Epoch 144:  89% 799/901 [01:34<00:11,  9.12it/s]Step 64750: loss = 2.1337\n",
            "Epoch 144:  89% 800/901 [01:34<00:11,  9.10it/s]Step 64750: loss = 2.1332\n",
            "Epoch 144: 100% 899/901 [01:45<00:00,  9.41it/s]Step 64800: loss = 2.1382\n",
            "Epoch 144: 100% 900/901 [01:45<00:00,  8.55it/s]Step 64800: loss = 2.1384\n",
            "Epoch 144: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 144 completed. Average training loss: 2.1384\n",
            "Validation loss after epoch 144: 2.3256\n",
            "Checkpoint saved -> checkpoints/model_epoch_144.pt\n",
            "Epoch 145:   0% 0/901 [00:00<?, ?it/s]Step 64800: loss = 1.5887\n",
            "Epoch 145:  11% 98/901 [00:11<01:42,  7.85it/s]Step 64850: loss = 2.1343\n",
            "Epoch 145:  11% 100/901 [00:11<01:27,  9.11it/s]Step 64850: loss = 2.1328\n",
            "Epoch 145:  22% 198/901 [00:22<01:16,  9.16it/s]Step 64900: loss = 2.1354\n",
            "Epoch 145:  22% 200/901 [00:22<01:19,  8.77it/s]Step 64900: loss = 2.1373\n",
            "Epoch 145:  33% 299/901 [00:33<01:15,  7.96it/s]Step 64950: loss = 2.1641\n",
            "Epoch 145:  33% 300/901 [00:33<01:16,  7.86it/s]Step 64950: loss = 2.1640\n",
            "Epoch 145:  44% 398/901 [00:44<00:58,  8.59it/s]Step 65000: loss = 2.1545\n",
            "Checkpoint saved -> checkpoints/model_step_65000.pt\n",
            "Epoch 145:  44% 400/901 [00:45<01:43,  4.83it/s]Step 65000: loss = 2.1533\n",
            "Checkpoint saved -> checkpoints/model_step_65000.pt\n",
            "Epoch 145:  55% 499/901 [00:57<00:47,  8.49it/s]Step 65050: loss = 2.1502\n",
            "Epoch 145:  55% 500/901 [00:57<00:46,  8.71it/s]Step 65050: loss = 2.1504\n",
            "Epoch 145:  66% 598/901 [01:09<00:30,  9.84it/s]Step 65100: loss = 2.1401\n",
            "Epoch 145:  67% 600/901 [01:09<00:30, 10.03it/s]Step 65100: loss = 2.1411\n",
            "Epoch 145:  77% 698/901 [01:22<00:21,  9.29it/s]Step 65150: loss = 2.1279\n",
            "Epoch 145:  78% 700/901 [01:22<00:21,  9.56it/s]Step 65150: loss = 2.1280\n",
            "Epoch 145:  89% 799/901 [01:33<00:14,  6.96it/s]Step 65200: loss = 2.1251\n",
            "Epoch 145:  89% 800/901 [01:34<00:14,  7.07it/s]Step 65200: loss = 2.1250\n",
            "Epoch 145: 100% 898/901 [01:45<00:00,  9.12it/s]Step 65250: loss = 2.1353\n",
            "Epoch 145: 100% 900/901 [01:45<00:00,  9.44it/s]Step 65250: loss = 2.1357\n",
            "Epoch 145: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 145 completed. Average training loss: 2.1357\n",
            "Validation loss after epoch 145: 2.3247\n",
            "Checkpoint saved -> checkpoints/model_epoch_145.pt\n",
            "Epoch 146:   0% 0/901 [00:00<?, ?it/s]Step 65250: loss = 1.3847\n",
            "Epoch 146:  11% 99/901 [00:11<01:33,  8.62it/s]Step 65300: loss = 2.1228\n",
            "Step 65300: loss = 2.1244\n",
            "Epoch 146:  22% 198/901 [00:23<01:11,  9.89it/s]Step 65350: loss = 2.1144\n",
            "Epoch 146:  22% 200/901 [00:23<01:12,  9.69it/s]Step 65350: loss = 2.1149\n",
            "Epoch 146:  33% 299/901 [00:34<01:34,  6.35it/s]Step 65400: loss = 2.1385\n",
            "Epoch 146:  33% 300/901 [00:34<01:30,  6.66it/s]Step 65400: loss = 2.1386\n",
            "Epoch 146:  44% 398/901 [00:45<01:00,  8.34it/s]Step 65450: loss = 2.1392\n",
            "Epoch 146:  44% 400/901 [00:46<01:01,  8.19it/s]Step 65450: loss = 2.1400\n",
            "Epoch 146:  55% 499/901 [00:57<00:55,  7.29it/s]Step 65500: loss = 2.1563\n",
            "Checkpoint saved -> checkpoints/model_step_65500.pt\n",
            "Epoch 146:  55% 500/901 [00:57<01:50,  3.62it/s]Step 65500: loss = 2.1579\n",
            "Checkpoint saved -> checkpoints/model_step_65500.pt\n",
            "Epoch 146:  66% 598/901 [01:09<00:33,  9.03it/s]Step 65550: loss = 2.1640\n",
            "Epoch 146:  67% 600/901 [01:09<00:34,  8.70it/s]Step 65550: loss = 2.1639\n",
            "Epoch 146:  77% 698/901 [01:20<00:20,  9.75it/s]Step 65600: loss = 2.1585\n",
            "Epoch 146:  78% 700/901 [01:21<00:19, 10.18it/s]Step 65600: loss = 2.1578\n",
            "Epoch 146:  89% 798/901 [01:32<00:15,  6.59it/s]Step 65650: loss = 2.1502\n",
            "Epoch 146:  89% 800/901 [01:33<00:14,  7.09it/s]Step 65650: loss = 2.1495\n",
            "Epoch 146: 100% 899/901 [01:44<00:00,  8.16it/s]Step 65700: loss = 2.1477\n",
            "Epoch 146: 100% 900/901 [01:44<00:00,  7.75it/s]Step 65700: loss = 2.1470\n",
            "Epoch 146: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 146 completed. Average training loss: 2.1470\n",
            "Validation loss after epoch 146: 2.3238\n",
            "Checkpoint saved -> checkpoints/model_epoch_146.pt\n",
            "Epoch 147:   0% 0/901 [00:00<?, ?it/s]Step 65700: loss = 1.4892\n",
            "Epoch 147:  11% 98/901 [00:11<01:48,  7.43it/s]Step 65750: loss = 2.0789\n",
            "Epoch 147:  11% 100/901 [00:11<01:43,  7.73it/s]Step 65750: loss = 2.0745\n",
            "Epoch 147:  22% 198/901 [00:23<01:23,  8.42it/s]Step 65800: loss = 2.1049\n",
            "Epoch 147:  22% 200/901 [00:23<01:27,  7.98it/s]Step 65800: loss = 2.1081\n",
            "Epoch 147:  33% 299/901 [00:35<01:13,  8.21it/s]Step 65850: loss = 2.1239\n",
            "Epoch 147:  33% 300/901 [00:35<01:11,  8.46it/s]Step 65850: loss = 2.1232\n",
            "Epoch 147:  44% 399/901 [00:47<00:59,  8.44it/s]Step 65900: loss = 2.1160\n",
            "Epoch 147:  44% 400/901 [00:47<01:07,  7.47it/s]Step 65900: loss = 2.1164\n",
            "Epoch 147:  55% 498/901 [00:58<00:38, 10.60it/s]Step 65950: loss = 2.1288\n",
            "Epoch 147:  55% 500/901 [00:58<00:47,  8.37it/s]Step 65950: loss = 2.1281\n",
            "Epoch 147:  66% 599/901 [01:10<00:37,  8.16it/s]Step 66000: loss = 2.1273\n",
            "Checkpoint saved -> checkpoints/model_step_66000.pt\n",
            "Epoch 147:  67% 600/901 [01:11<01:13,  4.09it/s]Step 66000: loss = 2.1273\n",
            "Checkpoint saved -> checkpoints/model_step_66000.pt\n",
            "Epoch 147:  78% 699/901 [01:22<00:22,  8.88it/s]Step 66050: loss = 2.1267\n",
            "Epoch 147:  78% 700/901 [01:22<00:23,  8.54it/s]Step 66050: loss = 2.1263\n",
            "Epoch 147:  89% 799/901 [01:34<00:11,  9.02it/s]Step 66100: loss = 2.1331\n",
            "Epoch 147:  89% 800/901 [01:34<00:10,  9.18it/s]Step 66100: loss = 2.1332\n",
            "Epoch 147: 100% 898/901 [01:45<00:00,  9.76it/s]Step 66150: loss = 2.1265\n",
            "Epoch 147: 100% 900/901 [01:45<00:00,  9.46it/s]Step 66150: loss = 2.1263\n",
            "Epoch 147: 100% 901/901 [01:46<00:00,  8.49it/s]\n",
            "Epoch 147 completed. Average training loss: 2.1263\n",
            "Validation loss after epoch 147: 2.3230\n",
            "Checkpoint saved -> checkpoints/model_epoch_147.pt\n",
            "Epoch 148:   0% 0/901 [00:00<?, ?it/s]Step 66150: loss = 2.2596\n",
            "Epoch 148:  11% 99/901 [00:11<01:25,  9.38it/s]Step 66200: loss = 2.1047\n",
            "Epoch 148:  11% 100/901 [00:11<01:26,  9.26it/s]Step 66200: loss = 2.1050\n",
            "Epoch 148:  22% 198/901 [00:22<01:17,  9.01it/s]Step 66250: loss = 2.1453\n",
            "Epoch 148:  22% 200/901 [00:22<01:15,  9.24it/s]Step 66250: loss = 2.1469\n",
            "Epoch 148:  33% 298/901 [00:33<01:04,  9.40it/s]Step 66300: loss = 2.1603\n",
            "Epoch 148:  33% 300/901 [00:34<01:04,  9.36it/s]Step 66300: loss = 2.1581\n",
            "Epoch 148:  44% 398/901 [00:45<00:50,  9.94it/s]Step 66350: loss = 2.1471\n",
            "Epoch 148:  44% 400/901 [00:45<00:51,  9.77it/s]Step 66350: loss = 2.1482\n",
            "Epoch 148:  55% 499/901 [00:57<00:42,  9.47it/s]Step 66400: loss = 2.1416\n",
            "Epoch 148:  55% 500/901 [00:57<00:48,  8.23it/s]Step 66400: loss = 2.1424\n",
            "Epoch 148:  66% 599/901 [01:09<00:34,  8.78it/s]Step 66450: loss = 2.1330\n",
            "Epoch 148:  67% 600/901 [01:09<00:35,  8.56it/s]Step 66450: loss = 2.1332\n",
            "Epoch 148:  78% 699/901 [01:20<00:21,  9.26it/s]Step 66500: loss = 2.1256\n",
            "Checkpoint saved -> checkpoints/model_step_66500.pt\n",
            "Epoch 148:  78% 700/901 [01:21<00:48,  4.13it/s]Step 66500: loss = 2.1256\n",
            "Checkpoint saved -> checkpoints/model_step_66500.pt\n",
            "Epoch 148:  89% 798/901 [01:33<00:10,  9.57it/s]Step 66550: loss = 2.1237\n",
            "Epoch 148:  89% 800/901 [01:33<00:10,  9.87it/s]Step 66550: loss = 2.1232\n",
            "Epoch 148: 100% 899/901 [01:45<00:00,  9.47it/s]Step 66600: loss = 2.1257\n",
            "Epoch 148: 100% 900/901 [01:45<00:00,  9.49it/s]Step 66600: loss = 2.1262\n",
            "Epoch 148: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 148 completed. Average training loss: 2.1262\n",
            "Validation loss after epoch 148: 2.3221\n",
            "Checkpoint saved -> checkpoints/model_epoch_148.pt\n",
            "Epoch 149:   0% 0/901 [00:00<?, ?it/s]Step 66600: loss = 2.1382\n",
            "Epoch 149:  11% 98/901 [00:11<01:33,  8.57it/s]Step 66650: loss = 2.1200\n",
            "Epoch 149:  11% 100/901 [00:11<01:23,  9.56it/s]Step 66650: loss = 2.1269\n",
            "Epoch 149:  22% 199/901 [00:23<01:17,  9.03it/s]Step 66700: loss = 2.1066\n",
            "Epoch 149:  22% 200/901 [00:23<01:18,  8.91it/s]Step 66700: loss = 2.1061\n",
            "Epoch 149:  33% 299/901 [00:34<01:09,  8.70it/s]Step 66750: loss = 2.1245\n",
            "Epoch 149:  33% 300/901 [00:34<01:07,  8.86it/s]Step 66750: loss = 2.1252\n",
            "Epoch 149:  44% 399/901 [00:46<01:06,  7.54it/s]Step 66800: loss = 2.1216\n",
            "Epoch 149:  44% 400/901 [00:46<01:07,  7.38it/s]Step 66800: loss = 2.1213\n",
            "Epoch 149:  55% 498/901 [00:57<00:44,  9.08it/s]Step 66850: loss = 2.1278\n",
            "Epoch 149:  55% 500/901 [00:57<00:41,  9.59it/s]Step 66850: loss = 2.1276\n",
            "Epoch 149:  66% 599/901 [01:09<00:35,  8.59it/s]Step 66900: loss = 2.1217\n",
            "Step 66900: loss = 2.1209\n",
            "Epoch 149:  77% 698/901 [01:20<00:25,  7.89it/s]Step 66950: loss = 2.1233\n",
            "Epoch 149:  78% 700/901 [01:21<00:23,  8.57it/s]Step 66950: loss = 2.1231\n",
            "Epoch 149:  89% 799/901 [01:32<00:11,  9.15it/s]Step 67000: loss = 2.1226\n",
            "Checkpoint saved -> checkpoints/model_step_67000.pt\n",
            "Epoch 149:  89% 800/901 [01:33<00:22,  4.51it/s]Step 67000: loss = 2.1227\n",
            "Checkpoint saved -> checkpoints/model_step_67000.pt\n",
            "Epoch 149: 100% 899/901 [01:45<00:00,  8.54it/s]Step 67050: loss = 2.1197\n",
            "Epoch 149: 100% 900/901 [01:45<00:00,  7.28it/s]Step 67050: loss = 2.1201\n",
            "Epoch 149: 100% 901/901 [01:45<00:00,  8.50it/s]\n",
            "Epoch 149 completed. Average training loss: 2.1201\n",
            "Validation loss after epoch 149: 2.3213\n",
            "Checkpoint saved -> checkpoints/model_epoch_149.pt\n",
            "Epoch 150:   0% 0/901 [00:00<?, ?it/s]Step 67050: loss = 2.1417\n",
            "Epoch 150:  11% 98/901 [00:11<01:37,  8.21it/s]Step 67100: loss = 2.0326\n",
            "Epoch 150:  11% 100/901 [00:12<01:33,  8.59it/s]Step 67100: loss = 2.0315\n",
            "Epoch 150:  22% 198/901 [00:23<01:10,  9.96it/s]Step 67150: loss = 2.0944\n",
            "Epoch 150:  22% 200/901 [00:23<01:13,  9.54it/s]Step 67150: loss = 2.0957\n",
            "Epoch 150:  33% 298/901 [00:35<01:22,  7.34it/s]Step 67200: loss = 2.0957\n",
            "Epoch 150:  33% 300/901 [00:35<01:21,  7.37it/s]Step 67200: loss = 2.0964\n",
            "Epoch 150:  44% 398/901 [00:46<00:59,  8.45it/s]Step 67250: loss = 2.1162\n",
            "Epoch 150:  44% 400/901 [00:46<00:56,  8.83it/s]Step 67250: loss = 2.1169\n",
            "Epoch 150:  55% 498/901 [00:58<00:45,  8.79it/s]Step 67300: loss = 2.1210\n",
            "Epoch 150:  55% 500/901 [00:58<00:43,  9.21it/s]Step 67300: loss = 2.1210\n",
            "Epoch 150:  66% 599/901 [01:09<00:32,  9.42it/s]Step 67350: loss = 2.1207\n",
            "Epoch 150:  67% 600/901 [01:09<00:34,  8.74it/s]Step 67350: loss = 2.1215\n",
            "Epoch 150:  77% 698/901 [01:21<00:34,  5.81it/s]Step 67400: loss = 2.1203\n",
            "Epoch 150:  78% 700/901 [01:21<00:32,  6.21it/s]Step 67400: loss = 2.1198\n",
            "Epoch 150:  89% 799/901 [01:33<00:11,  9.14it/s]Step 67450: loss = 2.1187\n",
            "Epoch 150:  89% 800/901 [01:33<00:11,  8.82it/s]Step 67450: loss = 2.1189\n",
            "Epoch 150: 100% 898/901 [01:44<00:00,  8.51it/s]Step 67500: loss = 2.1215\n",
            "Checkpoint saved -> checkpoints/model_step_67500.pt\n",
            "Epoch 150: 100% 900/901 [01:45<00:00,  4.65it/s]Step 67500: loss = 2.1216\n",
            "Checkpoint saved -> checkpoints/model_step_67500.pt\n",
            "Epoch 150: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 150 completed. Average training loss: 2.1216\n",
            "Validation loss after epoch 150: 2.3205\n",
            "Checkpoint saved -> checkpoints/model_epoch_150.pt\n",
            "Epoch 151:   0% 0/901 [00:00<?, ?it/s]Step 67500: loss = 2.1490\n",
            "Checkpoint saved -> checkpoints/model_step_67500.pt\n",
            "Epoch 151:  11% 99/901 [00:11<01:22,  9.73it/s]Step 67550: loss = 2.1657\n",
            "Epoch 151:  11% 100/901 [00:11<01:25,  9.35it/s]Step 67550: loss = 2.1649\n",
            "Epoch 151:  22% 198/901 [00:23<01:17,  9.11it/s]Step 67600: loss = 2.1238\n",
            "Epoch 151:  22% 200/901 [00:23<01:17,  9.06it/s]Step 67600: loss = 2.1242\n",
            "Epoch 151:  33% 298/901 [00:35<01:11,  8.38it/s]Step 67650: loss = 2.1125\n",
            "Epoch 151:  33% 300/901 [00:35<01:06,  9.06it/s]Step 67650: loss = 2.1146\n",
            "Epoch 151:  44% 398/901 [00:47<00:55,  9.13it/s]Step 67700: loss = 2.1127\n",
            "Epoch 151:  44% 400/901 [00:47<00:52,  9.60it/s]Step 67700: loss = 2.1129\n",
            "Epoch 151:  55% 498/901 [00:58<00:44,  9.02it/s]Step 67750: loss = 2.1152\n",
            "Epoch 151:  55% 500/901 [00:59<00:42,  9.43it/s]Step 67750: loss = 2.1147\n",
            "Epoch 151:  66% 599/901 [01:10<00:37,  8.15it/s]Step 67800: loss = 2.1101\n",
            "Epoch 151:  67% 600/901 [01:10<00:36,  8.21it/s]Step 67800: loss = 2.1104\n",
            "Epoch 151:  77% 698/901 [01:22<00:23,  8.52it/s]Step 67850: loss = 2.1070\n",
            "Epoch 151:  78% 700/901 [01:22<00:23,  8.59it/s]Step 67850: loss = 2.1075\n",
            "Epoch 151:  89% 799/901 [01:34<00:11,  8.67it/s]Step 67900: loss = 2.1067\n",
            "Epoch 151:  89% 800/901 [01:34<00:12,  8.31it/s]Step 67900: loss = 2.1070\n",
            "Epoch 151: 100% 899/901 [01:45<00:00,  9.67it/s]Step 67950: loss = 2.1143\n",
            "Epoch 151: 100% 900/901 [01:45<00:00,  8.89it/s]Step 67950: loss = 2.1151\n",
            "Epoch 151: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 151 completed. Average training loss: 2.1151\n",
            "Validation loss after epoch 151: 2.3197\n",
            "Checkpoint saved -> checkpoints/model_epoch_151.pt\n",
            "Epoch 152:   0% 0/901 [00:00<?, ?it/s]Step 67950: loss = 2.6574\n",
            "Epoch 152:  11% 99/901 [00:11<01:38,  8.16it/s]Step 68000: loss = 2.0965\n",
            "Checkpoint saved -> checkpoints/model_step_68000.pt\n",
            "Epoch 152:  11% 100/901 [00:12<03:43,  3.59it/s]Step 68000: loss = 2.0933\n",
            "Checkpoint saved -> checkpoints/model_step_68000.pt\n",
            "Epoch 152:  22% 199/901 [00:24<01:15,  9.32it/s]Step 68050: loss = 2.0989\n",
            "Epoch 152:  22% 200/901 [00:24<01:27,  7.97it/s]Step 68050: loss = 2.0976\n",
            "Epoch 152:  33% 298/901 [00:35<01:03,  9.48it/s]Step 68100: loss = 2.1199\n",
            "Epoch 152:  33% 300/901 [00:36<01:03,  9.47it/s]Step 68100: loss = 2.1195\n",
            "Epoch 152:  44% 398/901 [00:47<01:03,  7.91it/s]Step 68150: loss = 2.1180\n",
            "Epoch 152:  44% 400/901 [00:47<00:56,  8.87it/s]Step 68150: loss = 2.1181\n",
            "Epoch 152:  55% 498/901 [00:59<00:44,  9.16it/s]Step 68200: loss = 2.1235\n",
            "Epoch 152:  55% 500/901 [00:59<00:43,  9.32it/s]Step 68200: loss = 2.1248\n",
            "Epoch 152:  66% 598/901 [01:11<00:31,  9.50it/s]Step 68250: loss = 2.1118\n",
            "Epoch 152:  67% 600/901 [01:11<00:32,  9.20it/s]Step 68250: loss = 2.1107\n",
            "Epoch 152:  77% 698/901 [01:22<00:23,  8.50it/s]Step 68300: loss = 2.1221\n",
            "Epoch 152:  78% 700/901 [01:22<00:22,  9.07it/s]Step 68300: loss = 2.1219\n",
            "Epoch 152:  89% 798/901 [01:33<00:11,  9.12it/s]Step 68350: loss = 2.1265\n",
            "Epoch 152:  89% 800/901 [01:33<00:11,  8.81it/s]Step 68350: loss = 2.1270\n",
            "Epoch 152: 100% 898/901 [01:45<00:00,  8.44it/s]Step 68400: loss = 2.1256\n",
            "Epoch 152: 100% 900/901 [01:45<00:00,  8.47it/s]Step 68400: loss = 2.1257\n",
            "Epoch 152: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 152 completed. Average training loss: 2.1257\n",
            "Validation loss after epoch 152: 2.3188\n",
            "Checkpoint saved -> checkpoints/model_epoch_152.pt\n",
            "Epoch 153:   0% 0/901 [00:00<?, ?it/s]Step 68400: loss = 1.8630\n",
            "Epoch 153:  11% 99/901 [00:11<01:32,  8.70it/s]Step 68450: loss = 2.0715\n",
            "Epoch 153:  11% 100/901 [00:12<01:34,  8.46it/s]Step 68450: loss = 2.0731\n",
            "Epoch 153:  22% 198/901 [00:23<01:26,  8.15it/s]Step 68500: loss = 2.1050\n",
            "Checkpoint saved -> checkpoints/model_step_68500.pt\n",
            "Epoch 153:  22% 200/901 [00:24<02:36,  4.47it/s]Step 68500: loss = 2.1015\n",
            "Checkpoint saved -> checkpoints/model_step_68500.pt\n",
            "Epoch 153:  33% 298/901 [00:36<01:00,  9.95it/s]Step 68550: loss = 2.0815\n",
            "Epoch 153:  33% 300/901 [00:37<00:58, 10.22it/s]Step 68550: loss = 2.0809\n",
            "Epoch 153:  44% 399/901 [00:48<01:04,  7.80it/s]Step 68600: loss = 2.0875\n",
            "Epoch 153:  44% 400/901 [00:48<01:01,  8.16it/s]Step 68600: loss = 2.0878\n",
            "Epoch 153:  55% 499/901 [00:59<00:47,  8.41it/s]Step 68650: loss = 2.0993\n",
            "Step 68650: loss = 2.1006\n",
            "Epoch 153:  66% 599/901 [01:11<00:32,  9.31it/s]Step 68700: loss = 2.1093\n",
            "Step 68700: loss = 2.1082\n",
            "Epoch 153:  78% 699/901 [01:22<00:22,  8.87it/s]Step 68750: loss = 2.1134\n",
            "Epoch 153:  78% 700/901 [01:22<00:22,  8.86it/s]Step 68750: loss = 2.1131\n",
            "Epoch 153:  89% 798/901 [01:34<00:11,  9.36it/s]Step 68800: loss = 2.1159\n",
            "Epoch 153:  89% 800/901 [01:34<00:10,  9.60it/s]Step 68800: loss = 2.1159\n",
            "Epoch 153: 100% 898/901 [01:45<00:00,  8.44it/s]Step 68850: loss = 2.1183\n",
            "Epoch 153: 100% 900/901 [01:45<00:00,  9.36it/s]Step 68850: loss = 2.1176\n",
            "Epoch 153: 100% 901/901 [01:45<00:00,  8.50it/s]\n",
            "Epoch 153 completed. Average training loss: 2.1176\n",
            "Validation loss after epoch 153: 2.3180\n",
            "Checkpoint saved -> checkpoints/model_epoch_153.pt\n",
            "Epoch 154:   0% 0/901 [00:00<?, ?it/s]Step 68850: loss = 2.5325\n",
            "Epoch 154:  11% 99/901 [00:11<01:25,  9.33it/s]Step 68900: loss = 2.0949\n",
            "Epoch 154:  11% 100/901 [00:11<01:31,  8.74it/s]Step 68900: loss = 2.0955\n",
            "Epoch 154:  22% 198/901 [00:23<01:15,  9.34it/s]Step 68950: loss = 2.1009\n",
            "Epoch 154:  22% 200/901 [00:23<01:17,  9.08it/s]Step 68950: loss = 2.0983\n",
            "Epoch 154:  33% 299/901 [00:34<01:02,  9.70it/s]Step 69000: loss = 2.1097\n",
            "Checkpoint saved -> checkpoints/model_step_69000.pt\n",
            "Epoch 154:  33% 300/901 [00:35<02:29,  4.03it/s]Step 69000: loss = 2.1095\n",
            "Checkpoint saved -> checkpoints/model_step_69000.pt\n",
            "Epoch 154:  44% 399/901 [00:47<00:58,  8.57it/s]Step 69050: loss = 2.1021\n",
            "Epoch 154:  44% 400/901 [00:47<00:57,  8.65it/s]Step 69050: loss = 2.1030\n",
            "Epoch 154:  55% 499/901 [00:59<00:47,  8.42it/s]Step 69100: loss = 2.1163\n",
            "Epoch 154:  55% 500/901 [00:59<00:46,  8.55it/s]Step 69100: loss = 2.1166\n",
            "Epoch 154:  66% 598/901 [01:10<00:32,  9.29it/s]Step 69150: loss = 2.1178\n",
            "Epoch 154:  67% 600/901 [01:10<00:32,  9.25it/s]Step 69150: loss = 2.1168\n",
            "Epoch 154:  77% 698/901 [01:22<00:21,  9.41it/s]Step 69200: loss = 2.1194\n",
            "Epoch 154:  78% 700/901 [01:22<00:21,  9.44it/s]Step 69200: loss = 2.1198\n",
            "Epoch 154:  89% 799/901 [01:34<00:13,  7.38it/s]Step 69250: loss = 2.1158\n",
            "Epoch 154:  89% 800/901 [01:34<00:12,  7.78it/s]Step 69250: loss = 2.1155\n",
            "Epoch 154: 100% 899/901 [01:45<00:00,  9.33it/s]Step 69300: loss = 2.1235\n",
            "Epoch 154: 100% 900/901 [01:45<00:00,  9.45it/s]Step 69300: loss = 2.1236\n",
            "Epoch 154: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 154 completed. Average training loss: 2.1236\n",
            "Validation loss after epoch 154: 2.3172\n",
            "Checkpoint saved -> checkpoints/model_epoch_154.pt\n",
            "Epoch 155:   0% 0/901 [00:00<?, ?it/s]Step 69300: loss = 2.3562\n",
            "Epoch 155:  11% 98/901 [00:11<01:29,  8.95it/s]Step 69350: loss = 2.1274\n",
            "Epoch 155:  11% 100/901 [00:11<01:25,  9.39it/s]Step 69350: loss = 2.1326\n",
            "Epoch 155:  22% 198/901 [00:23<01:50,  6.36it/s]Step 69400: loss = 2.1387\n",
            "Epoch 155:  22% 200/901 [00:23<01:33,  7.48it/s]Step 69400: loss = 2.1394\n",
            "Epoch 155:  33% 298/901 [00:34<01:07,  8.97it/s]Step 69450: loss = 2.1315\n",
            "Epoch 155:  33% 300/901 [00:34<01:02,  9.56it/s]Step 69450: loss = 2.1296\n",
            "Epoch 155:  44% 398/901 [00:46<00:56,  8.91it/s]Step 69500: loss = 2.1082\n",
            "Checkpoint saved -> checkpoints/model_step_69500.pt\n",
            "Epoch 155:  44% 400/901 [00:47<01:50,  4.55it/s]Step 69500: loss = 2.1070\n",
            "Checkpoint saved -> checkpoints/model_step_69500.pt\n",
            "Epoch 155:  55% 499/901 [00:59<00:46,  8.66it/s]Step 69550: loss = 2.1003\n",
            "Epoch 155:  55% 500/901 [00:59<00:44,  8.94it/s]Step 69550: loss = 2.0992\n",
            "Epoch 155:  66% 598/901 [01:10<00:34,  8.84it/s]Step 69600: loss = 2.1103\n",
            "Epoch 155:  67% 600/901 [01:11<00:32,  9.28it/s]Step 69600: loss = 2.1098\n",
            "Epoch 155:  78% 699/901 [01:22<00:25,  7.90it/s]Step 69650: loss = 2.1129\n",
            "Epoch 155:  78% 700/901 [01:23<00:24,  8.14it/s]Step 69650: loss = 2.1125\n",
            "Epoch 155:  89% 798/901 [01:34<00:12,  8.47it/s]Step 69700: loss = 2.1164\n",
            "Epoch 155:  89% 800/901 [01:34<00:10,  9.20it/s]Step 69700: loss = 2.1161\n",
            "Epoch 155: 100% 898/901 [01:45<00:00,  9.96it/s]Step 69750: loss = 2.1165\n",
            "Epoch 155: 100% 900/901 [01:45<00:00,  9.65it/s]Step 69750: loss = 2.1163\n",
            "Epoch 155: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 155 completed. Average training loss: 2.1163\n",
            "Validation loss after epoch 155: 2.3164\n",
            "Checkpoint saved -> checkpoints/model_epoch_155.pt\n",
            "Epoch 156:   0% 0/901 [00:00<?, ?it/s]Step 69750: loss = 2.6817\n",
            "Epoch 156:  11% 98/901 [00:11<01:32,  8.67it/s]Step 69800: loss = 2.1403\n",
            "Epoch 156:  11% 100/901 [00:11<01:31,  8.76it/s]Step 69800: loss = 2.1411\n",
            "Epoch 156:  22% 199/901 [00:22<01:26,  8.08it/s]Step 69850: loss = 2.1423\n",
            "Step 69850: loss = 2.1419\n",
            "Epoch 156:  33% 299/901 [00:33<01:20,  7.50it/s]Step 69900: loss = 2.1591\n",
            "Step 69900: loss = 2.1599\n",
            "Epoch 156:  44% 399/901 [00:46<00:53,  9.31it/s]Step 69950: loss = 2.1240\n",
            "Epoch 156:  44% 400/901 [00:46<00:57,  8.75it/s]Step 69950: loss = 2.1238\n",
            "Epoch 156:  55% 499/901 [00:58<00:45,  8.75it/s]Step 70000: loss = 2.1226\n",
            "Checkpoint saved -> checkpoints/model_step_70000.pt\n",
            "Epoch 156:  55% 500/901 [00:58<01:48,  3.69it/s]Step 70000: loss = 2.1223\n",
            "Checkpoint saved -> checkpoints/model_step_70000.pt\n",
            "Epoch 156:  66% 598/901 [01:10<00:30,  9.97it/s]Step 70050: loss = 2.1285\n",
            "Epoch 156:  67% 600/901 [01:10<00:29, 10.12it/s]Step 70050: loss = 2.1289\n",
            "Epoch 156:  77% 698/901 [01:22<00:19, 10.44it/s]Step 70100: loss = 2.1279\n",
            "Epoch 156:  78% 700/901 [01:22<00:23,  8.40it/s]Step 70100: loss = 2.1273\n",
            "Epoch 156:  89% 798/901 [01:34<00:12,  8.25it/s]Step 70150: loss = 2.1146\n",
            "Epoch 156:  89% 800/901 [01:34<00:11,  8.44it/s]Step 70150: loss = 2.1144\n",
            "Epoch 156: 100% 898/901 [01:45<00:00,  8.66it/s]Step 70200: loss = 2.1214\n",
            "Epoch 156: 100% 900/901 [01:45<00:00,  8.73it/s]Step 70200: loss = 2.1209\n",
            "Epoch 156: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 156 completed. Average training loss: 2.1209\n",
            "Validation loss after epoch 156: 2.3155\n",
            "Checkpoint saved -> checkpoints/model_epoch_156.pt\n",
            "Epoch 157:   0% 0/901 [00:00<?, ?it/s]Step 70200: loss = 2.7377\n",
            "Epoch 157:  11% 98/901 [00:11<01:31,  8.79it/s]Step 70250: loss = 2.1622\n",
            "Epoch 157:  11% 100/901 [00:11<01:26,  9.21it/s]Step 70250: loss = 2.1584\n",
            "Epoch 157:  22% 199/901 [00:22<01:21,  8.63it/s]Step 70300: loss = 2.1293\n",
            "Epoch 157:  22% 200/901 [00:22<01:21,  8.56it/s]Step 70300: loss = 2.1301\n",
            "Epoch 157:  33% 299/901 [00:33<01:09,  8.67it/s]Step 70350: loss = 2.1459\n",
            "Epoch 157:  33% 300/901 [00:33<01:10,  8.56it/s]Step 70350: loss = 2.1452\n",
            "Epoch 157:  44% 399/901 [00:45<00:48, 10.25it/s]Step 70400: loss = 2.1625\n",
            "Step 70400: loss = 2.1620\n",
            "Epoch 157:  55% 499/901 [00:57<00:53,  7.55it/s]Step 70450: loss = 2.1496\n",
            "Epoch 157:  55% 500/901 [00:57<00:53,  7.50it/s]Step 70450: loss = 2.1489\n",
            "Epoch 157:  66% 598/901 [01:08<00:38,  7.92it/s]Step 70500: loss = 2.1420\n",
            "Checkpoint saved -> checkpoints/model_step_70500.pt\n",
            "Epoch 157:  67% 600/901 [01:09<01:09,  4.35it/s]Step 70500: loss = 2.1408\n",
            "Checkpoint saved -> checkpoints/model_step_70500.pt\n",
            "Epoch 157:  78% 699/901 [01:21<00:21,  9.55it/s]Step 70550: loss = 2.1389\n",
            "Epoch 157:  78% 700/901 [01:21<00:21,  9.23it/s]Step 70550: loss = 2.1387\n",
            "Epoch 157:  89% 798/901 [01:33<00:13,  7.55it/s]Step 70600: loss = 2.1337\n",
            "Epoch 157:  89% 800/901 [01:33<00:11,  8.67it/s]Step 70600: loss = 2.1343\n",
            "Epoch 157: 100% 899/901 [01:44<00:00,  9.22it/s]Step 70650: loss = 2.1320\n",
            "Epoch 157: 100% 900/901 [01:45<00:00,  8.68it/s]Step 70650: loss = 2.1314\n",
            "Epoch 157: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 157 completed. Average training loss: 2.1314\n",
            "Validation loss after epoch 157: 2.3148\n",
            "Checkpoint saved -> checkpoints/model_epoch_157.pt\n",
            "Epoch 158:   0% 0/901 [00:00<?, ?it/s]Step 70650: loss = 1.9458\n",
            "Epoch 158:  11% 99/901 [00:11<01:37,  8.20it/s]Step 70700: loss = 2.0901\n",
            "Epoch 158:  11% 100/901 [00:11<01:42,  7.81it/s]Step 70700: loss = 2.0925\n",
            "Epoch 158:  22% 199/901 [00:23<01:29,  7.82it/s]Step 70750: loss = 2.1063\n",
            "Epoch 158:  22% 200/901 [00:23<01:29,  7.80it/s]Step 70750: loss = 2.1082\n",
            "Epoch 158:  33% 299/901 [00:35<01:10,  8.53it/s]Step 70800: loss = 2.0935\n",
            "Epoch 158:  33% 300/901 [00:35<01:12,  8.32it/s]Step 70800: loss = 2.0939\n",
            "Epoch 158:  44% 398/901 [00:47<00:56,  8.97it/s]Step 70850: loss = 2.1009\n",
            "Epoch 158:  44% 400/901 [00:47<00:54,  9.26it/s]Step 70850: loss = 2.1008\n",
            "Epoch 158:  55% 498/901 [00:57<00:40,  9.95it/s]Step 70900: loss = 2.1342\n",
            "Epoch 158:  55% 500/901 [00:57<00:39, 10.27it/s]Step 70900: loss = 2.1347\n",
            "Epoch 158:  66% 598/901 [01:09<00:32,  9.46it/s]Step 70950: loss = 2.1330\n",
            "Epoch 158:  67% 600/901 [01:09<00:31,  9.69it/s]Step 70950: loss = 2.1313\n",
            "Epoch 158:  78% 699/901 [01:21<00:23,  8.65it/s]Step 71000: loss = 2.1262\n",
            "Checkpoint saved -> checkpoints/model_step_71000.pt\n",
            "Epoch 158:  78% 700/901 [01:21<00:44,  4.56it/s]Step 71000: loss = 2.1265\n",
            "Checkpoint saved -> checkpoints/model_step_71000.pt\n",
            "Epoch 158:  89% 799/901 [01:33<00:11,  9.20it/s]Step 71050: loss = 2.1341\n",
            "Epoch 158:  89% 800/901 [01:33<00:11,  8.42it/s]Step 71050: loss = 2.1336\n",
            "Epoch 158: 100% 899/901 [01:44<00:00,  9.72it/s]Step 71100: loss = 2.1330\n",
            "Epoch 158: 100% 900/901 [01:44<00:00,  9.07it/s]Step 71100: loss = 2.1324\n",
            "Epoch 158: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 158 completed. Average training loss: 2.1324\n",
            "Validation loss after epoch 158: 2.3140\n",
            "Checkpoint saved -> checkpoints/model_epoch_158.pt\n",
            "Epoch 159:   0% 0/901 [00:00<?, ?it/s]Step 71100: loss = 2.3970\n",
            "Epoch 159:  11% 99/901 [00:12<01:34,  8.46it/s]Step 71150: loss = 2.0409\n",
            "Epoch 159:  11% 100/901 [00:12<01:42,  7.85it/s]Step 71150: loss = 2.0310\n",
            "Epoch 159:  22% 199/901 [00:24<01:30,  7.73it/s]Step 71200: loss = 2.0678\n",
            "Epoch 159:  22% 200/901 [00:24<01:42,  6.83it/s]Step 71200: loss = 2.0690\n",
            "Epoch 159:  33% 299/901 [00:35<01:08,  8.81it/s]Step 71250: loss = 2.0935\n",
            "Epoch 159:  33% 300/901 [00:35<01:08,  8.83it/s]Step 71250: loss = 2.0930\n",
            "Epoch 159:  44% 399/901 [00:47<00:55,  8.97it/s]Step 71300: loss = 2.1028\n",
            "Step 71300: loss = 2.1022\n",
            "Epoch 159:  55% 498/901 [00:58<00:43,  9.24it/s]Step 71350: loss = 2.1032\n",
            "Epoch 159:  55% 500/901 [00:58<00:42,  9.50it/s]Step 71350: loss = 2.1054\n",
            "Epoch 159:  66% 598/901 [01:09<00:35,  8.60it/s]Step 71400: loss = 2.1071\n",
            "Epoch 159:  67% 600/901 [01:10<00:31,  9.44it/s]Step 71400: loss = 2.1058\n",
            "Epoch 159:  78% 699/901 [01:21<00:26,  7.49it/s]Step 71450: loss = 2.1091\n",
            "Epoch 159:  78% 700/901 [01:21<00:25,  7.81it/s]Step 71450: loss = 2.1102\n",
            "Epoch 159:  89% 798/901 [01:32<00:10,  9.51it/s]Step 71500: loss = 2.1169\n",
            "Checkpoint saved -> checkpoints/model_step_71500.pt\n",
            "Epoch 159:  89% 800/901 [01:33<00:19,  5.31it/s]Step 71500: loss = 2.1153\n",
            "Checkpoint saved -> checkpoints/model_step_71500.pt\n",
            "Epoch 159: 100% 898/901 [01:45<00:00,  7.90it/s]Step 71550: loss = 2.1138\n",
            "Epoch 159: 100% 900/901 [01:45<00:00,  8.53it/s]Step 71550: loss = 2.1143\n",
            "Epoch 159: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 159 completed. Average training loss: 2.1143\n",
            "Validation loss after epoch 159: 2.3132\n",
            "Checkpoint saved -> checkpoints/model_epoch_159.pt\n",
            "Epoch 160:   0% 0/901 [00:00<?, ?it/s]Step 71550: loss = 0.9218\n",
            "Epoch 160:  11% 98/901 [00:11<01:37,  8.22it/s]Step 71600: loss = 2.1081\n",
            "Epoch 160:  11% 100/901 [00:12<01:24,  9.46it/s]Step 71600: loss = 2.1029\n",
            "Epoch 160:  22% 199/901 [00:23<01:20,  8.71it/s]Step 71650: loss = 2.0999\n",
            "Epoch 160:  22% 200/901 [00:23<01:17,  9.01it/s]Step 71650: loss = 2.1025\n",
            "Epoch 160:  33% 298/901 [00:34<00:59, 10.05it/s]Step 71700: loss = 2.1384\n",
            "Epoch 160:  33% 300/901 [00:34<01:01,  9.73it/s]Step 71700: loss = 2.1404\n",
            "Epoch 160:  44% 398/901 [00:45<00:47, 10.51it/s]Step 71750: loss = 2.1496\n",
            "Epoch 160:  44% 400/901 [00:46<01:03,  7.86it/s]Step 71750: loss = 2.1521\n",
            "Epoch 160:  55% 498/901 [00:57<00:44,  9.00it/s]Step 71800: loss = 2.1374\n",
            "Epoch 160:  55% 500/901 [00:58<00:41,  9.59it/s]Step 71800: loss = 2.1374\n",
            "Epoch 160:  66% 598/901 [01:08<00:38,  7.82it/s]Step 71850: loss = 2.1422\n",
            "Epoch 160:  67% 600/901 [01:09<00:36,  8.14it/s]Step 71850: loss = 2.1428\n",
            "Epoch 160:  77% 698/901 [01:20<00:25,  7.99it/s]Step 71900: loss = 2.1503\n",
            "Epoch 160:  78% 700/901 [01:20<00:24,  8.13it/s]Step 71900: loss = 2.1488\n",
            "Epoch 160:  89% 799/901 [01:32<00:11,  8.69it/s]Step 71950: loss = 2.1337\n",
            "Epoch 160:  89% 800/901 [01:32<00:11,  8.77it/s]Step 71950: loss = 2.1339\n",
            "Epoch 160: 100% 898/901 [01:43<00:00,  7.49it/s]Step 72000: loss = 2.1289\n",
            "Checkpoint saved -> checkpoints/model_step_72000.pt\n",
            "Epoch 160: 100% 900/901 [01:44<00:00,  3.55it/s]Step 72000: loss = 2.1292\n",
            "Checkpoint saved -> checkpoints/model_step_72000.pt\n",
            "Epoch 160: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 160 completed. Average training loss: 2.1292\n",
            "Validation loss after epoch 160: 2.3124\n",
            "Checkpoint saved -> checkpoints/model_epoch_160.pt\n",
            "Epoch 161:   0% 0/901 [00:00<?, ?it/s]Step 72000: loss = 2.4107\n",
            "Checkpoint saved -> checkpoints/model_step_72000.pt\n",
            "Epoch 161:  11% 98/901 [00:12<01:34,  8.49it/s]Step 72050: loss = 2.0951\n",
            "Epoch 161:  11% 100/901 [00:12<01:33,  8.60it/s]Step 72050: loss = 2.0934\n",
            "Epoch 161:  22% 199/901 [00:23<01:16,  9.15it/s]Step 72100: loss = 2.1300\n",
            "Epoch 161:  22% 200/901 [00:23<01:18,  8.89it/s]Step 72100: loss = 2.1304\n",
            "Epoch 161:  33% 298/901 [00:35<01:32,  6.53it/s]Step 72150: loss = 2.1104\n",
            "Epoch 161:  33% 300/901 [00:35<01:17,  7.73it/s]Step 72150: loss = 2.1120\n",
            "Epoch 161:  44% 399/901 [00:47<01:00,  8.27it/s]Step 72200: loss = 2.0987\n",
            "Epoch 161:  44% 400/901 [00:47<01:06,  7.55it/s]Step 72200: loss = 2.1011\n",
            "Epoch 161:  55% 498/901 [00:59<00:47,  8.51it/s]Step 72250: loss = 2.0880\n",
            "Epoch 161:  55% 500/901 [00:59<00:46,  8.71it/s]Step 72250: loss = 2.0871\n",
            "Epoch 161:  66% 599/901 [01:11<00:36,  8.34it/s]Step 72300: loss = 2.0877\n",
            "Epoch 161:  67% 600/901 [01:11<00:34,  8.61it/s]Step 72300: loss = 2.0872\n",
            "Epoch 161:  77% 698/901 [01:22<00:21,  9.55it/s]Step 72350: loss = 2.1068\n",
            "Epoch 161:  78% 700/901 [01:22<00:20, 10.03it/s]Step 72350: loss = 2.1067\n",
            "Epoch 161:  89% 799/901 [01:33<00:12,  8.44it/s]Step 72400: loss = 2.1135\n",
            "Epoch 161:  89% 800/901 [01:33<00:11,  8.54it/s]Step 72400: loss = 2.1137\n",
            "Epoch 161: 100% 898/901 [01:44<00:00,  8.31it/s]Step 72450: loss = 2.1132\n",
            "Epoch 161: 100% 900/901 [01:45<00:00,  8.59it/s]Step 72450: loss = 2.1130\n",
            "Epoch 161: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 161 completed. Average training loss: 2.1130\n",
            "Validation loss after epoch 161: 2.3116\n",
            "Checkpoint saved -> checkpoints/model_epoch_161.pt\n",
            "Epoch 162:   0% 0/901 [00:00<?, ?it/s]Step 72450: loss = 2.3583\n",
            "Epoch 162:  11% 98/901 [00:11<01:31,  8.78it/s]Step 72500: loss = 2.1452\n",
            "Checkpoint saved -> checkpoints/model_step_72500.pt\n",
            "Epoch 162:  11% 100/901 [00:11<02:55,  4.57it/s]Step 72500: loss = 2.1420\n",
            "Checkpoint saved -> checkpoints/model_step_72500.pt\n",
            "Epoch 162:  22% 199/901 [00:23<01:13,  9.56it/s]Step 72550: loss = 2.1319\n",
            "Epoch 162:  22% 200/901 [00:23<01:17,  9.03it/s]Step 72550: loss = 2.1335\n",
            "Epoch 162:  33% 298/901 [00:35<01:00,  9.91it/s]Step 72600: loss = 2.1462\n",
            "Epoch 162:  33% 300/901 [00:35<01:04,  9.27it/s]Step 72600: loss = 2.1467\n",
            "Epoch 162:  44% 398/901 [00:46<00:52,  9.61it/s]Step 72650: loss = 2.1435\n",
            "Epoch 162:  44% 400/901 [00:46<01:00,  8.28it/s]Step 72650: loss = 2.1430\n",
            "Epoch 162:  55% 499/901 [00:58<00:45,  8.74it/s]Step 72700: loss = 2.1334\n",
            "Epoch 162:  55% 500/901 [00:58<00:47,  8.48it/s]Step 72700: loss = 2.1334\n",
            "Epoch 162:  66% 598/901 [01:10<00:39,  7.64it/s]Step 72750: loss = 2.1194\n",
            "Epoch 162:  67% 600/901 [01:10<00:35,  8.45it/s]Step 72750: loss = 2.1187\n",
            "Epoch 162:  78% 699/901 [01:22<00:22,  9.17it/s]Step 72800: loss = 2.1257\n",
            "Step 72800: loss = 2.1260\n",
            "Epoch 162:  89% 799/901 [01:33<00:11,  9.21it/s]Step 72850: loss = 2.1204\n",
            "Epoch 162:  89% 800/901 [01:33<00:12,  8.20it/s]Step 72850: loss = 2.1204\n",
            "Epoch 162: 100% 899/901 [01:45<00:00,  8.06it/s]Step 72900: loss = 2.1171\n",
            "Epoch 162: 100% 900/901 [01:45<00:00,  7.73it/s]Step 72900: loss = 2.1162\n",
            "Epoch 162: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 162 completed. Average training loss: 2.1162\n",
            "Validation loss after epoch 162: 2.3108\n",
            "Checkpoint saved -> checkpoints/model_epoch_162.pt\n",
            "Epoch 163:   0% 0/901 [00:00<?, ?it/s]Step 72900: loss = 2.2154\n",
            "Epoch 163:  11% 98/901 [00:11<01:44,  7.68it/s]Step 72950: loss = 2.0977\n",
            "Epoch 163:  11% 100/901 [00:11<01:36,  8.33it/s]Step 72950: loss = 2.1010\n",
            "Epoch 163:  22% 199/901 [00:23<01:26,  8.15it/s]Step 73000: loss = 2.1130\n",
            "Checkpoint saved -> checkpoints/model_step_73000.pt\n",
            "Epoch 163:  22% 200/901 [00:23<02:57,  3.94it/s]Step 73000: loss = 2.1156\n",
            "Checkpoint saved -> checkpoints/model_step_73000.pt\n",
            "Epoch 163:  33% 299/901 [00:35<01:27,  6.91it/s]Step 73050: loss = 2.1064\n",
            "Epoch 163:  33% 300/901 [00:36<01:22,  7.25it/s]Step 73050: loss = 2.1079\n",
            "Epoch 163:  44% 399/901 [00:47<00:53,  9.40it/s]Step 73100: loss = 2.1196\n",
            "Epoch 163:  44% 400/901 [00:47<00:53,  9.37it/s]Step 73100: loss = 2.1194\n",
            "Epoch 163:  55% 498/901 [00:58<00:49,  8.07it/s]Step 73150: loss = 2.1207\n",
            "Epoch 163:  55% 500/901 [00:58<00:49,  8.11it/s]Step 73150: loss = 2.1200\n",
            "Epoch 163:  66% 599/901 [01:10<00:40,  7.40it/s]Step 73200: loss = 2.1206\n",
            "Epoch 163:  67% 600/901 [01:10<00:41,  7.33it/s]Step 73200: loss = 2.1209\n",
            "Epoch 163:  78% 699/901 [01:21<00:21,  9.60it/s]Step 73250: loss = 2.1173\n",
            "Epoch 163:  78% 700/901 [01:22<00:21,  9.30it/s]Step 73250: loss = 2.1167\n",
            "Epoch 163:  89% 799/901 [01:33<00:12,  8.17it/s]Step 73300: loss = 2.1089\n",
            "Epoch 163:  89% 800/901 [01:33<00:12,  8.35it/s]Step 73300: loss = 2.1091\n",
            "Epoch 163: 100% 899/901 [01:45<00:00,  8.43it/s]Step 73350: loss = 2.1088\n",
            "Epoch 163: 100% 900/901 [01:45<00:00,  8.47it/s]Step 73350: loss = 2.1084\n",
            "Epoch 163: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 163 completed. Average training loss: 2.1084\n",
            "Validation loss after epoch 163: 2.3100\n",
            "Checkpoint saved -> checkpoints/model_epoch_163.pt\n",
            "Epoch 164:   0% 0/901 [00:00<?, ?it/s]Step 73350: loss = 2.0715\n",
            "Epoch 164:  11% 98/901 [00:11<01:30,  8.86it/s]Step 73400: loss = 2.1077\n",
            "Epoch 164:  11% 100/901 [00:11<01:22,  9.72it/s]Step 73400: loss = 2.1076\n",
            "Epoch 164:  22% 199/901 [00:22<01:15,  9.35it/s]Step 73450: loss = 2.1194\n",
            "Epoch 164:  22% 200/901 [00:22<01:19,  8.77it/s]Step 73450: loss = 2.1148\n",
            "Epoch 164:  33% 298/901 [00:34<01:16,  7.88it/s]Step 73500: loss = 2.0890\n",
            "Checkpoint saved -> checkpoints/model_step_73500.pt\n",
            "Epoch 164:  33% 300/901 [00:35<02:07,  4.73it/s]Step 73500: loss = 2.0886\n",
            "Checkpoint saved -> checkpoints/model_step_73500.pt\n",
            "Epoch 164:  44% 398/901 [00:47<00:55,  9.08it/s]Step 73550: loss = 2.0978\n",
            "Epoch 164:  44% 400/901 [00:47<00:54,  9.27it/s]Step 73550: loss = 2.0965\n",
            "Epoch 164:  55% 498/901 [00:58<00:43,  9.26it/s]Step 73600: loss = 2.1029\n",
            "Epoch 164:  55% 500/901 [00:59<00:43,  9.16it/s]Step 73600: loss = 2.1036\n",
            "Epoch 164:  66% 598/901 [01:10<00:36,  8.31it/s]Step 73650: loss = 2.0964\n",
            "Epoch 164:  67% 600/901 [01:10<00:32,  9.28it/s]Step 73650: loss = 2.0956\n",
            "Epoch 164:  78% 699/901 [01:22<00:24,  8.12it/s]Step 73700: loss = 2.0995\n",
            "Epoch 164:  78% 700/901 [01:22<00:24,  8.34it/s]Step 73700: loss = 2.0996\n",
            "Epoch 164:  89% 799/901 [01:34<00:12,  8.26it/s]Step 73750: loss = 2.0983\n",
            "Epoch 164:  89% 800/901 [01:34<00:16,  6.31it/s]Step 73750: loss = 2.0977\n",
            "Epoch 164: 100% 898/901 [01:45<00:00,  9.09it/s]Step 73800: loss = 2.1069\n",
            "Epoch 164: 100% 900/901 [01:45<00:00,  9.61it/s]Step 73800: loss = 2.1066\n",
            "Epoch 164: 100% 901/901 [01:45<00:00,  8.50it/s]\n",
            "Epoch 164 completed. Average training loss: 2.1066\n",
            "Validation loss after epoch 164: 2.3092\n",
            "Checkpoint saved -> checkpoints/model_epoch_164.pt\n",
            "Epoch 165:   0% 0/901 [00:00<?, ?it/s]Step 73800: loss = 1.6682\n",
            "Epoch 165:  11% 98/901 [00:11<01:30,  8.91it/s]Step 73850: loss = 2.0970\n",
            "Epoch 165:  11% 100/901 [00:11<01:22,  9.65it/s]Step 73850: loss = 2.0959\n",
            "Epoch 165:  22% 199/901 [00:22<01:16,  9.19it/s]Step 73900: loss = 2.1035\n",
            "Epoch 165:  22% 200/901 [00:22<01:17,  9.09it/s]Step 73900: loss = 2.1033\n",
            "Epoch 165:  33% 299/901 [00:34<01:10,  8.59it/s]Step 73950: loss = 2.1088\n",
            "Epoch 165:  33% 300/901 [00:34<01:10,  8.52it/s]Step 73950: loss = 2.1066\n",
            "Epoch 165:  44% 398/901 [00:45<00:58,  8.64it/s]Step 74000: loss = 2.1087\n",
            "Checkpoint saved -> checkpoints/model_step_74000.pt\n",
            "Epoch 165:  44% 400/901 [00:46<01:40,  4.96it/s]Step 74000: loss = 2.1082\n",
            "Checkpoint saved -> checkpoints/model_step_74000.pt\n",
            "Epoch 165:  55% 498/901 [00:58<00:44,  9.03it/s]Step 74050: loss = 2.1044\n",
            "Epoch 165:  55% 500/901 [00:58<00:42,  9.43it/s]Step 74050: loss = 2.1047\n",
            "Epoch 165:  66% 599/901 [01:10<00:32,  9.36it/s]Step 74100: loss = 2.1081\n",
            "Step 74100: loss = 2.1088\n",
            "Epoch 165:  77% 698/901 [01:21<00:25,  8.05it/s]Step 74150: loss = 2.1076\n",
            "Epoch 165:  78% 700/901 [01:22<00:23,  8.38it/s]Step 74150: loss = 2.1073\n",
            "Epoch 165:  89% 798/901 [01:34<00:12,  8.52it/s]Step 74200: loss = 2.1019\n",
            "Epoch 165:  89% 800/901 [01:34<00:10,  9.38it/s]Step 74200: loss = 2.1027\n",
            "Epoch 165: 100% 898/901 [01:45<00:00,  8.23it/s]Step 74250: loss = 2.1065\n",
            "Epoch 165: 100% 900/901 [01:45<00:00,  8.74it/s]Step 74250: loss = 2.1078\n",
            "Epoch 165: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 165 completed. Average training loss: 2.1078\n",
            "Validation loss after epoch 165: 2.3085\n",
            "Checkpoint saved -> checkpoints/model_epoch_165.pt\n",
            "Epoch 166:   0% 0/901 [00:00<?, ?it/s]Step 74250: loss = 1.7471\n",
            "Epoch 166:  11% 99/901 [00:11<01:36,  8.30it/s]Step 74300: loss = 2.1409\n",
            "Epoch 166:  11% 100/901 [00:11<01:38,  8.16it/s]Step 74300: loss = 2.1346\n",
            "Epoch 166:  22% 199/901 [00:23<01:26,  8.13it/s]Step 74350: loss = 2.1104\n",
            "Epoch 166:  22% 200/901 [00:23<01:27,  8.06it/s]Step 74350: loss = 2.1154\n",
            "Epoch 166:  33% 298/901 [00:34<01:22,  7.32it/s]Step 74400: loss = 2.1252\n",
            "Epoch 166:  33% 300/901 [00:34<01:13,  8.17it/s]Step 74400: loss = 2.1267\n",
            "Epoch 166:  44% 399/901 [00:46<00:55,  9.03it/s]Step 74450: loss = 2.1163\n",
            "Epoch 166:  44% 400/901 [00:46<01:07,  7.47it/s]Step 74450: loss = 2.1178\n",
            "Epoch 166:  55% 498/901 [00:57<00:45,  8.90it/s]Step 74500: loss = 2.1081\n",
            "Checkpoint saved -> checkpoints/model_step_74500.pt\n",
            "Epoch 166:  55% 500/901 [00:58<01:23,  4.80it/s]Step 74500: loss = 2.1083\n",
            "Checkpoint saved -> checkpoints/model_step_74500.pt\n",
            "Epoch 166:  66% 598/901 [01:10<00:38,  7.91it/s]Step 74550: loss = 2.1200\n",
            "Epoch 166:  67% 600/901 [01:10<00:38,  7.81it/s]Step 74550: loss = 2.1197\n",
            "Epoch 166:  78% 699/901 [01:22<00:23,  8.54it/s]Step 74600: loss = 2.1190\n",
            "Step 74600: loss = 2.1187\n",
            "Epoch 166:  89% 798/901 [01:33<00:12,  8.32it/s]Step 74650: loss = 2.1264\n",
            "Epoch 166:  89% 800/901 [01:33<00:12,  8.33it/s]Step 74650: loss = 2.1267\n",
            "Epoch 166: 100% 898/901 [01:45<00:00,  7.75it/s]Step 74700: loss = 2.1181\n",
            "Epoch 166: 100% 900/901 [01:45<00:00,  5.41it/s]Step 74700: loss = 2.1185\n",
            "Epoch 166: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 166 completed. Average training loss: 2.1185\n",
            "Validation loss after epoch 166: 2.3077\n",
            "Checkpoint saved -> checkpoints/model_epoch_166.pt\n",
            "Epoch 167:   0% 0/901 [00:00<?, ?it/s]Step 74700: loss = 2.0984\n",
            "Epoch 167:  11% 98/901 [00:11<01:41,  7.92it/s]Step 74750: loss = 2.1050\n",
            "Epoch 167:  11% 100/901 [00:11<01:28,  9.07it/s]Step 74750: loss = 2.1072\n",
            "Epoch 167:  22% 198/901 [00:23<01:21,  8.60it/s]Step 74800: loss = 2.1126\n",
            "Epoch 167:  22% 200/901 [00:23<01:16,  9.14it/s]Step 74800: loss = 2.1113\n",
            "Epoch 167:  33% 298/901 [00:34<01:10,  8.61it/s]Step 74850: loss = 2.0960\n",
            "Epoch 167:  33% 300/901 [00:35<01:06,  9.05it/s]Step 74850: loss = 2.0962\n",
            "Epoch 167:  44% 398/901 [00:47<00:58,  8.59it/s]Step 74900: loss = 2.0850\n",
            "Epoch 167:  44% 400/901 [00:47<00:55,  9.06it/s]Step 74900: loss = 2.0820\n",
            "Epoch 167:  55% 499/901 [00:58<00:43,  9.34it/s]Step 74950: loss = 2.1002\n",
            "Epoch 167:  55% 500/901 [00:58<00:43,  9.22it/s]Step 74950: loss = 2.1002\n",
            "Epoch 167:  66% 598/901 [01:09<00:32,  9.24it/s]Step 75000: loss = 2.1109\n",
            "Checkpoint saved -> checkpoints/model_step_75000.pt\n",
            "Epoch 167:  67% 600/901 [01:10<00:58,  5.13it/s]Step 75000: loss = 2.1115\n",
            "Checkpoint saved -> checkpoints/model_step_75000.pt\n",
            "Epoch 167:  78% 699/901 [01:21<00:21,  9.34it/s]Step 75050: loss = 2.1223\n",
            "Epoch 167:  78% 700/901 [01:22<00:35,  5.69it/s]Step 75050: loss = 2.1221\n",
            "Epoch 167:  89% 798/901 [01:33<00:12,  8.06it/s]Step 75100: loss = 2.1284\n",
            "Epoch 167:  89% 800/901 [01:33<00:11,  8.73it/s]Step 75100: loss = 2.1278\n",
            "Epoch 167: 100% 898/901 [01:45<00:00,  8.50it/s]Step 75150: loss = 2.1229\n",
            "Epoch 167: 100% 900/901 [01:45<00:00,  9.32it/s]Step 75150: loss = 2.1230\n",
            "Epoch 167: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 167 completed. Average training loss: 2.1230\n",
            "Validation loss after epoch 167: 2.3070\n",
            "Checkpoint saved -> checkpoints/model_epoch_167.pt\n",
            "Epoch 168:   0% 0/901 [00:00<?, ?it/s]Step 75150: loss = 2.2502\n",
            "Epoch 168:  11% 98/901 [00:11<01:53,  7.10it/s]Step 75200: loss = 2.0794\n",
            "Epoch 168:  11% 100/901 [00:11<01:37,  8.24it/s]Step 75200: loss = 2.0811\n",
            "Epoch 168:  22% 198/901 [00:22<01:19,  8.83it/s]Step 75250: loss = 2.1084\n",
            "Epoch 168:  22% 200/901 [00:22<01:12,  9.65it/s]Step 75250: loss = 2.1066\n",
            "Epoch 168:  33% 298/901 [00:34<00:58, 10.37it/s]Step 75300: loss = 2.1245\n",
            "Epoch 168:  33% 300/901 [00:34<01:00,  9.92it/s]Step 75300: loss = 2.1236\n",
            "Epoch 168:  44% 399/901 [00:46<00:54,  9.16it/s]Step 75350: loss = 2.1174\n",
            "Epoch 168:  44% 400/901 [00:46<00:54,  9.18it/s]Step 75350: loss = 2.1195\n",
            "Epoch 168:  55% 499/901 [00:57<00:43,  9.22it/s]Step 75400: loss = 2.1257\n",
            "Epoch 168:  55% 500/901 [00:57<00:45,  8.80it/s]Step 75400: loss = 2.1256\n",
            "Epoch 168:  66% 598/901 [01:09<00:33,  9.12it/s]Step 75450: loss = 2.1258\n",
            "Epoch 168:  67% 600/901 [01:09<00:31,  9.62it/s]Step 75450: loss = 2.1246\n",
            "Epoch 168:  78% 699/901 [01:21<00:24,  8.27it/s]Step 75500: loss = 2.1232\n",
            "Checkpoint saved -> checkpoints/model_step_75500.pt\n",
            "Epoch 168:  78% 700/901 [01:21<00:50,  4.02it/s]Step 75500: loss = 2.1224\n",
            "Checkpoint saved -> checkpoints/model_step_75500.pt\n",
            "Epoch 168:  89% 798/901 [01:33<00:12,  8.54it/s]Step 75550: loss = 2.1209\n",
            "Epoch 168:  89% 800/901 [01:33<00:11,  8.74it/s]Step 75550: loss = 2.1209\n",
            "Epoch 168: 100% 898/901 [01:45<00:00,  7.87it/s]Step 75600: loss = 2.1198\n",
            "Epoch 168: 100% 900/901 [01:45<00:00,  8.05it/s]Step 75600: loss = 2.1202\n",
            "Epoch 168: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 168 completed. Average training loss: 2.1202\n",
            "Validation loss after epoch 168: 2.3062\n",
            "Checkpoint saved -> checkpoints/model_epoch_168.pt\n",
            "Epoch 169:   0% 0/901 [00:00<?, ?it/s]Step 75600: loss = 2.4233\n",
            "Epoch 169:  11% 98/901 [00:10<01:25,  9.37it/s]Step 75650: loss = 2.1600\n",
            "Epoch 169:  11% 100/901 [00:11<01:27,  9.20it/s]Step 75650: loss = 2.1574\n",
            "Epoch 169:  22% 199/901 [00:22<01:14,  9.43it/s]Step 75700: loss = 2.1199\n",
            "Epoch 169:  22% 200/901 [00:23<01:16,  9.12it/s]Step 75700: loss = 2.1212\n",
            "Epoch 169:  33% 298/901 [00:34<01:05,  9.16it/s]Step 75750: loss = 2.1158\n",
            "Epoch 169:  33% 300/901 [00:34<01:12,  8.27it/s]Step 75750: loss = 2.1155\n",
            "Epoch 169:  44% 398/901 [00:46<00:53,  9.40it/s]Step 75800: loss = 2.1197\n",
            "Epoch 169:  44% 400/901 [00:46<00:52,  9.57it/s]Step 75800: loss = 2.1191\n",
            "Epoch 169:  55% 499/901 [00:58<00:53,  7.54it/s]Step 75850: loss = 2.1060\n",
            "Epoch 169:  55% 500/901 [00:58<00:56,  7.11it/s]Step 75850: loss = 2.1047\n",
            "Epoch 169:  66% 598/901 [01:09<00:32,  9.26it/s]Step 75900: loss = 2.1041\n",
            "Epoch 169:  67% 600/901 [01:09<00:30,  9.99it/s]Step 75900: loss = 2.1043\n",
            "Epoch 169:  77% 698/901 [01:21<00:24,  8.17it/s]Step 75950: loss = 2.1088\n",
            "Epoch 169:  78% 700/901 [01:21<00:22,  8.76it/s]Step 75950: loss = 2.1091\n",
            "Epoch 169:  89% 799/901 [01:32<00:10,  9.69it/s]Step 76000: loss = 2.1112\n",
            "Checkpoint saved -> checkpoints/model_step_76000.pt\n",
            "Epoch 169:  89% 800/901 [01:33<00:24,  4.10it/s]Step 76000: loss = 2.1116\n",
            "Checkpoint saved -> checkpoints/model_step_76000.pt\n",
            "Epoch 169: 100% 899/901 [01:45<00:00,  9.53it/s]Step 76050: loss = 2.1160\n",
            "Step 76050: loss = 2.1159\n",
            "Epoch 169: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 169 completed. Average training loss: 2.1159\n",
            "Validation loss after epoch 169: 2.3055\n",
            "Checkpoint saved -> checkpoints/model_epoch_169.pt\n",
            "Epoch 170:   0% 0/901 [00:00<?, ?it/s]Step 76050: loss = 1.5128\n",
            "Epoch 170:  11% 99/901 [00:11<01:39,  8.04it/s]Step 76100: loss = 2.0700\n",
            "Step 76100: loss = 2.0653\n",
            "Epoch 170:  22% 198/901 [00:22<01:31,  7.70it/s]Step 76150: loss = 2.1021\n",
            "Epoch 170:  22% 200/901 [00:23<01:24,  8.30it/s]Step 76150: loss = 2.1039\n",
            "Epoch 170:  33% 298/901 [00:34<01:14,  8.07it/s]Step 76200: loss = 2.0973\n",
            "Epoch 170:  33% 300/901 [00:34<01:08,  8.77it/s]Step 76200: loss = 2.0982\n",
            "Epoch 170:  44% 398/901 [00:46<00:54,  9.19it/s]Step 76250: loss = 2.1118\n",
            "Epoch 170:  44% 400/901 [00:46<00:52,  9.60it/s]Step 76250: loss = 2.1107\n",
            "Epoch 170:  55% 499/901 [00:57<00:48,  8.35it/s]Step 76300: loss = 2.1052\n",
            "Epoch 170:  55% 500/901 [00:57<00:48,  8.32it/s]Step 76300: loss = 2.1050\n",
            "Epoch 170:  66% 598/901 [01:09<00:41,  7.34it/s]Step 76350: loss = 2.1120\n",
            "Epoch 170:  67% 600/901 [01:09<00:35,  8.38it/s]Step 76350: loss = 2.1127\n",
            "Epoch 170:  77% 698/901 [01:20<00:23,  8.82it/s]Step 76400: loss = 2.1134\n",
            "Epoch 170:  78% 700/901 [01:20<00:21,  9.19it/s]Step 76400: loss = 2.1127\n",
            "Epoch 170:  89% 799/901 [01:32<00:12,  8.18it/s]Step 76450: loss = 2.1127\n",
            "Epoch 170:  89% 800/901 [01:32<00:12,  8.22it/s]Step 76450: loss = 2.1130\n",
            "Epoch 170: 100% 899/901 [01:44<00:00,  8.98it/s]Step 76500: loss = 2.1091\n",
            "Checkpoint saved -> checkpoints/model_step_76500.pt\n",
            "Epoch 170: 100% 900/901 [01:45<00:00,  3.84it/s]Step 76500: loss = 2.1093\n",
            "Checkpoint saved -> checkpoints/model_step_76500.pt\n",
            "Epoch 170: 100% 901/901 [01:45<00:00,  8.50it/s]\n",
            "Epoch 170 completed. Average training loss: 2.1093\n",
            "Validation loss after epoch 170: 2.3047\n",
            "Checkpoint saved -> checkpoints/model_epoch_170.pt\n",
            "Epoch 171:   0% 0/901 [00:00<?, ?it/s]Step 76500: loss = 1.8985\n",
            "Checkpoint saved -> checkpoints/model_step_76500.pt\n",
            "Epoch 171:  11% 98/901 [00:11<01:32,  8.72it/s]Step 76550: loss = 2.1331\n",
            "Epoch 171:  11% 100/901 [00:11<01:31,  8.77it/s]Step 76550: loss = 2.1344\n",
            "Epoch 171:  22% 199/901 [00:24<01:20,  8.74it/s]Step 76600: loss = 2.0959\n",
            "Epoch 171:  22% 200/901 [00:24<01:25,  8.23it/s]Step 76600: loss = 2.0957\n",
            "Epoch 171:  33% 299/901 [00:35<01:12,  8.33it/s]Step 76650: loss = 2.1103\n",
            "Epoch 171:  33% 300/901 [00:35<01:09,  8.68it/s]Step 76650: loss = 2.1112\n",
            "Epoch 171:  44% 398/901 [00:46<00:53,  9.48it/s]Step 76700: loss = 2.1080\n",
            "Epoch 171:  44% 400/901 [00:47<00:52,  9.60it/s]Step 76700: loss = 2.1082\n",
            "Epoch 171:  55% 498/901 [00:58<00:44,  8.98it/s]Step 76750: loss = 2.1118\n",
            "Epoch 171:  55% 500/901 [00:58<00:43,  9.27it/s]Step 76750: loss = 2.1104\n",
            "Epoch 171:  66% 598/901 [01:09<00:31,  9.75it/s]Step 76800: loss = 2.1161\n",
            "Epoch 171:  67% 600/901 [01:10<00:30,  9.91it/s]Step 76800: loss = 2.1174\n",
            "Epoch 171:  78% 699/901 [01:21<00:22,  8.96it/s]Step 76850: loss = 2.1103\n",
            "Epoch 171:  78% 700/901 [01:21<00:25,  7.73it/s]Step 76850: loss = 2.1097\n",
            "Epoch 171:  89% 799/901 [01:33<00:10,  9.29it/s]Step 76900: loss = 2.1071\n",
            "Epoch 171:  89% 800/901 [01:33<00:12,  8.23it/s]Step 76900: loss = 2.1072\n",
            "Epoch 171: 100% 898/901 [01:44<00:00,  7.02it/s]Step 76950: loss = 2.0995\n",
            "Epoch 171: 100% 900/901 [01:45<00:00,  7.37it/s]Step 76950: loss = 2.0992\n",
            "Epoch 171: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 171 completed. Average training loss: 2.0992\n",
            "Validation loss after epoch 171: 2.3039\n",
            "Checkpoint saved -> checkpoints/model_epoch_171.pt\n",
            "Epoch 172:   0% 0/901 [00:00<?, ?it/s]Step 76950: loss = 1.9936\n",
            "Epoch 172:  11% 99/901 [00:11<02:01,  6.60it/s]Step 77000: loss = 2.0403\n",
            "Checkpoint saved -> checkpoints/model_step_77000.pt\n",
            "Epoch 172:  11% 100/901 [00:12<04:10,  3.20it/s]Step 77000: loss = 2.0419\n",
            "Checkpoint saved -> checkpoints/model_step_77000.pt\n",
            "Epoch 172:  22% 198/901 [00:24<01:26,  8.11it/s]Step 77050: loss = 2.0797\n",
            "Epoch 172:  22% 200/901 [00:24<01:25,  8.22it/s]Step 77050: loss = 2.0802\n",
            "Epoch 172:  33% 298/901 [00:36<01:13,  8.18it/s]Step 77100: loss = 2.0838\n",
            "Epoch 172:  33% 300/901 [00:36<01:16,  7.88it/s]Step 77100: loss = 2.0834\n",
            "Epoch 172:  44% 398/901 [00:48<00:55,  8.99it/s]Step 77150: loss = 2.0925\n",
            "Epoch 172:  44% 400/901 [00:48<00:53,  9.33it/s]Step 77150: loss = 2.0949\n",
            "Epoch 172:  55% 498/901 [00:59<00:39, 10.33it/s]Step 77200: loss = 2.0983\n",
            "Epoch 172:  55% 500/901 [00:59<00:40,  9.93it/s]Step 77200: loss = 2.0985\n",
            "Epoch 172:  66% 599/901 [01:10<00:32,  9.43it/s]Step 77250: loss = 2.1119\n",
            "Step 77250: loss = 2.1125\n",
            "Epoch 172:  78% 699/901 [01:22<00:24,  8.38it/s]Step 77300: loss = 2.1051\n",
            "Epoch 172:  78% 700/901 [01:22<00:23,  8.69it/s]Step 77300: loss = 2.1058\n",
            "Epoch 172:  89% 798/901 [01:33<00:13,  7.56it/s]Step 77350: loss = 2.1035\n",
            "Epoch 172:  89% 800/901 [01:34<00:12,  8.40it/s]Step 77350: loss = 2.1033\n",
            "Epoch 172: 100% 898/901 [01:45<00:00,  9.27it/s]Step 77400: loss = 2.1070\n",
            "Epoch 172: 100% 900/901 [01:45<00:00,  8.69it/s]Step 77400: loss = 2.1074\n",
            "Epoch 172: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 172 completed. Average training loss: 2.1074\n",
            "Validation loss after epoch 172: 2.3032\n",
            "Checkpoint saved -> checkpoints/model_epoch_172.pt\n",
            "Epoch 173:   0% 0/901 [00:00<?, ?it/s]Step 77400: loss = 1.5662\n",
            "Epoch 173:  11% 99/901 [00:11<01:40,  7.96it/s]Step 77450: loss = 2.1330\n",
            "Epoch 173:  11% 100/901 [00:11<01:36,  8.29it/s]Step 77450: loss = 2.1304\n",
            "Epoch 173:  22% 199/901 [00:22<01:12,  9.74it/s]Step 77500: loss = 2.1114\n",
            "Checkpoint saved -> checkpoints/model_step_77500.pt\n",
            "Epoch 173:  22% 200/901 [00:23<02:40,  4.38it/s]Step 77500: loss = 2.1081\n",
            "Checkpoint saved -> checkpoints/model_step_77500.pt\n",
            "Epoch 173:  33% 299/901 [00:35<01:18,  7.65it/s]Step 77550: loss = 2.0927\n",
            "Epoch 173:  33% 300/901 [00:35<01:17,  7.74it/s]Step 77550: loss = 2.0917\n",
            "Epoch 173:  44% 398/901 [00:47<01:03,  7.93it/s]Step 77600: loss = 2.0897\n",
            "Epoch 173:  44% 400/901 [00:47<01:00,  8.31it/s]Step 77600: loss = 2.0896\n",
            "Epoch 173:  55% 499/901 [00:59<00:41,  9.63it/s]Step 77650: loss = 2.0982\n",
            "Step 77650: loss = 2.0975\n",
            "Epoch 173:  66% 598/901 [01:10<00:32,  9.30it/s]Step 77700: loss = 2.1056\n",
            "Epoch 173:  67% 600/901 [01:10<00:31,  9.58it/s]Step 77700: loss = 2.1044\n",
            "Epoch 173:  77% 698/901 [01:21<00:23,  8.69it/s]Step 77750: loss = 2.1094\n",
            "Epoch 173:  78% 700/901 [01:21<00:22,  8.97it/s]Step 77750: loss = 2.1096\n",
            "Epoch 173:  89% 798/901 [01:33<00:11,  8.66it/s]Step 77800: loss = 2.1063\n",
            "Epoch 173:  89% 800/901 [01:33<00:10,  9.28it/s]Step 77800: loss = 2.1061\n",
            "Epoch 173: 100% 899/901 [01:45<00:00,  8.24it/s]Step 77850: loss = 2.1056\n",
            "Epoch 173: 100% 900/901 [01:45<00:00,  7.96it/s]Step 77850: loss = 2.1063\n",
            "Epoch 173: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 173 completed. Average training loss: 2.1063\n",
            "Validation loss after epoch 173: 2.3024\n",
            "Checkpoint saved -> checkpoints/model_epoch_173.pt\n",
            "Epoch 174:   0% 0/901 [00:00<?, ?it/s]Step 77850: loss = 2.3339\n",
            "Epoch 174:  11% 98/901 [00:11<01:35,  8.43it/s]Step 77900: loss = 2.1435\n",
            "Epoch 174:  11% 100/901 [00:11<01:32,  8.65it/s]Step 77900: loss = 2.1384\n",
            "Epoch 174:  22% 198/901 [00:22<01:14,  9.49it/s]Step 77950: loss = 2.1364\n",
            "Epoch 174:  22% 200/901 [00:22<01:12,  9.61it/s]Step 77950: loss = 2.1381\n",
            "Epoch 174:  33% 299/901 [00:34<01:04,  9.36it/s]Step 78000: loss = 2.1320\n",
            "Checkpoint saved -> checkpoints/model_step_78000.pt\n",
            "Epoch 174:  33% 300/901 [00:34<02:11,  4.56it/s]Step 78000: loss = 2.1322\n",
            "Checkpoint saved -> checkpoints/model_step_78000.pt\n",
            "Epoch 174:  44% 399/901 [00:47<00:55,  9.09it/s]Step 78050: loss = 2.1136\n",
            "Epoch 174:  44% 400/901 [00:47<00:54,  9.18it/s]Step 78050: loss = 2.1152\n",
            "Epoch 174:  55% 498/901 [00:58<00:42,  9.50it/s]Step 78100: loss = 2.1149\n",
            "Epoch 174:  55% 500/901 [00:59<00:40,  9.96it/s]Step 78100: loss = 2.1158\n",
            "Epoch 174:  66% 598/901 [01:10<00:31,  9.77it/s]Step 78150: loss = 2.1125\n",
            "Epoch 174:  67% 600/901 [01:10<00:36,  8.24it/s]Step 78150: loss = 2.1119\n",
            "Epoch 174:  77% 698/901 [01:21<00:23,  8.46it/s]Step 78200: loss = 2.1143\n",
            "Epoch 174:  78% 700/901 [01:22<00:27,  7.42it/s]Step 78200: loss = 2.1141\n",
            "Epoch 174:  89% 799/901 [01:33<00:12,  8.22it/s]Step 78250: loss = 2.1101\n",
            "Step 78250: loss = 2.1099\n",
            "Epoch 174: 100% 898/901 [01:45<00:00,  8.26it/s]Step 78300: loss = 2.1091\n",
            "Epoch 174: 100% 900/901 [01:45<00:00,  8.66it/s]Step 78300: loss = 2.1091\n",
            "Epoch 174: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 174 completed. Average training loss: 2.1091\n",
            "Validation loss after epoch 174: 2.3017\n",
            "Checkpoint saved -> checkpoints/model_epoch_174.pt\n",
            "Epoch 175:   0% 0/901 [00:00<?, ?it/s]Step 78300: loss = 2.2115\n",
            "Epoch 175:  11% 98/901 [00:11<01:27,  9.21it/s]Step 78350: loss = 2.1740\n",
            "Epoch 175:  11% 100/901 [00:11<01:24,  9.48it/s]Step 78350: loss = 2.1739\n",
            "Epoch 175:  22% 198/901 [00:22<01:19,  8.88it/s]Step 78400: loss = 2.1617\n",
            "Epoch 175:  22% 200/901 [00:22<01:13,  9.53it/s]Step 78400: loss = 2.1625\n",
            "Epoch 175:  33% 298/901 [00:33<01:13,  8.20it/s]Step 78450: loss = 2.1451\n",
            "Epoch 175:  33% 300/901 [00:34<01:08,  8.72it/s]Step 78450: loss = 2.1427\n",
            "Epoch 175:  44% 399/901 [00:45<01:01,  8.22it/s]Step 78500: loss = 2.1240\n",
            "Checkpoint saved -> checkpoints/model_step_78500.pt\n",
            "Epoch 175:  44% 400/901 [00:45<02:14,  3.73it/s]Step 78500: loss = 2.1230\n",
            "Checkpoint saved -> checkpoints/model_step_78500.pt\n",
            "Epoch 175:  55% 499/901 [00:57<00:42,  9.52it/s]Step 78550: loss = 2.1291\n",
            "Epoch 175:  55% 500/901 [00:57<00:42,  9.38it/s]Step 78550: loss = 2.1293\n",
            "Epoch 175:  66% 599/901 [01:09<00:35,  8.54it/s]Step 78600: loss = 2.1243\n",
            "Epoch 175:  67% 600/901 [01:09<00:43,  6.84it/s]Step 78600: loss = 2.1243\n",
            "Epoch 175:  77% 698/901 [01:21<00:22,  8.83it/s]Step 78650: loss = 2.1163\n",
            "Epoch 175:  78% 700/901 [01:21<00:22,  9.10it/s]Step 78650: loss = 2.1168\n",
            "Epoch 175:  89% 798/901 [01:33<00:12,  7.99it/s]Step 78700: loss = 2.1082\n",
            "Epoch 175:  89% 800/901 [01:33<00:13,  7.69it/s]Step 78700: loss = 2.1083\n",
            "Epoch 175: 100% 899/901 [01:45<00:00,  8.60it/s]Step 78750: loss = 2.1041\n",
            "Epoch 175: 100% 900/901 [01:45<00:00,  8.44it/s]Step 78750: loss = 2.1036\n",
            "Epoch 175: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 175 completed. Average training loss: 2.1036\n",
            "Validation loss after epoch 175: 2.3010\n",
            "Checkpoint saved -> checkpoints/model_epoch_175.pt\n",
            "Epoch 176:   0% 0/901 [00:00<?, ?it/s]Step 78750: loss = 2.3810\n",
            "Epoch 176:  11% 99/901 [00:11<01:33,  8.60it/s]Step 78800: loss = 2.1390\n",
            "Epoch 176:  11% 100/901 [00:11<01:32,  8.70it/s]Step 78800: loss = 2.1363\n",
            "Epoch 176:  22% 198/901 [00:23<01:25,  8.22it/s]Step 78850: loss = 2.1181\n",
            "Epoch 176:  22% 200/901 [00:23<01:18,  8.90it/s]Step 78850: loss = 2.1171\n",
            "Epoch 176:  33% 298/901 [00:34<01:05,  9.16it/s]Step 78900: loss = 2.1236\n",
            "Epoch 176:  33% 300/901 [00:34<00:59, 10.06it/s]Step 78900: loss = 2.1246\n",
            "Epoch 176:  44% 398/901 [00:46<01:00,  8.35it/s]Step 78950: loss = 2.1165\n",
            "Epoch 176:  44% 400/901 [00:46<00:56,  8.83it/s]Step 78950: loss = 2.1184\n",
            "Epoch 176:  55% 499/901 [00:57<00:41,  9.60it/s]Step 79000: loss = 2.1254\n",
            "Checkpoint saved -> checkpoints/model_step_79000.pt\n",
            "Epoch 176:  55% 500/901 [00:58<01:35,  4.22it/s]Step 79000: loss = 2.1249\n",
            "Checkpoint saved -> checkpoints/model_step_79000.pt\n",
            "Epoch 176:  66% 599/901 [01:10<00:36,  8.22it/s]Step 79050: loss = 2.1255\n",
            "Step 79050: loss = 2.1247\n",
            "Epoch 176:  78% 699/901 [01:22<00:23,  8.60it/s]Step 79100: loss = 2.1075\n",
            "Epoch 176:  78% 700/901 [01:22<00:23,  8.61it/s]Step 79100: loss = 2.1076\n",
            "Epoch 176:  89% 798/901 [01:33<00:12,  8.58it/s]Step 79150: loss = 2.1125\n",
            "Epoch 176:  89% 800/901 [01:33<00:12,  8.41it/s]Step 79150: loss = 2.1127\n",
            "Epoch 176: 100% 898/901 [01:45<00:00,  8.80it/s]Step 79200: loss = 2.1048\n",
            "Epoch 176: 100% 900/901 [01:45<00:00,  9.32it/s]Step 79200: loss = 2.1038\n",
            "Epoch 176: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 176 completed. Average training loss: 2.1038\n",
            "Validation loss after epoch 176: 2.3003\n",
            "Checkpoint saved -> checkpoints/model_epoch_176.pt\n",
            "Epoch 177:   0% 0/901 [00:00<?, ?it/s]Step 79200: loss = 2.2231\n",
            "Epoch 177:  11% 99/901 [00:12<01:42,  7.81it/s]Step 79250: loss = 2.0386\n",
            "Step 79250: loss = 2.0387\n",
            "Epoch 177:  22% 198/901 [00:23<01:16,  9.18it/s]Step 79300: loss = 2.0659\n",
            "Epoch 177:  22% 200/901 [00:24<01:14,  9.45it/s]Step 79300: loss = 2.0666\n",
            "Epoch 177:  33% 298/901 [00:35<01:09,  8.66it/s]Step 79350: loss = 2.0817\n",
            "Epoch 177:  33% 300/901 [00:35<01:04,  9.38it/s]Step 79350: loss = 2.0820\n",
            "Epoch 177:  44% 399/901 [00:47<00:58,  8.62it/s]Step 79400: loss = 2.0862\n",
            "Step 79400: loss = 2.0864\n",
            "Epoch 177:  55% 498/901 [00:58<00:43,  9.37it/s]Step 79450: loss = 2.0925\n",
            "Epoch 177:  55% 500/901 [00:58<00:54,  7.32it/s]Step 79450: loss = 2.0939\n",
            "Epoch 177:  66% 598/901 [01:09<00:32,  9.38it/s]Step 79500: loss = 2.1001\n",
            "Checkpoint saved -> checkpoints/model_step_79500.pt\n",
            "Epoch 177:  67% 600/901 [01:10<01:01,  4.88it/s]Step 79500: loss = 2.1007\n",
            "Checkpoint saved -> checkpoints/model_step_79500.pt\n",
            "Epoch 177:  77% 698/901 [01:22<00:24,  8.39it/s]Step 79550: loss = 2.1047\n",
            "Epoch 177:  78% 700/901 [01:22<00:21,  9.25it/s]Step 79550: loss = 2.1033\n",
            "Epoch 177:  89% 798/901 [01:33<00:10,  9.43it/s]Step 79600: loss = 2.1085\n",
            "Epoch 177:  89% 800/901 [01:33<00:10,  9.65it/s]Step 79600: loss = 2.1089\n",
            "Epoch 177: 100% 898/901 [01:45<00:00,  9.22it/s]Step 79650: loss = 2.1079\n",
            "Epoch 177: 100% 900/901 [01:45<00:00,  8.66it/s]Step 79650: loss = 2.1075\n",
            "Epoch 177: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 177 completed. Average training loss: 2.1075\n",
            "Validation loss after epoch 177: 2.2995\n",
            "Checkpoint saved -> checkpoints/model_epoch_177.pt\n",
            "Epoch 178:   0% 0/901 [00:00<?, ?it/s]Step 79650: loss = 1.5891\n",
            "Epoch 178:  11% 99/901 [00:11<01:32,  8.64it/s]Step 79700: loss = 2.0790\n",
            "Epoch 178:  11% 100/901 [00:11<01:36,  8.29it/s]Step 79700: loss = 2.0829\n",
            "Epoch 178:  22% 199/901 [00:23<01:26,  8.12it/s]Step 79750: loss = 2.1126\n",
            "Epoch 178:  22% 200/901 [00:23<01:25,  8.25it/s]Step 79750: loss = 2.1130\n",
            "Epoch 178:  33% 298/901 [00:34<01:10,  8.56it/s]Step 79800: loss = 2.1160\n",
            "Epoch 178:  33% 300/901 [00:34<01:05,  9.14it/s]Step 79800: loss = 2.1147\n",
            "Epoch 178:  44% 399/901 [00:45<00:51,  9.69it/s]Step 79850: loss = 2.1164\n",
            "Epoch 178:  44% 400/901 [00:45<00:51,  9.65it/s]Step 79850: loss = 2.1154\n",
            "Epoch 178:  55% 498/901 [00:57<00:46,  8.58it/s]Step 79900: loss = 2.1099\n",
            "Epoch 178:  55% 500/901 [00:57<00:43,  9.22it/s]Step 79900: loss = 2.1098\n",
            "Epoch 178:  66% 599/901 [01:09<00:34,  8.74it/s]Step 79950: loss = 2.1078\n",
            "Epoch 178:  67% 600/901 [01:09<00:34,  8.64it/s]Step 79950: loss = 2.1073\n",
            "Epoch 178:  78% 699/901 [01:20<00:21,  9.61it/s]Step 80000: loss = 2.1108\n",
            "Checkpoint saved -> checkpoints/model_step_80000.pt\n",
            "Epoch 178:  78% 700/901 [01:21<00:50,  4.00it/s]Step 80000: loss = 2.1101\n",
            "Checkpoint saved -> checkpoints/model_step_80000.pt\n",
            "Epoch 178:  89% 799/901 [01:33<00:17,  5.76it/s]Step 80050: loss = 2.1037\n",
            "Epoch 178:  89% 800/901 [01:33<00:15,  6.36it/s]Step 80050: loss = 2.1044\n",
            "Epoch 178: 100% 899/901 [01:45<00:00,  8.69it/s]Step 80100: loss = 2.1024\n",
            "Epoch 178: 100% 900/901 [01:45<00:00,  8.46it/s]Step 80100: loss = 2.1035\n",
            "Epoch 178: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 178 completed. Average training loss: 2.1035\n",
            "Validation loss after epoch 178: 2.2988\n",
            "Checkpoint saved -> checkpoints/model_epoch_178.pt\n",
            "Epoch 179:   0% 0/901 [00:00<?, ?it/s]Step 80100: loss = 2.2437\n",
            "Epoch 179:  11% 99/901 [00:11<01:37,  8.20it/s]Step 80150: loss = 2.1021\n",
            "Epoch 179:  11% 100/901 [00:11<01:35,  8.35it/s]Step 80150: loss = 2.1054\n",
            "Epoch 179:  22% 199/901 [00:23<01:23,  8.41it/s]Step 80200: loss = 2.0940\n",
            "Epoch 179:  22% 200/901 [00:23<01:21,  8.63it/s]Step 80200: loss = 2.0918\n",
            "Epoch 179:  33% 299/901 [00:34<01:11,  8.40it/s]Step 80250: loss = 2.0925\n",
            "Epoch 179:  33% 300/901 [00:35<01:20,  7.49it/s]Step 80250: loss = 2.0914\n",
            "Epoch 179:  44% 398/901 [00:46<00:53,  9.34it/s]Step 80300: loss = 2.1081\n",
            "Epoch 179:  44% 400/901 [00:46<00:52,  9.58it/s]Step 80300: loss = 2.1079\n",
            "Epoch 179:  55% 498/901 [00:57<00:46,  8.58it/s]Step 80350: loss = 2.1022\n",
            "Epoch 179:  55% 500/901 [00:57<00:45,  8.81it/s]Step 80350: loss = 2.1027\n",
            "Epoch 179:  66% 599/901 [01:09<00:32,  9.24it/s]Step 80400: loss = 2.1015\n",
            "Step 80400: loss = 2.1006\n",
            "Epoch 179:  78% 699/901 [01:21<00:26,  7.70it/s]Step 80450: loss = 2.1000\n",
            "Epoch 179:  78% 700/901 [01:21<00:25,  7.91it/s]Step 80450: loss = 2.1000\n",
            "Epoch 179:  89% 799/901 [01:32<00:12,  8.21it/s]Step 80500: loss = 2.1013\n",
            "Checkpoint saved -> checkpoints/model_step_80500.pt\n",
            "Epoch 179:  89% 800/901 [01:33<00:25,  4.01it/s]Step 80500: loss = 2.1011\n",
            "Checkpoint saved -> checkpoints/model_step_80500.pt\n",
            "Epoch 179: 100% 899/901 [01:45<00:00,  8.25it/s]Step 80550: loss = 2.0987\n",
            "Epoch 179: 100% 900/901 [01:45<00:00,  8.60it/s]Step 80550: loss = 2.0988\n",
            "Epoch 179: 100% 901/901 [01:46<00:00,  8.50it/s]\n",
            "Epoch 179 completed. Average training loss: 2.0988\n",
            "Validation loss after epoch 179: 2.2981\n",
            "Checkpoint saved -> checkpoints/model_epoch_179.pt\n",
            "Epoch 180:   0% 0/901 [00:00<?, ?it/s]Step 80550: loss = 2.2527\n",
            "Epoch 180:  11% 98/901 [00:11<01:32,  8.70it/s]Step 80600: loss = 2.1050\n",
            "Epoch 180:  11% 100/901 [00:11<01:32,  8.66it/s]Step 80600: loss = 2.1003\n",
            "Epoch 180:  22% 198/901 [00:23<01:13,  9.62it/s]Step 80650: loss = 2.0610\n",
            "Epoch 180:  22% 200/901 [00:23<01:18,  8.98it/s]Step 80650: loss = 2.0632\n",
            "Epoch 180:  33% 299/901 [00:35<01:26,  6.92it/s]Step 80700: loss = 2.0569\n",
            "Step 80700: loss = 2.0602\n",
            "Epoch 180:  44% 398/901 [00:46<00:53,  9.38it/s]Step 80750: loss = 2.0821\n",
            "Epoch 180:  44% 400/901 [00:46<00:51,  9.68it/s]Step 80750: loss = 2.0824\n",
            "Epoch 180:  55% 498/901 [00:57<00:46,  8.63it/s]Step 80800: loss = 2.0939\n",
            "Epoch 180:  55% 500/901 [00:57<00:44,  9.05it/s]Step 80800: loss = 2.0934\n",
            "Epoch 180:  66% 598/901 [01:08<00:29, 10.12it/s]Step 80850: loss = 2.1034\n",
            "Epoch 180:  67% 600/901 [01:09<00:32,  9.34it/s]Step 80850: loss = 2.1044\n",
            "Epoch 180:  78% 699/901 [01:20<00:25,  7.96it/s]Step 80900: loss = 2.0995\n",
            "Epoch 180:  78% 700/901 [01:21<00:26,  7.65it/s]Step 80900: loss = 2.1000\n",
            "Epoch 180:  89% 798/901 [01:32<00:13,  7.42it/s]Step 80950: loss = 2.1035\n",
            "Epoch 180:  89% 800/901 [01:32<00:12,  8.19it/s]Step 80950: loss = 2.1025\n",
            "Epoch 180: 100% 898/901 [01:44<00:00,  8.19it/s]Step 81000: loss = 2.0968\n",
            "Checkpoint saved -> checkpoints/model_step_81000.pt\n",
            "Epoch 180: 100% 900/901 [01:45<00:00,  4.37it/s]Step 81000: loss = 2.0978\n",
            "Checkpoint saved -> checkpoints/model_step_81000.pt\n",
            "Epoch 180: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 180 completed. Average training loss: 2.0978\n",
            "Validation loss after epoch 180: 2.2974\n",
            "Checkpoint saved -> checkpoints/model_epoch_180.pt\n",
            "Epoch 181:   0% 0/901 [00:00<?, ?it/s]Step 81000: loss = 2.6901\n",
            "Checkpoint saved -> checkpoints/model_step_81000.pt\n",
            "Epoch 181:  11% 99/901 [00:12<01:46,  7.53it/s]Step 81050: loss = 2.1010\n",
            "Epoch 181:  11% 100/901 [00:12<01:48,  7.37it/s]Step 81050: loss = 2.1074\n",
            "Epoch 181:  22% 199/901 [00:23<01:17,  9.05it/s]Step 81100: loss = 2.0987\n",
            "Epoch 181:  22% 200/901 [00:23<01:20,  8.69it/s]Step 81100: loss = 2.0978\n",
            "Epoch 181:  33% 299/901 [00:35<01:13,  8.24it/s]Step 81150: loss = 2.0901\n",
            "Epoch 181:  33% 300/901 [00:35<01:10,  8.54it/s]Step 81150: loss = 2.0915\n",
            "Epoch 181:  44% 398/901 [00:46<00:50,  9.98it/s]Step 81200: loss = 2.1061\n",
            "Epoch 181:  44% 400/901 [00:46<00:55,  9.05it/s]Step 81200: loss = 2.1066\n",
            "Epoch 181:  55% 498/901 [00:58<00:45,  8.77it/s]Step 81250: loss = 2.1083\n",
            "Epoch 181:  55% 500/901 [00:58<00:41,  9.63it/s]Step 81250: loss = 2.1072\n",
            "Epoch 181:  66% 599/901 [01:10<00:31,  9.54it/s]Step 81300: loss = 2.1096\n",
            "Epoch 181:  67% 600/901 [01:10<00:33,  9.00it/s]Step 81300: loss = 2.1093\n",
            "Epoch 181:  78% 699/901 [01:21<00:23,  8.66it/s]Step 81350: loss = 2.1007\n",
            "Epoch 181:  78% 700/901 [01:22<00:24,  8.36it/s]Step 81350: loss = 2.1016\n",
            "Epoch 181:  89% 798/901 [01:33<00:11,  8.59it/s]Step 81400: loss = 2.1035\n",
            "Epoch 181:  89% 800/901 [01:33<00:10,  9.49it/s]Step 81400: loss = 2.1039\n",
            "Epoch 181: 100% 899/901 [01:44<00:00,  7.87it/s]Step 81450: loss = 2.1028\n",
            "Epoch 181: 100% 900/901 [01:45<00:00,  8.08it/s]Step 81450: loss = 2.1027\n",
            "Epoch 181: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 181 completed. Average training loss: 2.1027\n",
            "Validation loss after epoch 181: 2.2967\n",
            "Checkpoint saved -> checkpoints/model_epoch_181.pt\n",
            "Epoch 182:   0% 0/901 [00:00<?, ?it/s]Step 81450: loss = 1.9898\n",
            "Epoch 182:  11% 99/901 [00:11<01:27,  9.22it/s]Step 81500: loss = 2.1086\n",
            "Checkpoint saved -> checkpoints/model_step_81500.pt\n",
            "Epoch 182:  11% 100/901 [00:11<03:08,  4.25it/s]Step 81500: loss = 2.1092\n",
            "Checkpoint saved -> checkpoints/model_step_81500.pt\n",
            "Epoch 182:  22% 199/901 [00:23<01:17,  9.03it/s]Step 81550: loss = 2.1124\n",
            "Epoch 182:  22% 200/901 [00:23<01:26,  8.11it/s]Step 81550: loss = 2.1125\n",
            "Epoch 182:  33% 299/901 [00:35<01:10,  8.58it/s]Step 81600: loss = 2.1186\n",
            "Epoch 182:  33% 300/901 [00:35<01:16,  7.89it/s]Step 81600: loss = 2.1165\n",
            "Epoch 182:  44% 399/901 [00:46<00:54,  9.16it/s]Step 81650: loss = 2.1098\n",
            "Epoch 182:  44% 400/901 [00:47<00:56,  8.93it/s]Step 81650: loss = 2.1067\n",
            "Epoch 182:  55% 499/901 [00:58<00:46,  8.58it/s]Step 81700: loss = 2.0957\n",
            "Step 81700: loss = 2.0948\n",
            "Epoch 182:  66% 599/901 [01:11<00:32,  9.40it/s]Step 81750: loss = 2.0856\n",
            "Epoch 182:  67% 600/901 [01:11<00:34,  8.75it/s]Step 81750: loss = 2.0852\n",
            "Epoch 182:  77% 698/901 [01:22<00:23,  8.69it/s]Step 81800: loss = 2.0839\n",
            "Epoch 182:  78% 700/901 [01:22<00:22,  8.96it/s]Step 81800: loss = 2.0846\n",
            "Epoch 182:  89% 799/901 [01:34<00:11,  8.65it/s]Step 81850: loss = 2.0808\n",
            "Epoch 182:  89% 800/901 [01:34<00:11,  8.53it/s]Step 81850: loss = 2.0805\n",
            "Epoch 182: 100% 898/901 [01:45<00:00,  7.81it/s]Step 81900: loss = 2.0850\n",
            "Epoch 182: 100% 900/901 [01:46<00:00,  8.38it/s]Step 81900: loss = 2.0853\n",
            "Epoch 182: 100% 901/901 [01:46<00:00,  8.48it/s]\n",
            "Epoch 182 completed. Average training loss: 2.0853\n",
            "Validation loss after epoch 182: 2.2960\n",
            "Checkpoint saved -> checkpoints/model_epoch_182.pt\n",
            "Epoch 183:   0% 0/901 [00:00<?, ?it/s]Step 81900: loss = 2.3540\n",
            "Epoch 183:  11% 99/901 [00:11<01:34,  8.53it/s]Step 81950: loss = 2.1217\n",
            "Epoch 183:  11% 100/901 [00:11<01:33,  8.55it/s]Step 81950: loss = 2.1217\n",
            "Epoch 183:  22% 198/901 [00:23<01:26,  8.16it/s]Step 82000: loss = 2.1034\n",
            "Checkpoint saved -> checkpoints/model_step_82000.pt\n",
            "Epoch 183:  22% 200/901 [00:23<02:21,  4.94it/s]Step 82000: loss = 2.1020\n",
            "Checkpoint saved -> checkpoints/model_step_82000.pt\n",
            "Epoch 183:  33% 299/901 [00:35<01:03,  9.46it/s]Step 82050: loss = 2.0948\n",
            "Epoch 183:  33% 300/901 [00:36<01:04,  9.26it/s]Step 82050: loss = 2.0953\n",
            "Epoch 183:  44% 399/901 [00:47<00:58,  8.63it/s]Step 82100: loss = 2.0997\n",
            "Epoch 183:  44% 400/901 [00:47<00:59,  8.40it/s]Step 82100: loss = 2.0986\n",
            "Epoch 183:  55% 498/901 [00:59<00:51,  7.88it/s]Step 82150: loss = 2.0950\n",
            "Epoch 183:  55% 500/901 [00:59<00:45,  8.77it/s]Step 82150: loss = 2.0944\n",
            "Epoch 183:  66% 598/901 [01:10<00:33,  9.17it/s]Step 82200: loss = 2.1042\n",
            "Epoch 183:  67% 600/901 [01:10<00:32,  9.38it/s]Step 82200: loss = 2.1038\n",
            "Epoch 183:  78% 699/901 [01:22<00:24,  8.11it/s]Step 82250: loss = 2.0993\n",
            "Step 82250: loss = 2.0991\n",
            "Epoch 183:  89% 798/901 [01:33<00:10,  9.46it/s]Step 82300: loss = 2.1067\n",
            "Epoch 183:  89% 800/901 [01:33<00:11,  9.15it/s]Step 82300: loss = 2.1064\n",
            "Epoch 183: 100% 898/901 [01:45<00:00,  8.03it/s]Step 82350: loss = 2.1051\n",
            "Epoch 183: 100% 900/901 [01:45<00:00,  8.88it/s]Step 82350: loss = 2.1053\n",
            "Epoch 183: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 183 completed. Average training loss: 2.1053\n",
            "Validation loss after epoch 183: 2.2952\n",
            "Checkpoint saved -> checkpoints/model_epoch_183.pt\n",
            "Epoch 184:   0% 0/901 [00:00<?, ?it/s]Step 82350: loss = 1.1179\n",
            "Epoch 184:  11% 99/901 [00:11<01:30,  8.84it/s]Step 82400: loss = 2.0731\n",
            "Epoch 184:  11% 100/901 [00:11<01:28,  9.04it/s]Step 82400: loss = 2.0785\n",
            "Epoch 184:  22% 199/901 [00:22<01:40,  6.96it/s]Step 82450: loss = 2.0904\n",
            "Epoch 184:  22% 200/901 [00:23<01:39,  7.04it/s]Step 82450: loss = 2.0938\n",
            "Epoch 184:  33% 299/901 [00:34<01:02,  9.69it/s]Step 82500: loss = 2.0944\n",
            "Checkpoint saved -> checkpoints/model_step_82500.pt\n",
            "Epoch 184:  33% 300/901 [00:35<02:09,  4.63it/s]Step 82500: loss = 2.0952\n",
            "Checkpoint saved -> checkpoints/model_step_82500.pt\n",
            "Epoch 184:  44% 398/901 [00:47<00:55,  9.06it/s]Step 82550: loss = 2.0895\n",
            "Epoch 184:  44% 400/901 [00:47<00:53,  9.35it/s]Step 82550: loss = 2.0892\n",
            "Epoch 184:  55% 499/901 [00:58<00:44,  8.94it/s]Step 82600: loss = 2.0916\n",
            "Epoch 184:  55% 500/901 [00:59<00:44,  9.07it/s]Step 82600: loss = 2.0912\n",
            "Epoch 184:  66% 599/901 [01:10<00:36,  8.34it/s]Step 82650: loss = 2.0828\n",
            "Epoch 184:  67% 600/901 [01:10<00:34,  8.60it/s]Step 82650: loss = 2.0826\n",
            "Epoch 184:  77% 698/901 [01:22<00:27,  7.47it/s]Step 82700: loss = 2.0821\n",
            "Epoch 184:  78% 700/901 [01:22<00:26,  7.67it/s]Step 82700: loss = 2.0818\n",
            "Epoch 184:  89% 798/901 [01:34<00:10, 10.20it/s]Step 82750: loss = 2.0872\n",
            "Epoch 184:  89% 800/901 [01:34<00:11,  8.91it/s]Step 82750: loss = 2.0871\n",
            "Epoch 184: 100% 898/901 [01:45<00:00,  8.78it/s]Step 82800: loss = 2.0934\n",
            "Epoch 184: 100% 900/901 [01:45<00:00,  9.22it/s]Step 82800: loss = 2.0930\n",
            "Epoch 184: 100% 901/901 [01:45<00:00,  8.52it/s]\n",
            "Epoch 184 completed. Average training loss: 2.0930\n",
            "Validation loss after epoch 184: 2.2945\n",
            "Checkpoint saved -> checkpoints/model_epoch_184.pt\n",
            "Epoch 185:   0% 0/901 [00:00<?, ?it/s]Step 82800: loss = 1.9367\n",
            "Epoch 185:  11% 98/901 [00:11<01:31,  8.77it/s]Step 82850: loss = 2.1247\n",
            "Epoch 185:  11% 100/901 [00:11<01:42,  7.80it/s]Step 82850: loss = 2.1238\n",
            "Epoch 185:  22% 198/901 [00:22<01:20,  8.69it/s]Step 82900: loss = 2.1329\n",
            "Epoch 185:  22% 200/901 [00:22<01:21,  8.65it/s]Step 82900: loss = 2.1347\n",
            "Epoch 185:  33% 299/901 [00:34<01:15,  7.98it/s]Step 82950: loss = 2.1156\n",
            "Epoch 185:  33% 300/901 [00:34<01:15,  7.94it/s]Step 82950: loss = 2.1172\n",
            "Epoch 185:  44% 398/901 [00:46<00:59,  8.47it/s]Step 83000: loss = 2.1035\n",
            "Checkpoint saved -> checkpoints/model_step_83000.pt\n",
            "Epoch 185:  44% 400/901 [00:46<01:51,  4.48it/s]Step 83000: loss = 2.1034\n",
            "Checkpoint saved -> checkpoints/model_step_83000.pt\n",
            "Epoch 185:  55% 498/901 [00:58<00:47,  8.43it/s]Step 83050: loss = 2.1020\n",
            "Epoch 185:  55% 500/901 [00:59<00:45,  8.81it/s]Step 83050: loss = 2.1034\n",
            "Epoch 185:  66% 599/901 [01:10<00:36,  8.23it/s]Step 83100: loss = 2.1046\n",
            "Epoch 185:  67% 600/901 [01:10<00:36,  8.27it/s]Step 83100: loss = 2.1049\n",
            "Epoch 185:  78% 699/901 [01:22<00:22,  9.05it/s]Step 83150: loss = 2.0965\n",
            "Epoch 185:  78% 700/901 [01:22<00:22,  9.09it/s]Step 83150: loss = 2.0966\n",
            "Epoch 185:  89% 799/901 [01:33<00:11,  9.08it/s]Step 83200: loss = 2.0960\n",
            "Epoch 185:  89% 800/901 [01:34<00:11,  9.05it/s]Step 83200: loss = 2.0963\n",
            "Epoch 185: 100% 898/901 [01:45<00:00,  9.85it/s]Step 83250: loss = 2.0977\n",
            "Epoch 185: 100% 900/901 [01:45<00:00,  9.81it/s]Step 83250: loss = 2.0974\n",
            "Epoch 185: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 185 completed. Average training loss: 2.0974\n",
            "Validation loss after epoch 185: 2.2938\n",
            "Checkpoint saved -> checkpoints/model_epoch_185.pt\n",
            "Epoch 186:   0% 0/901 [00:00<?, ?it/s]Step 83250: loss = 2.1000\n",
            "Epoch 186:  11% 98/901 [00:11<01:33,  8.55it/s]Step 83300: loss = 2.0782\n",
            "Epoch 186:  11% 100/901 [00:11<01:23,  9.61it/s]Step 83300: loss = 2.0794\n",
            "Epoch 186:  22% 199/901 [00:23<01:22,  8.51it/s]Step 83350: loss = 2.0756\n",
            "Step 83350: loss = 2.0801\n",
            "Epoch 186:  33% 298/901 [00:35<01:19,  7.59it/s]Step 83400: loss = 2.0617\n",
            "Epoch 186:  33% 300/901 [00:35<01:09,  8.59it/s]Step 83400: loss = 2.0606\n",
            "Epoch 186:  44% 399/901 [00:47<00:51,  9.68it/s]Step 83450: loss = 2.0792\n",
            "Epoch 186:  44% 400/901 [00:47<00:55,  8.96it/s]Step 83450: loss = 2.0798\n",
            "Epoch 186:  55% 498/901 [00:58<00:49,  8.20it/s]Step 83500: loss = 2.0832\n",
            "Checkpoint saved -> checkpoints/model_step_83500.pt\n",
            "Epoch 186:  55% 500/901 [00:59<01:25,  4.68it/s]Step 83500: loss = 2.0828\n",
            "Checkpoint saved -> checkpoints/model_step_83500.pt\n",
            "Epoch 186:  66% 599/901 [01:11<00:34,  8.79it/s]Step 83550: loss = 2.0841\n",
            "Step 83550: loss = 2.0848\n",
            "Epoch 186:  77% 698/901 [01:22<00:22,  8.99it/s]Step 83600: loss = 2.0837\n",
            "Epoch 186:  78% 700/901 [01:22<00:21,  9.34it/s]Step 83600: loss = 2.0837\n",
            "Epoch 186:  89% 798/901 [01:34<00:12,  8.41it/s]Step 83650: loss = 2.0871\n",
            "Epoch 186:  89% 800/901 [01:34<00:12,  8.08it/s]Step 83650: loss = 2.0874\n",
            "Epoch 186: 100% 899/901 [01:45<00:00,  7.93it/s]Step 83700: loss = 2.0937\n",
            "Epoch 186: 100% 900/901 [01:45<00:00,  8.31it/s]Step 83700: loss = 2.0935\n",
            "Epoch 186: 100% 901/901 [01:46<00:00,  8.50it/s]\n",
            "Epoch 186 completed. Average training loss: 2.0935\n",
            "Validation loss after epoch 186: 2.2932\n",
            "Checkpoint saved -> checkpoints/model_epoch_186.pt\n",
            "Epoch 187:   0% 0/901 [00:00<?, ?it/s]Step 83700: loss = 2.2735\n",
            "Epoch 187:  11% 99/901 [00:11<01:46,  7.56it/s]Step 83750: loss = 2.0926\n",
            "Epoch 187:  11% 100/901 [00:11<01:45,  7.59it/s]Step 83750: loss = 2.0932\n",
            "Epoch 187:  22% 198/901 [00:23<01:20,  8.79it/s]Step 83800: loss = 2.0851\n",
            "Epoch 187:  22% 200/901 [00:23<01:21,  8.65it/s]Step 83800: loss = 2.0886\n",
            "Epoch 187:  33% 299/901 [00:34<01:16,  7.84it/s]Step 83850: loss = 2.0876\n",
            "Epoch 187:  33% 300/901 [00:35<01:12,  8.26it/s]Step 83850: loss = 2.0876\n",
            "Epoch 187:  44% 399/901 [00:45<00:55,  8.98it/s]Step 83900: loss = 2.0985\n",
            "Epoch 187:  44% 400/901 [00:46<00:57,  8.65it/s]Step 83900: loss = 2.0967\n",
            "Epoch 187:  55% 499/901 [00:58<00:45,  8.82it/s]Step 83950: loss = 2.0856\n",
            "Epoch 187:  55% 500/901 [00:58<00:47,  8.46it/s]Step 83950: loss = 2.0858\n",
            "Epoch 187:  66% 599/901 [01:09<00:31,  9.73it/s]Step 84000: loss = 2.1007\n",
            "Checkpoint saved -> checkpoints/model_step_84000.pt\n",
            "Epoch 187:  67% 600/901 [01:09<01:04,  4.67it/s]Step 84000: loss = 2.0999\n",
            "Checkpoint saved -> checkpoints/model_step_84000.pt\n",
            "Epoch 187:  78% 699/901 [01:21<00:25,  7.91it/s]Step 84050: loss = 2.0947\n",
            "Epoch 187:  78% 700/901 [01:22<00:24,  8.15it/s]Step 84050: loss = 2.0941\n",
            "Epoch 187:  89% 798/901 [01:33<00:11,  9.27it/s]Step 84100: loss = 2.0940\n",
            "Epoch 187:  89% 800/901 [01:33<00:10,  9.86it/s]Step 84100: loss = 2.0934\n",
            "Epoch 187: 100% 899/901 [01:45<00:00,  8.16it/s]Step 84150: loss = 2.0911\n",
            "Epoch 187: 100% 900/901 [01:45<00:00,  7.96it/s]Step 84150: loss = 2.0910\n",
            "Epoch 187: 100% 901/901 [01:45<00:00,  8.53it/s]\n",
            "Epoch 187 completed. Average training loss: 2.0910\n",
            "Validation loss after epoch 187: 2.2924\n",
            "Checkpoint saved -> checkpoints/model_epoch_187.pt\n",
            "Epoch 188:   0% 0/901 [00:00<?, ?it/s]Step 84150: loss = 1.6703\n",
            "Epoch 188:  11% 98/901 [00:11<01:46,  7.55it/s]Step 84200: loss = 2.0729\n",
            "Epoch 188:  11% 100/901 [00:11<01:36,  8.27it/s]Step 84200: loss = 2.0726\n",
            "Epoch 188:  22% 199/901 [00:23<02:16,  5.14it/s]Step 84250: loss = 2.0897\n",
            "Epoch 188:  22% 200/901 [00:23<02:04,  5.62it/s]Step 84250: loss = 2.0887\n",
            "Epoch 188:  33% 299/901 [00:34<01:05,  9.18it/s]Step 84300: loss = 2.0798\n",
            "Epoch 188:  33% 300/901 [00:34<01:08,  8.79it/s]Step 84300: loss = 2.0797\n",
            "Epoch 188:  44% 398/901 [00:45<00:53,  9.39it/s]Step 84350: loss = 2.0823\n",
            "Epoch 188:  44% 400/901 [00:46<01:06,  7.48it/s]Step 84350: loss = 2.0844\n",
            "Epoch 188:  55% 498/901 [00:58<00:49,  8.18it/s]Step 84400: loss = 2.0754\n",
            "Epoch 188:  55% 500/901 [00:58<00:43,  9.13it/s]Step 84400: loss = 2.0746\n",
            "Epoch 188:  66% 598/901 [01:09<00:33,  8.96it/s]Step 84450: loss = 2.0829\n",
            "Epoch 188:  67% 600/901 [01:09<00:34,  8.77it/s]Step 84450: loss = 2.0822\n",
            "Epoch 188:  77% 698/901 [01:21<00:22,  8.88it/s]Step 84500: loss = 2.0895\n",
            "Checkpoint saved -> checkpoints/model_step_84500.pt\n",
            "Epoch 188:  78% 700/901 [01:21<00:37,  5.41it/s]Step 84500: loss = 2.0896\n",
            "Checkpoint saved -> checkpoints/model_step_84500.pt\n",
            "Epoch 188:  89% 799/901 [01:33<00:13,  7.79it/s]Step 84550: loss = 2.0997\n",
            "Epoch 188:  89% 800/901 [01:33<00:12,  7.80it/s]Step 84550: loss = 2.1007\n",
            "Epoch 188: 100% 899/901 [01:45<00:00,  7.21it/s]Step 84600: loss = 2.0927\n",
            "Epoch 188: 100% 900/901 [01:45<00:00,  7.41it/s]Step 84600: loss = 2.0925\n",
            "Epoch 188: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 188 completed. Average training loss: 2.0925\n",
            "Validation loss after epoch 188: 2.2917\n",
            "Checkpoint saved -> checkpoints/model_epoch_188.pt\n",
            "Epoch 189:   0% 0/901 [00:00<?, ?it/s]Step 84600: loss = 1.9171\n",
            "Epoch 189:  11% 98/901 [00:11<01:25,  9.35it/s]Step 84650: loss = 2.1028\n",
            "Epoch 189:  11% 100/901 [00:11<01:27,  9.20it/s]Step 84650: loss = 2.1061\n",
            "Epoch 189:  22% 199/901 [00:22<01:17,  9.09it/s]Step 84700: loss = 2.1186\n",
            "Epoch 189:  22% 200/901 [00:23<01:16,  9.20it/s]Step 84700: loss = 2.1214\n",
            "Epoch 189:  33% 298/901 [00:34<01:05,  9.16it/s]Step 84750: loss = 2.0942\n",
            "Epoch 189:  33% 300/901 [00:34<01:02,  9.57it/s]Step 84750: loss = 2.0918\n",
            "Epoch 189:  44% 399/901 [00:46<00:57,  8.80it/s]Step 84800: loss = 2.1047\n",
            "Epoch 189:  44% 400/901 [00:46<00:55,  8.96it/s]Step 84800: loss = 2.1040\n",
            "Epoch 189:  55% 499/901 [00:57<00:42,  9.45it/s]Step 84850: loss = 2.1092\n",
            "Epoch 189:  55% 500/901 [00:57<00:44,  9.00it/s]Step 84850: loss = 2.1093\n",
            "Epoch 189:  66% 599/901 [01:08<00:37,  8.00it/s]Step 84900: loss = 2.1073\n",
            "Epoch 189:  67% 600/901 [01:08<00:36,  8.17it/s]Step 84900: loss = 2.1070\n",
            "Epoch 189:  78% 699/901 [01:20<00:27,  7.27it/s]Step 84950: loss = 2.1108\n",
            "Epoch 189:  78% 700/901 [01:20<00:27,  7.43it/s]Step 84950: loss = 2.1112\n",
            "Epoch 189:  89% 799/901 [01:32<00:14,  6.92it/s]Step 85000: loss = 2.0952\n",
            "Checkpoint saved -> checkpoints/model_step_85000.pt\n",
            "Epoch 189:  89% 800/901 [01:33<00:29,  3.41it/s]Step 85000: loss = 2.0953\n",
            "Checkpoint saved -> checkpoints/model_step_85000.pt\n",
            "Epoch 189: 100% 898/901 [01:45<00:00,  8.03it/s]Step 85050: loss = 2.0895\n",
            "Epoch 189: 100% 900/901 [01:45<00:00,  8.78it/s]Step 85050: loss = 2.0895\n",
            "Epoch 189: 100% 901/901 [01:45<00:00,  8.51it/s]\n",
            "Epoch 189 completed. Average training loss: 2.0895\n",
            "Validation loss after epoch 189: 2.2911\n",
            "Checkpoint saved -> checkpoints/model_epoch_189.pt\n",
            "Epoch 190:   0% 0/901 [00:00<?, ?it/s]Step 85050: loss = 2.9397\n",
            "Epoch 190:  11% 98/901 [00:10<01:29,  8.99it/s]Step 85100: loss = 2.1680\n",
            "Epoch 190:  11% 100/901 [00:11<01:39,  8.05it/s]Step 85100: loss = 2.1664\n",
            "Epoch 190:  22% 198/901 [00:22<01:32,  7.61it/s]Step 85150: loss = 2.1235\n",
            "Epoch 190:  22% 200/901 [00:22<01:21,  8.63it/s]Step 85150: loss = 2.1218\n",
            "Epoch 190:  33% 298/901 [00:33<01:12,  8.34it/s]Step 85200: loss = 2.1265\n",
            "Epoch 190:  33% 300/901 [00:33<01:08,  8.80it/s]Step 85200: loss = 2.1276\n",
            "Epoch 190:  44% 399/901 [00:45<01:01,  8.18it/s]Step 85250: loss = 2.1109\n",
            "Step 85250: loss = 2.1105\n",
            "Epoch 190:  55% 499/901 [00:57<00:44,  8.98it/s]Step 85300: loss = 2.1067\n",
            "Epoch 190:  55% 500/901 [00:57<00:46,  8.59it/s]Step 85300: loss = 2.1062\n",
            "Epoch 190:  66% 598/901 [01:08<00:38,  7.96it/s]Step 85350: loss = 2.1133\n",
            "Epoch 190:  67% 600/901 [01:08<00:33,  9.10it/s]Step 85350: loss = 2.1133\n",
            "Epoch 190:  77% 698/901 [01:20<00:22,  9.14it/s]Step 85400: loss = 2.1162\n",
            "Epoch 190:  78% 700/901 [01:20<00:21,  9.52it/s]Step 85400: loss = 2.1155\n",
            "Epoch 190:  89% 798/901 [01:32<00:12,  8.39it/s]Step 85450: loss = 2.1078\n",
            "Epoch 190:  89% 800/901 [01:32<00:11,  8.44it/s]Step 85450: loss = 2.1083\n",
            "Epoch 190: 100% 899/901 [01:43<00:00,  7.80it/s]Step 85500: loss = 2.1041\n",
            "Checkpoint saved -> checkpoints/model_step_85500.pt\n",
            "Epoch 190: 100% 900/901 [01:44<00:00,  3.70it/s]Step 85500: loss = 2.1036\n",
            "Checkpoint saved -> checkpoints/model_step_85500.pt\n",
            "Epoch 190: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 190 completed. Average training loss: 2.1036\n",
            "Validation loss after epoch 190: 2.2904\n",
            "Checkpoint saved -> checkpoints/model_epoch_190.pt\n",
            "Epoch 191:   0% 0/901 [00:00<?, ?it/s]Step 85500: loss = 2.1068\n",
            "Checkpoint saved -> checkpoints/model_step_85500.pt\n",
            "Epoch 191:  11% 98/901 [00:12<01:36,  8.31it/s]Step 85550: loss = 2.0735\n",
            "Epoch 191:  11% 100/901 [00:12<01:35,  8.42it/s]Step 85550: loss = 2.0738\n",
            "Epoch 191:  22% 199/901 [00:23<01:15,  9.27it/s]Step 85600: loss = 2.0766\n",
            "Epoch 191:  22% 200/901 [00:23<01:19,  8.81it/s]Step 85600: loss = 2.0708\n",
            "Epoch 191:  33% 299/901 [00:35<01:00,  9.88it/s]Step 85650: loss = 2.0788\n",
            "Epoch 191:  33% 300/901 [00:35<01:01,  9.76it/s]Step 85650: loss = 2.0767\n",
            "Epoch 191:  44% 399/901 [00:47<01:09,  7.26it/s]Step 85700: loss = 2.0539\n",
            "Epoch 191:  44% 400/901 [00:47<01:07,  7.39it/s]Step 85700: loss = 2.0527\n",
            "Epoch 191:  55% 498/901 [00:58<00:42,  9.58it/s]Step 85750: loss = 2.0669\n",
            "Epoch 191:  55% 500/901 [00:59<00:40,  9.86it/s]Step 85750: loss = 2.0678\n",
            "Epoch 191:  66% 599/901 [01:10<00:44,  6.75it/s]Step 85800: loss = 2.0804\n",
            "Step 85800: loss = 2.0814\n",
            "Epoch 191:  77% 698/901 [01:22<00:22,  9.15it/s]Step 85850: loss = 2.0820\n",
            "Epoch 191:  78% 700/901 [01:22<00:22,  9.08it/s]Step 85850: loss = 2.0820\n",
            "Epoch 191:  89% 799/901 [01:33<00:15,  6.76it/s]Step 85900: loss = 2.0837\n",
            "Epoch 191:  89% 800/901 [01:33<00:17,  5.67it/s]Step 85900: loss = 2.0842\n",
            "Epoch 191: 100% 899/901 [01:45<00:00,  8.46it/s]Step 85950: loss = 2.0916\n",
            "Epoch 191: 100% 900/901 [01:45<00:00,  8.64it/s]Step 85950: loss = 2.0915\n",
            "Epoch 191: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 191 completed. Average training loss: 2.0915\n",
            "Validation loss after epoch 191: 2.2897\n",
            "Checkpoint saved -> checkpoints/model_epoch_191.pt\n",
            "Epoch 192:   0% 0/901 [00:00<?, ?it/s]Step 85950: loss = 2.3811\n",
            "Epoch 192:  11% 98/901 [00:11<01:28,  9.02it/s]Step 86000: loss = 2.1364\n",
            "Checkpoint saved -> checkpoints/model_step_86000.pt\n",
            "Epoch 192:  11% 100/901 [00:11<02:29,  5.35it/s]Step 86000: loss = 2.1387\n",
            "Checkpoint saved -> checkpoints/model_step_86000.pt\n",
            "Epoch 192:  22% 198/901 [00:23<01:22,  8.57it/s]Step 86050: loss = 2.1375\n",
            "Epoch 192:  22% 200/901 [00:23<01:14,  9.36it/s]Step 86050: loss = 2.1373\n",
            "Epoch 192:  33% 298/901 [00:35<01:04,  9.39it/s]Step 86100: loss = 2.1175\n",
            "Epoch 192:  33% 300/901 [00:35<01:06,  9.10it/s]Step 86100: loss = 2.1176\n",
            "Epoch 192:  44% 399/901 [00:46<00:55,  8.98it/s]Step 86150: loss = 2.1190\n",
            "Epoch 192:  44% 400/901 [00:46<00:55,  8.99it/s]Step 86150: loss = 2.1189\n",
            "Epoch 192:  55% 498/901 [00:58<00:51,  7.82it/s]Step 86200: loss = 2.1128\n",
            "Epoch 192:  55% 500/901 [00:58<00:47,  8.37it/s]Step 86200: loss = 2.1134\n",
            "Epoch 192:  66% 598/901 [01:09<00:32,  9.25it/s]Step 86250: loss = 2.1089\n",
            "Epoch 192:  67% 600/901 [01:10<00:39,  7.68it/s]Step 86250: loss = 2.1072\n",
            "Epoch 192:  77% 698/901 [01:22<00:26,  7.77it/s]Step 86300: loss = 2.0977\n",
            "Epoch 192:  78% 700/901 [01:22<00:23,  8.47it/s]Step 86300: loss = 2.0981\n",
            "Epoch 192:  89% 798/901 [01:33<00:11,  8.66it/s]Step 86350: loss = 2.0971\n",
            "Epoch 192:  89% 800/901 [01:33<00:11,  9.04it/s]Step 86350: loss = 2.0967\n",
            "Epoch 192: 100% 899/901 [01:45<00:00, 10.20it/s]Step 86400: loss = 2.0984\n",
            "Step 86400: loss = 2.0979\n",
            "Epoch 192: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 192 completed. Average training loss: 2.0979\n",
            "Validation loss after epoch 192: 2.2890\n",
            "Checkpoint saved -> checkpoints/model_epoch_192.pt\n",
            "Epoch 193:   0% 0/901 [00:00<?, ?it/s]Step 86400: loss = 2.6022\n",
            "Epoch 193:  11% 99/901 [00:11<01:42,  7.83it/s]Step 86450: loss = 2.0449\n",
            "Step 86450: loss = 2.0370\n",
            "Epoch 193:  22% 198/901 [00:22<01:22,  8.53it/s]Step 86500: loss = 2.1165\n",
            "Checkpoint saved -> checkpoints/model_step_86500.pt\n",
            "Epoch 193:  22% 200/901 [00:23<02:28,  4.71it/s]Step 86500: loss = 2.1142\n",
            "Checkpoint saved -> checkpoints/model_step_86500.pt\n",
            "Epoch 193:  33% 298/901 [00:35<01:10,  8.54it/s]Step 86550: loss = 2.0970\n",
            "Epoch 193:  33% 300/901 [00:35<01:09,  8.69it/s]Step 86550: loss = 2.0965\n",
            "Epoch 193:  44% 398/901 [00:46<00:51,  9.77it/s]Step 86600: loss = 2.1133\n",
            "Epoch 193:  44% 400/901 [00:46<00:54,  9.24it/s]Step 86600: loss = 2.1131\n",
            "Epoch 193:  55% 498/901 [00:58<00:45,  8.95it/s]Step 86650: loss = 2.1088\n",
            "Epoch 193:  55% 500/901 [00:58<00:41,  9.58it/s]Step 86650: loss = 2.1081\n",
            "Epoch 193:  66% 599/901 [01:10<00:37,  8.01it/s]Step 86700: loss = 2.0932\n",
            "Epoch 193:  67% 600/901 [01:10<00:38,  7.92it/s]Step 86700: loss = 2.0940\n",
            "Epoch 193:  77% 698/901 [01:21<00:23,  8.82it/s]Step 86750: loss = 2.1005\n",
            "Epoch 193:  78% 700/901 [01:21<00:22,  8.81it/s]Step 86750: loss = 2.0988\n",
            "Epoch 193:  89% 798/901 [01:32<00:10,  9.72it/s]Step 86800: loss = 2.1037\n",
            "Epoch 193:  89% 800/901 [01:33<00:10,  9.84it/s]Step 86800: loss = 2.1029\n",
            "Epoch 193: 100% 898/901 [01:45<00:00,  7.46it/s]Step 86850: loss = 2.1027\n",
            "Epoch 193: 100% 900/901 [01:45<00:00,  7.82it/s]Step 86850: loss = 2.1025\n",
            "Epoch 193: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 193 completed. Average training loss: 2.1025\n",
            "Validation loss after epoch 193: 2.2883\n",
            "Checkpoint saved -> checkpoints/model_epoch_193.pt\n",
            "Epoch 194:   0% 0/901 [00:00<?, ?it/s]Step 86850: loss = 2.3454\n",
            "Epoch 194:  11% 99/901 [00:11<02:04,  6.45it/s]Step 86900: loss = 2.0982\n",
            "Epoch 194:  11% 100/901 [00:11<01:55,  6.94it/s]Step 86900: loss = 2.0989\n",
            "Epoch 194:  22% 199/901 [00:23<01:13,  9.51it/s]Step 86950: loss = 2.0979\n",
            "Epoch 194:  22% 200/901 [00:23<01:16,  9.12it/s]Step 86950: loss = 2.0970\n",
            "Epoch 194:  33% 298/901 [00:35<01:14,  8.13it/s]Step 87000: loss = 2.0871\n",
            "Checkpoint saved -> checkpoints/model_step_87000.pt\n",
            "Epoch 194:  33% 300/901 [00:36<02:06,  4.74it/s]Step 87000: loss = 2.0873\n",
            "Checkpoint saved -> checkpoints/model_step_87000.pt\n",
            "Epoch 194:  44% 398/901 [00:47<00:54,  9.28it/s]Step 87050: loss = 2.0867\n",
            "Epoch 194:  44% 400/901 [00:48<00:53,  9.32it/s]Step 87050: loss = 2.0867\n",
            "Epoch 194:  55% 498/901 [00:59<00:40, 10.05it/s]Step 87100: loss = 2.0888\n",
            "Epoch 194:  55% 500/901 [00:59<00:40,  9.89it/s]Step 87100: loss = 2.0890\n",
            "Epoch 194:  66% 599/901 [01:10<00:34,  8.73it/s]Step 87150: loss = 2.0971\n",
            "Epoch 194:  67% 600/901 [01:10<00:34,  8.64it/s]Step 87150: loss = 2.0972\n",
            "Epoch 194:  78% 699/901 [01:22<00:24,  8.30it/s]Step 87200: loss = 2.0960\n",
            "Step 87200: loss = 2.0960\n",
            "Epoch 194:  89% 799/901 [01:33<00:10,  9.38it/s]Step 87250: loss = 2.0982\n",
            "Epoch 194:  89% 800/901 [01:33<00:11,  8.95it/s]Step 87250: loss = 2.0978\n",
            "Epoch 194: 100% 898/901 [01:45<00:00,  8.53it/s]Step 87300: loss = 2.0973\n",
            "Epoch 194: 100% 900/901 [01:45<00:00,  8.58it/s]Step 87300: loss = 2.0976\n",
            "Epoch 194: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 194 completed. Average training loss: 2.0976\n",
            "Validation loss after epoch 194: 2.2877\n",
            "Checkpoint saved -> checkpoints/model_epoch_194.pt\n",
            "Epoch 195:   0% 0/901 [00:00<?, ?it/s]Step 87300: loss = 1.3036\n",
            "Epoch 195:  11% 98/901 [00:11<01:32,  8.71it/s]Step 87350: loss = 2.0943\n",
            "Epoch 195:  11% 100/901 [00:11<01:29,  8.93it/s]Step 87350: loss = 2.1053\n",
            "Epoch 195:  22% 199/901 [00:23<01:25,  8.17it/s]Step 87400: loss = 2.1126\n",
            "Epoch 195:  22% 200/901 [00:23<01:26,  8.08it/s]Step 87400: loss = 2.1125\n",
            "Epoch 195:  33% 299/901 [00:35<01:09,  8.62it/s]Step 87450: loss = 2.0863\n",
            "Epoch 195:  33% 300/901 [00:35<01:12,  8.34it/s]Step 87450: loss = 2.0846\n",
            "Epoch 195:  44% 399/901 [00:46<01:00,  8.27it/s]Step 87500: loss = 2.0757\n",
            "Checkpoint saved -> checkpoints/model_step_87500.pt\n",
            "Epoch 195:  44% 400/901 [00:47<02:22,  3.51it/s]Step 87500: loss = 2.0767\n",
            "Checkpoint saved -> checkpoints/model_step_87500.pt\n",
            "Epoch 195:  55% 498/901 [00:59<00:45,  8.81it/s]Step 87550: loss = 2.0758\n",
            "Epoch 195:  55% 500/901 [00:59<00:43,  9.21it/s]Step 87550: loss = 2.0767\n",
            "Epoch 195:  66% 598/901 [01:10<00:32,  9.30it/s]Step 87600: loss = 2.0869\n",
            "Epoch 195:  67% 600/901 [01:10<00:33,  9.01it/s]Step 87600: loss = 2.0858\n",
            "Epoch 195:  78% 699/901 [01:21<00:21,  9.40it/s]Step 87650: loss = 2.0910\n",
            "Epoch 195:  78% 700/901 [01:22<00:24,  8.08it/s]Step 87650: loss = 2.0912\n",
            "Epoch 195:  89% 799/901 [01:33<00:11,  8.54it/s]Step 87700: loss = 2.1000\n",
            "Epoch 195:  89% 800/901 [01:33<00:12,  7.78it/s]Step 87700: loss = 2.0997\n",
            "Epoch 195: 100% 898/901 [01:44<00:00,  8.40it/s]Step 87750: loss = 2.0958\n",
            "Epoch 195: 100% 900/901 [01:45<00:00,  8.29it/s]Step 87750: loss = 2.0960\n",
            "Epoch 195: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 195 completed. Average training loss: 2.0960\n",
            "Validation loss after epoch 195: 2.2870\n",
            "Checkpoint saved -> checkpoints/model_epoch_195.pt\n",
            "Epoch 196:   0% 0/901 [00:00<?, ?it/s]Step 87750: loss = 2.4173\n",
            "Epoch 196:  11% 99/901 [00:11<01:36,  8.31it/s]Step 87800: loss = 2.1338\n",
            "Epoch 196:  11% 100/901 [00:11<01:34,  8.50it/s]Step 87800: loss = 2.1327\n",
            "Epoch 196:  22% 199/901 [00:22<01:13,  9.59it/s]Step 87850: loss = 2.1207\n",
            "Epoch 196:  22% 200/901 [00:23<01:13,  9.49it/s]Step 87850: loss = 2.1215\n",
            "Epoch 196:  33% 299/901 [00:33<00:57, 10.44it/s]Step 87900: loss = 2.1258\n",
            "Step 87900: loss = 2.1271\n",
            "Epoch 196:  44% 398/901 [00:46<01:10,  7.16it/s]Step 87950: loss = 2.1080\n",
            "Epoch 196:  44% 400/901 [00:46<01:02,  8.00it/s]Step 87950: loss = 2.1095\n",
            "Epoch 196:  55% 498/901 [00:58<00:49,  8.22it/s]Step 88000: loss = 2.1021\n",
            "Checkpoint saved -> checkpoints/model_step_88000.pt\n",
            "Epoch 196:  55% 500/901 [00:58<01:24,  4.72it/s]Step 88000: loss = 2.1032\n",
            "Checkpoint saved -> checkpoints/model_step_88000.pt\n",
            "Epoch 196:  66% 598/901 [01:10<00:35,  8.43it/s]Step 88050: loss = 2.1046\n",
            "Epoch 196:  67% 600/901 [01:10<00:32,  9.20it/s]Step 88050: loss = 2.1050\n",
            "Epoch 196:  77% 698/901 [01:21<00:23,  8.64it/s]Step 88100: loss = 2.0997\n",
            "Epoch 196:  78% 700/901 [01:21<00:22,  9.05it/s]Step 88100: loss = 2.0998\n",
            "Epoch 196:  89% 798/901 [01:33<00:13,  7.86it/s]Step 88150: loss = 2.0939\n",
            "Epoch 196:  89% 800/901 [01:33<00:11,  8.88it/s]Step 88150: loss = 2.0943\n",
            "Epoch 196: 100% 898/901 [01:44<00:00,  9.17it/s]Step 88200: loss = 2.0968\n",
            "Epoch 196: 100% 900/901 [01:45<00:00,  9.69it/s]Step 88200: loss = 2.0973\n",
            "Epoch 196: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 196 completed. Average training loss: 2.0973\n",
            "Validation loss after epoch 196: 2.2864\n",
            "Checkpoint saved -> checkpoints/model_epoch_196.pt\n",
            "Epoch 197:   0% 0/901 [00:00<?, ?it/s]Step 88200: loss = 1.8712\n",
            "Epoch 197:  11% 99/901 [00:11<01:49,  7.33it/s]Step 88250: loss = 2.0921\n",
            "Epoch 197:  11% 100/901 [00:11<01:45,  7.60it/s]Step 88250: loss = 2.0980\n",
            "Epoch 197:  22% 199/901 [00:23<01:27,  8.01it/s]Step 88300: loss = 2.1016\n",
            "Epoch 197:  22% 200/901 [00:23<01:31,  7.70it/s]Step 88300: loss = 2.0988\n",
            "Epoch 197:  33% 298/901 [00:35<01:09,  8.72it/s]Step 88350: loss = 2.0893\n",
            "Epoch 197:  33% 300/901 [00:35<01:04,  9.32it/s]Step 88350: loss = 2.0893\n",
            "Epoch 197:  44% 399/901 [00:46<01:01,  8.16it/s]Step 88400: loss = 2.0858\n",
            "Epoch 197:  44% 400/901 [00:46<01:07,  7.47it/s]Step 88400: loss = 2.0872\n",
            "Epoch 197:  55% 499/901 [00:57<00:39, 10.06it/s]Step 88450: loss = 2.0942\n",
            "Epoch 197:  55% 500/901 [00:57<00:41,  9.62it/s]Step 88450: loss = 2.0931\n",
            "Epoch 197:  66% 598/901 [01:09<00:39,  7.66it/s]Step 88500: loss = 2.0954\n",
            "Checkpoint saved -> checkpoints/model_step_88500.pt\n",
            "Epoch 197:  67% 600/901 [01:09<01:08,  4.40it/s]Step 88500: loss = 2.0960\n",
            "Checkpoint saved -> checkpoints/model_step_88500.pt\n",
            "Epoch 197:  78% 699/901 [01:22<00:23,  8.46it/s]Step 88550: loss = 2.0941\n",
            "Epoch 197:  78% 700/901 [01:22<00:24,  8.30it/s]Step 88550: loss = 2.0944\n",
            "Epoch 197:  89% 799/901 [01:33<00:12,  8.14it/s]Step 88600: loss = 2.0905\n",
            "Epoch 197:  89% 800/901 [01:33<00:12,  7.78it/s]Step 88600: loss = 2.0904\n",
            "Epoch 197: 100% 899/901 [01:45<00:00,  9.34it/s]Step 88650: loss = 2.0936\n",
            "Epoch 197: 100% 900/901 [01:45<00:00,  8.87it/s]Step 88650: loss = 2.0937\n",
            "Epoch 197: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 197 completed. Average training loss: 2.0937\n",
            "Validation loss after epoch 197: 2.2857\n",
            "Checkpoint saved -> checkpoints/model_epoch_197.pt\n",
            "Epoch 198:   0% 0/901 [00:00<?, ?it/s]Step 88650: loss = 1.9583\n",
            "Epoch 198:  11% 98/901 [00:11<01:37,  8.22it/s]Step 88700: loss = 2.0877\n",
            "Epoch 198:  11% 100/901 [00:11<01:33,  8.61it/s]Step 88700: loss = 2.0941\n",
            "Epoch 198:  22% 199/901 [00:22<01:20,  8.69it/s]Step 88750: loss = 2.1201\n",
            "Epoch 198:  22% 200/901 [00:22<01:18,  8.95it/s]Step 88750: loss = 2.1201\n",
            "Epoch 198:  33% 298/901 [00:34<01:11,  8.47it/s]Step 88800: loss = 2.1019\n",
            "Epoch 198:  33% 300/901 [00:34<01:12,  8.29it/s]Step 88800: loss = 2.1030\n",
            "Epoch 198:  44% 398/901 [00:45<00:56,  8.88it/s]Step 88850: loss = 2.1083\n",
            "Epoch 198:  44% 400/901 [00:45<00:51,  9.81it/s]Step 88850: loss = 2.1076\n",
            "Epoch 198:  55% 498/901 [00:57<00:38, 10.46it/s]Step 88900: loss = 2.0929\n",
            "Epoch 198:  55% 500/901 [00:57<00:41,  9.62it/s]Step 88900: loss = 2.0930\n",
            "Epoch 198:  66% 599/901 [01:09<00:34,  8.69it/s]Step 88950: loss = 2.1005\n",
            "Epoch 198:  67% 600/901 [01:09<00:38,  7.82it/s]Step 88950: loss = 2.1012\n",
            "Epoch 198:  78% 699/901 [01:20<00:29,  6.75it/s]Step 89000: loss = 2.1001\n",
            "Checkpoint saved -> checkpoints/model_step_89000.pt\n",
            "Epoch 198:  78% 700/901 [01:21<01:00,  3.34it/s]Step 89000: loss = 2.1003\n",
            "Checkpoint saved -> checkpoints/model_step_89000.pt\n",
            "Epoch 198:  89% 799/901 [01:33<00:12,  8.20it/s]Step 89050: loss = 2.0934\n",
            "Epoch 198:  89% 800/901 [01:33<00:12,  8.16it/s]Step 89050: loss = 2.0943\n",
            "Epoch 198: 100% 898/901 [01:44<00:00,  9.46it/s]Step 89100: loss = 2.0931\n",
            "Epoch 198: 100% 900/901 [01:45<00:00,  9.74it/s]Step 89100: loss = 2.0936\n",
            "Epoch 198: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 198 completed. Average training loss: 2.0936\n",
            "Validation loss after epoch 198: 2.2851\n",
            "Checkpoint saved -> checkpoints/model_epoch_198.pt\n",
            "Epoch 199:   0% 0/901 [00:00<?, ?it/s]Step 89100: loss = 1.3067\n",
            "Epoch 199:  11% 99/901 [00:11<01:39,  8.03it/s]Step 89150: loss = 2.0736\n",
            "Epoch 199:  11% 100/901 [00:11<01:41,  7.91it/s]Step 89150: loss = 2.0767\n",
            "Epoch 199:  22% 198/901 [00:23<01:28,  7.97it/s]Step 89200: loss = 2.0524\n",
            "Epoch 199:  22% 200/901 [00:24<01:21,  8.59it/s]Step 89200: loss = 2.0517\n",
            "Epoch 199:  33% 299/901 [00:35<01:15,  7.94it/s]Step 89250: loss = 2.0659\n",
            "Epoch 199:  33% 300/901 [00:35<01:18,  7.69it/s]Step 89250: loss = 2.0669\n",
            "Epoch 199:  44% 399/901 [00:46<00:59,  8.43it/s]Step 89300: loss = 2.0706\n",
            "Step 89300: loss = 2.0704\n",
            "Epoch 199:  55% 498/901 [00:57<00:43,  9.17it/s]Step 89350: loss = 2.0846\n",
            "Epoch 199:  55% 500/901 [00:58<00:40,  9.85it/s]Step 89350: loss = 2.0850\n",
            "Epoch 199:  66% 599/901 [01:09<00:32,  9.16it/s]Step 89400: loss = 2.0889\n",
            "Epoch 199:  67% 600/901 [01:09<00:35,  8.38it/s]Step 89400: loss = 2.0894\n",
            "Epoch 199:  78% 699/901 [01:21<00:23,  8.56it/s]Step 89450: loss = 2.0930\n",
            "Epoch 199:  78% 700/901 [01:21<00:24,  8.20it/s]Step 89450: loss = 2.0925\n",
            "Epoch 199:  89% 798/901 [01:32<00:11,  9.29it/s]Step 89500: loss = 2.0965\n",
            "Checkpoint saved -> checkpoints/model_step_89500.pt\n",
            "Epoch 199:  89% 800/901 [01:32<00:18,  5.53it/s]Step 89500: loss = 2.0956\n",
            "Checkpoint saved -> checkpoints/model_step_89500.pt\n",
            "Epoch 199: 100% 898/901 [01:44<00:00,  8.72it/s]Step 89550: loss = 2.0992\n",
            "Epoch 199: 100% 900/901 [01:44<00:00,  8.95it/s]Step 89550: loss = 2.0997\n",
            "Epoch 199: 100% 901/901 [01:44<00:00,  8.59it/s]\n",
            "Epoch 199 completed. Average training loss: 2.0997\n",
            "Validation loss after epoch 199: 2.2844\n",
            "Checkpoint saved -> checkpoints/model_epoch_199.pt\n",
            "Epoch 200:   0% 0/901 [00:00<?, ?it/s]Step 89550: loss = 2.2611\n",
            "Epoch 200:  11% 98/901 [00:11<01:21,  9.91it/s]Step 89600: loss = 2.1264\n",
            "Epoch 200:  11% 100/901 [00:11<01:21,  9.82it/s]Step 89600: loss = 2.1277\n",
            "Epoch 200:  22% 199/901 [00:22<01:29,  7.87it/s]Step 89650: loss = 2.0978\n",
            "Epoch 200:  22% 200/901 [00:22<01:28,  7.95it/s]Step 89650: loss = 2.0989\n",
            "Epoch 200:  33% 299/901 [00:33<01:14,  8.03it/s]Step 89700: loss = 2.1059\n",
            "Epoch 200:  33% 300/901 [00:34<01:15,  7.98it/s]Step 89700: loss = 2.1067\n",
            "Epoch 200:  44% 398/901 [00:46<01:02,  8.09it/s]Step 89750: loss = 2.0896\n",
            "Epoch 200:  44% 400/901 [00:46<00:55,  9.07it/s]Step 89750: loss = 2.0893\n",
            "Epoch 200:  55% 499/901 [00:58<00:45,  8.84it/s]Step 89800: loss = 2.0779\n",
            "Step 89800: loss = 2.0789\n",
            "Epoch 200:  66% 599/901 [01:09<00:32,  9.27it/s]Step 89850: loss = 2.0885\n",
            "Epoch 200:  67% 600/901 [01:09<00:34,  8.67it/s]Step 89850: loss = 2.0893\n",
            "Epoch 200:  78% 699/901 [01:20<00:21,  9.29it/s]Step 89900: loss = 2.0958\n",
            "Epoch 200:  78% 700/901 [01:20<00:25,  8.02it/s]Step 89900: loss = 2.0952\n",
            "Epoch 200:  89% 798/901 [01:31<00:10,  9.44it/s]Step 89950: loss = 2.0908\n",
            "Epoch 200:  89% 800/901 [01:31<00:10,  9.49it/s]Step 89950: loss = 2.0912\n",
            "Epoch 200: 100% 898/901 [01:43<00:00,  9.14it/s]Step 90000: loss = 2.0933\n",
            "Checkpoint saved -> checkpoints/model_step_90000.pt\n",
            "Epoch 200: 100% 900/901 [01:44<00:00,  4.80it/s]Step 90000: loss = 2.0935\n",
            "Checkpoint saved -> checkpoints/model_step_90000.pt\n",
            "Epoch 200: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 200 completed. Average training loss: 2.0935\n",
            "Validation loss after epoch 200: 2.2837\n",
            "Checkpoint saved -> checkpoints/model_epoch_200.pt\n",
            "Epoch 201:   0% 0/901 [00:00<?, ?it/s]Step 90000: loss = 2.5060\n",
            "Checkpoint saved -> checkpoints/model_step_90000.pt\n",
            "Epoch 201:  11% 99/901 [00:11<01:25,  9.37it/s]Step 90050: loss = 2.1106\n",
            "Epoch 201:  11% 100/901 [00:12<01:27,  9.13it/s]Step 90050: loss = 2.1115\n",
            "Epoch 201:  22% 199/901 [00:23<01:18,  8.94it/s]Step 90100: loss = 2.0845\n",
            "Epoch 201:  22% 200/901 [00:23<01:18,  8.90it/s]Step 90100: loss = 2.0871\n",
            "Epoch 201:  33% 298/901 [00:34<00:59, 10.18it/s]Step 90150: loss = 2.1043\n",
            "Epoch 201:  33% 300/901 [00:34<01:02,  9.63it/s]Step 90150: loss = 2.1030\n",
            "Epoch 201:  44% 399/901 [00:46<00:55,  9.05it/s]Step 90200: loss = 2.1020\n",
            "Epoch 201:  44% 400/901 [00:46<00:57,  8.68it/s]Step 90200: loss = 2.1002\n",
            "Epoch 201:  55% 499/901 [00:58<00:41,  9.59it/s]Step 90250: loss = 2.0993\n",
            "Epoch 201:  55% 500/901 [00:58<00:41,  9.60it/s]Step 90250: loss = 2.0998\n",
            "Epoch 201:  66% 598/901 [01:09<00:30,  9.83it/s]Step 90300: loss = 2.0914\n",
            "Epoch 201:  67% 600/901 [01:10<00:30,  9.97it/s]Step 90300: loss = 2.0911\n",
            "Epoch 201:  78% 699/901 [01:21<00:23,  8.55it/s]Step 90350: loss = 2.0913\n",
            "Epoch 201:  78% 700/901 [01:21<00:26,  7.51it/s]Step 90350: loss = 2.0902\n",
            "Epoch 201:  89% 799/901 [01:32<00:10,  9.81it/s]Step 90400: loss = 2.0942\n",
            "Epoch 201:  89% 800/901 [01:32<00:11,  8.76it/s]Step 90400: loss = 2.0942\n",
            "Epoch 201: 100% 899/901 [01:44<00:00,  9.09it/s]Step 90450: loss = 2.1017\n",
            "Epoch 201: 100% 900/901 [01:44<00:00,  8.77it/s]Step 90450: loss = 2.1007\n",
            "Epoch 201: 100% 901/901 [01:44<00:00,  8.64it/s]\n",
            "Epoch 201 completed. Average training loss: 2.1007\n",
            "Validation loss after epoch 201: 2.2830\n",
            "Checkpoint saved -> checkpoints/model_epoch_201.pt\n",
            "Epoch 202:   0% 0/901 [00:00<?, ?it/s]Step 90450: loss = 2.4844\n",
            "Epoch 202:  11% 98/901 [00:11<01:33,  8.62it/s]Step 90500: loss = 2.0745\n",
            "Checkpoint saved -> checkpoints/model_step_90500.pt\n",
            "Epoch 202:  11% 100/901 [00:12<03:02,  4.40it/s]Step 90500: loss = 2.0725\n",
            "Checkpoint saved -> checkpoints/model_step_90500.pt\n",
            "Epoch 202:  22% 198/901 [00:23<01:15,  9.27it/s]Step 90550: loss = 2.0758\n",
            "Epoch 202:  22% 200/901 [00:23<01:13,  9.47it/s]Step 90550: loss = 2.0762\n",
            "Epoch 202:  33% 299/901 [00:35<01:22,  7.27it/s]Step 90600: loss = 2.0712\n",
            "Epoch 202:  33% 300/901 [00:35<01:26,  6.96it/s]Step 90600: loss = 2.0722\n",
            "Epoch 202:  44% 398/901 [00:47<00:54,  9.26it/s]Step 90650: loss = 2.0690\n",
            "Epoch 202:  44% 400/901 [00:47<00:52,  9.57it/s]Step 90650: loss = 2.0697\n",
            "Epoch 202:  55% 498/901 [00:58<00:47,  8.44it/s]Step 90700: loss = 2.0873\n",
            "Epoch 202:  55% 500/901 [00:58<00:49,  8.16it/s]Step 90700: loss = 2.0860\n",
            "Epoch 202:  66% 599/901 [01:10<00:35,  8.46it/s]Step 90750: loss = 2.0842\n",
            "Epoch 202:  67% 600/901 [01:10<00:35,  8.45it/s]Step 90750: loss = 2.0848\n",
            "Epoch 202:  77% 698/901 [01:21<00:22,  8.83it/s]Step 90800: loss = 2.0860\n",
            "Epoch 202:  78% 700/901 [01:21<00:21,  9.27it/s]Step 90800: loss = 2.0855\n",
            "Epoch 202:  89% 799/901 [01:32<00:12,  8.29it/s]Step 90850: loss = 2.0929\n",
            "Epoch 202:  89% 800/901 [01:33<00:13,  7.57it/s]Step 90850: loss = 2.0936\n",
            "Epoch 202: 100% 898/901 [01:45<00:00,  7.77it/s]Step 90900: loss = 2.0871\n",
            "Epoch 202: 100% 900/901 [01:45<00:00,  8.05it/s]Step 90900: loss = 2.0872\n",
            "Epoch 202: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 202 completed. Average training loss: 2.0872\n",
            "Validation loss after epoch 202: 2.2824\n",
            "Checkpoint saved -> checkpoints/model_epoch_202.pt\n",
            "Epoch 203:   0% 0/901 [00:00<?, ?it/s]Step 90900: loss = 1.7998\n",
            "Epoch 203:  11% 99/901 [00:11<01:40,  8.00it/s]Step 90950: loss = 2.1210\n",
            "Epoch 203:  11% 100/901 [00:11<01:42,  7.82it/s]Step 90950: loss = 2.1268\n",
            "Epoch 203:  22% 198/901 [00:23<01:27,  8.07it/s]Step 91000: loss = 2.1090\n",
            "Checkpoint saved -> checkpoints/model_step_91000.pt\n",
            "Epoch 203:  22% 200/901 [00:23<02:34,  4.55it/s]Step 91000: loss = 2.1074\n",
            "Checkpoint saved -> checkpoints/model_step_91000.pt\n",
            "Epoch 203:  33% 298/901 [00:35<01:13,  8.16it/s]Step 91050: loss = 2.0936\n",
            "Epoch 203:  33% 300/901 [00:36<01:04,  9.27it/s]Step 91050: loss = 2.0935\n",
            "Epoch 203:  44% 398/901 [00:47<00:54,  9.21it/s]Step 91100: loss = 2.0981\n",
            "Epoch 203:  44% 400/901 [00:47<00:56,  8.92it/s]Step 91100: loss = 2.0976\n",
            "Epoch 203:  55% 498/901 [00:58<00:42,  9.50it/s]Step 91150: loss = 2.0906\n",
            "Epoch 203:  55% 500/901 [00:59<00:42,  9.51it/s]Step 91150: loss = 2.0905\n",
            "Epoch 203:  66% 599/901 [01:09<00:33,  8.91it/s]Step 91200: loss = 2.1021\n",
            "Step 91200: loss = 2.1012\n",
            "Epoch 203:  77% 698/901 [01:21<00:24,  8.38it/s]Step 91250: loss = 2.1009\n",
            "Epoch 203:  78% 700/901 [01:21<00:22,  9.09it/s]Step 91250: loss = 2.1004\n",
            "Epoch 203:  89% 799/901 [01:33<00:12,  8.43it/s]Step 91300: loss = 2.1004\n",
            "Epoch 203:  89% 800/901 [01:33<00:14,  7.10it/s]Step 91300: loss = 2.0999\n",
            "Epoch 203: 100% 899/901 [01:44<00:00,  8.53it/s]Step 91350: loss = 2.0952\n",
            "Epoch 203: 100% 900/901 [01:45<00:00,  8.22it/s]Step 91350: loss = 2.0949\n",
            "Epoch 203: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 203 completed. Average training loss: 2.0949\n",
            "Validation loss after epoch 203: 2.2818\n",
            "Checkpoint saved -> checkpoints/model_epoch_203.pt\n",
            "Epoch 204:   0% 0/901 [00:00<?, ?it/s]Step 91350: loss = 2.2559\n",
            "Epoch 204:  11% 99/901 [00:11<01:37,  8.24it/s]Step 91400: loss = 2.1099\n",
            "Epoch 204:  11% 100/901 [00:11<01:33,  8.59it/s]Step 91400: loss = 2.1100\n",
            "Epoch 204:  22% 198/901 [00:22<01:22,  8.55it/s]Step 91450: loss = 2.0826\n",
            "Epoch 204:  22% 200/901 [00:23<01:16,  9.13it/s]Step 91450: loss = 2.0813\n",
            "Epoch 204:  33% 299/901 [00:34<01:16,  7.89it/s]Step 91500: loss = 2.0824\n",
            "Checkpoint saved -> checkpoints/model_step_91500.pt\n",
            "Epoch 204:  33% 300/901 [00:35<02:36,  3.83it/s]Step 91500: loss = 2.0803\n",
            "Checkpoint saved -> checkpoints/model_step_91500.pt\n",
            "Epoch 204:  44% 398/901 [00:47<01:03,  7.96it/s]Step 91550: loss = 2.0792\n",
            "Epoch 204:  44% 400/901 [00:47<01:02,  8.03it/s]Step 91550: loss = 2.0789\n",
            "Epoch 204:  55% 499/901 [00:58<00:43,  9.32it/s]Step 91600: loss = 2.0923\n",
            "Epoch 204:  55% 500/901 [00:58<00:42,  9.43it/s]Step 91600: loss = 2.0923\n",
            "Epoch 204:  66% 598/901 [01:10<00:35,  8.57it/s]Step 91650: loss = 2.0966\n",
            "Epoch 204:  67% 600/901 [01:10<00:36,  8.35it/s]Step 91650: loss = 2.0971\n",
            "Epoch 204:  78% 699/901 [01:21<00:29,  6.87it/s]Step 91700: loss = 2.1005\n",
            "Epoch 204:  78% 700/901 [01:21<00:28,  7.17it/s]Step 91700: loss = 2.0999\n",
            "Epoch 204:  89% 798/901 [01:33<00:16,  6.14it/s]Step 91750: loss = 2.0896\n",
            "Epoch 204:  89% 800/901 [01:33<00:13,  7.28it/s]Step 91750: loss = 2.0899\n",
            "Epoch 204: 100% 898/901 [01:44<00:00,  7.91it/s]Step 91800: loss = 2.0895\n",
            "Epoch 204: 100% 900/901 [01:45<00:00,  8.35it/s]Step 91800: loss = 2.0895\n",
            "Epoch 204: 100% 901/901 [01:45<00:00,  8.56it/s]\n",
            "Epoch 204 completed. Average training loss: 2.0895\n",
            "Validation loss after epoch 204: 2.2811\n",
            "Checkpoint saved -> checkpoints/model_epoch_204.pt\n",
            "Epoch 205:   0% 0/901 [00:00<?, ?it/s]Step 91800: loss = 2.3866\n",
            "Epoch 205:  11% 98/901 [00:10<01:27,  9.22it/s]Step 91850: loss = 2.1286\n",
            "Epoch 205:  11% 100/901 [00:11<01:25,  9.42it/s]Step 91850: loss = 2.1265\n",
            "Epoch 205:  22% 199/901 [00:22<01:17,  9.09it/s]Step 91900: loss = 2.1011\n",
            "Epoch 205:  22% 200/901 [00:23<01:21,  8.63it/s]Step 91900: loss = 2.1007\n",
            "Epoch 205:  33% 298/901 [00:35<01:23,  7.25it/s]Step 91950: loss = 2.0791\n",
            "Epoch 205:  33% 300/901 [00:35<01:14,  8.07it/s]Step 91950: loss = 2.0802\n",
            "Epoch 205:  44% 398/901 [00:46<00:55,  9.13it/s]Step 92000: loss = 2.0885\n",
            "Checkpoint saved -> checkpoints/model_step_92000.pt\n",
            "Epoch 205:  44% 400/901 [00:47<01:35,  5.25it/s]Step 92000: loss = 2.0877\n",
            "Checkpoint saved -> checkpoints/model_step_92000.pt\n",
            "Epoch 205:  55% 499/901 [00:58<00:49,  8.04it/s]Step 92050: loss = 2.0932\n",
            "Epoch 205:  55% 500/901 [00:58<00:50,  7.91it/s]Step 92050: loss = 2.0934\n",
            "Epoch 205:  66% 599/901 [01:10<00:35,  8.39it/s]Step 92100: loss = 2.0906\n",
            "Epoch 205:  67% 600/901 [01:10<00:35,  8.55it/s]Step 92100: loss = 2.0915\n",
            "Epoch 205:  77% 698/901 [01:22<00:24,  8.24it/s]Step 92150: loss = 2.0809\n",
            "Epoch 205:  78% 700/901 [01:22<00:24,  8.28it/s]Step 92150: loss = 2.0804\n",
            "Epoch 205:  89% 799/901 [01:33<00:11,  8.79it/s]Step 92200: loss = 2.0839\n",
            "Epoch 205:  89% 800/901 [01:34<00:11,  8.63it/s]Step 92200: loss = 2.0844\n",
            "Epoch 205: 100% 899/901 [01:45<00:00,  8.68it/s]Step 92250: loss = 2.0888\n",
            "Epoch 205: 100% 900/901 [01:45<00:00,  8.70it/s]Step 92250: loss = 2.0890\n",
            "Epoch 205: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 205 completed. Average training loss: 2.0890\n",
            "Validation loss after epoch 205: 2.2805\n",
            "Checkpoint saved -> checkpoints/model_epoch_205.pt\n",
            "Epoch 206:   0% 0/901 [00:00<?, ?it/s]Step 92250: loss = 2.4193\n",
            "Epoch 206:  11% 98/901 [00:11<01:34,  8.50it/s]Step 92300: loss = 2.0598\n",
            "Epoch 206:  11% 100/901 [00:11<01:32,  8.68it/s]Step 92300: loss = 2.0540\n",
            "Epoch 206:  22% 199/901 [00:23<01:16,  9.17it/s]Step 92350: loss = 2.0657\n",
            "Epoch 206:  22% 200/901 [00:23<01:22,  8.52it/s]Step 92350: loss = 2.0669\n",
            "Epoch 206:  33% 298/901 [00:35<01:13,  8.23it/s]Step 92400: loss = 2.0683\n",
            "Epoch 206:  33% 300/901 [00:35<01:06,  9.10it/s]Step 92400: loss = 2.0702\n",
            "Epoch 206:  44% 399/901 [00:46<00:56,  8.90it/s]Step 92450: loss = 2.0897\n",
            "Epoch 206:  44% 400/901 [00:46<00:58,  8.61it/s]Step 92450: loss = 2.0885\n",
            "Epoch 206:  55% 499/901 [00:58<00:48,  8.26it/s]Step 92500: loss = 2.0728\n",
            "Checkpoint saved -> checkpoints/model_step_92500.pt\n",
            "Epoch 206:  55% 500/901 [00:58<01:40,  3.98it/s]Step 92500: loss = 2.0729\n",
            "Checkpoint saved -> checkpoints/model_step_92500.pt\n",
            "Epoch 206:  66% 598/901 [01:10<00:32,  9.28it/s]Step 92550: loss = 2.0743\n",
            "Epoch 206:  67% 600/901 [01:10<00:32,  9.19it/s]Step 92550: loss = 2.0744\n",
            "Epoch 206:  78% 699/901 [01:21<00:22,  8.84it/s]Step 92600: loss = 2.0803\n",
            "Epoch 206:  78% 700/901 [01:22<00:26,  7.54it/s]Step 92600: loss = 2.0801\n",
            "Epoch 206:  89% 798/901 [01:33<00:10,  9.41it/s]Step 92650: loss = 2.0860\n",
            "Epoch 206:  89% 800/901 [01:33<00:10,  9.63it/s]Step 92650: loss = 2.0856\n",
            "Epoch 206: 100% 899/901 [01:44<00:00,  8.69it/s]Step 92700: loss = 2.0888\n",
            "Epoch 206: 100% 900/901 [01:44<00:00,  8.68it/s]Step 92700: loss = 2.0879\n",
            "Epoch 206: 100% 901/901 [01:44<00:00,  8.58it/s]\n",
            "Epoch 206 completed. Average training loss: 2.0879\n",
            "Validation loss after epoch 206: 2.2798\n",
            "Checkpoint saved -> checkpoints/model_epoch_206.pt\n",
            "Epoch 207:   0% 0/901 [00:00<?, ?it/s]Step 92700: loss = 2.2119\n",
            "Epoch 207:  11% 98/901 [00:11<01:20,  9.98it/s]Step 92750: loss = 2.0944\n",
            "Epoch 207:  11% 100/901 [00:11<01:37,  8.20it/s]Step 92750: loss = 2.0899\n",
            "Epoch 207:  22% 199/901 [00:22<01:31,  7.69it/s]Step 92800: loss = 2.0945\n",
            "Epoch 207:  22% 200/901 [00:23<01:29,  7.85it/s]Step 92800: loss = 2.0964\n",
            "Epoch 207:  33% 299/901 [00:34<01:08,  8.73it/s]Step 92850: loss = 2.0803\n",
            "Epoch 207:  33% 300/901 [00:34<01:08,  8.82it/s]Step 92850: loss = 2.0795\n",
            "Epoch 207:  44% 398/901 [00:46<00:55,  9.13it/s]Step 92900: loss = 2.0807\n",
            "Epoch 207:  44% 400/901 [00:46<00:53,  9.30it/s]Step 92900: loss = 2.0803\n",
            "Epoch 207:  55% 499/901 [00:57<00:43,  9.26it/s]Step 92950: loss = 2.0857\n",
            "Epoch 207:  55% 500/901 [00:57<00:46,  8.71it/s]Step 92950: loss = 2.0855\n",
            "Epoch 207:  66% 599/901 [01:08<00:37,  7.97it/s]Step 93000: loss = 2.0845\n",
            "Checkpoint saved -> checkpoints/model_step_93000.pt\n",
            "Epoch 207:  67% 600/901 [01:09<01:11,  4.23it/s]Step 93000: loss = 2.0851\n",
            "Checkpoint saved -> checkpoints/model_step_93000.pt\n",
            "Epoch 207:  78% 699/901 [01:21<00:23,  8.52it/s]Step 93050: loss = 2.0865\n",
            "Epoch 207:  78% 700/901 [01:21<00:23,  8.57it/s]Step 93050: loss = 2.0867\n",
            "Epoch 207:  89% 798/901 [01:33<00:11,  9.11it/s]Step 93100: loss = 2.0858\n",
            "Epoch 207:  89% 800/901 [01:33<00:11,  8.91it/s]Step 93100: loss = 2.0867\n",
            "Epoch 207: 100% 899/901 [01:44<00:00,  9.86it/s]Step 93150: loss = 2.0912\n",
            "Epoch 207: 100% 900/901 [01:45<00:00,  8.81it/s]Step 93150: loss = 2.0919\n",
            "Epoch 207: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 207 completed. Average training loss: 2.0919\n",
            "Validation loss after epoch 207: 2.2792\n",
            "Checkpoint saved -> checkpoints/model_epoch_207.pt\n",
            "Epoch 208:   0% 0/901 [00:00<?, ?it/s]Step 93150: loss = 2.4007\n",
            "Epoch 208:  11% 99/901 [00:10<01:29,  8.98it/s]Step 93200: loss = 2.1640\n",
            "Epoch 208:  11% 100/901 [00:11<01:42,  7.80it/s]Step 93200: loss = 2.1652\n",
            "Epoch 208:  22% 199/901 [00:22<01:16,  9.13it/s]Step 93250: loss = 2.1458\n",
            "Epoch 208:  22% 200/901 [00:22<01:17,  9.01it/s]Step 93250: loss = 2.1468\n",
            "Epoch 208:  33% 299/901 [00:33<01:16,  7.87it/s]Step 93300: loss = 2.1363\n",
            "Epoch 208:  33% 300/901 [00:33<01:16,  7.87it/s]Step 93300: loss = 2.1361\n",
            "Epoch 208:  44% 399/901 [00:45<01:00,  8.37it/s]Step 93350: loss = 2.1073\n",
            "Epoch 208:  44% 400/901 [00:45<00:59,  8.41it/s]Step 93350: loss = 2.1070\n",
            "Epoch 208:  55% 498/901 [00:57<00:54,  7.35it/s]Step 93400: loss = 2.0969\n",
            "Epoch 208:  55% 500/901 [00:57<00:48,  8.29it/s]Step 93400: loss = 2.0968\n",
            "Epoch 208:  66% 599/901 [01:09<00:43,  6.90it/s]Step 93450: loss = 2.0910\n",
            "Epoch 208:  67% 600/901 [01:09<00:42,  7.05it/s]Step 93450: loss = 2.0900\n",
            "Epoch 208:  77% 698/901 [01:20<00:21,  9.25it/s]Step 93500: loss = 2.0926\n",
            "Checkpoint saved -> checkpoints/model_step_93500.pt\n",
            "Epoch 208:  78% 700/901 [01:21<00:41,  4.79it/s]Step 93500: loss = 2.0926\n",
            "Checkpoint saved -> checkpoints/model_step_93500.pt\n",
            "Epoch 208:  89% 798/901 [01:33<00:10,  9.98it/s]Step 93550: loss = 2.0944\n",
            "Epoch 208:  89% 800/901 [01:33<00:10,  9.40it/s]Step 93550: loss = 2.0949\n",
            "Epoch 208: 100% 898/901 [01:44<00:00,  7.79it/s]Step 93600: loss = 2.0910\n",
            "Epoch 208: 100% 900/901 [01:45<00:00,  7.65it/s]Step 93600: loss = 2.0914\n",
            "Epoch 208: 100% 901/901 [01:45<00:00,  8.57it/s]\n",
            "Epoch 208 completed. Average training loss: 2.0914\n",
            "Validation loss after epoch 208: 2.2786\n",
            "Checkpoint saved -> checkpoints/model_epoch_208.pt\n",
            "Epoch 209:   0% 0/901 [00:00<?, ?it/s]Step 93600: loss = 2.0835\n",
            "Epoch 209:  11% 98/901 [00:11<01:37,  8.23it/s]Step 93650: loss = 2.1127\n",
            "Epoch 209:  11% 100/901 [00:11<01:34,  8.52it/s]Step 93650: loss = 2.1148\n",
            "Epoch 209:  22% 198/901 [00:22<01:17,  9.09it/s]Step 93700: loss = 2.0645\n",
            "Epoch 209:  22% 200/901 [00:23<01:13,  9.49it/s]Step 93700: loss = 2.0678\n",
            "Epoch 209:  33% 298/901 [00:34<01:09,  8.71it/s]Step 93750: loss = 2.0669\n",
            "Epoch 209:  33% 300/901 [00:34<01:07,  8.93it/s]Step 93750: loss = 2.0665\n",
            "Epoch 209:  44% 399/901 [00:46<01:00,  8.34it/s]Step 93800: loss = 2.0648\n",
            "Epoch 209:  44% 400/901 [00:46<01:01,  8.17it/s]Step 93800: loss = 2.0636\n",
            "Epoch 209:  55% 498/901 [00:58<00:48,  8.35it/s]Step 93850: loss = 2.0655\n",
            "Epoch 209:  55% 500/901 [00:58<00:47,  8.42it/s]Step 93850: loss = 2.0653\n",
            "Epoch 209:  66% 599/901 [01:10<00:32,  9.25it/s]Step 93900: loss = 2.0627\n",
            "Epoch 209:  67% 600/901 [01:10<00:32,  9.20it/s]Step 93900: loss = 2.0634\n",
            "Epoch 209:  77% 698/901 [01:21<00:22,  9.08it/s]Step 93950: loss = 2.0691\n",
            "Epoch 209:  78% 700/901 [01:21<00:21,  9.56it/s]Step 93950: loss = 2.0696\n",
            "Epoch 209:  89% 799/901 [01:32<00:12,  8.43it/s]Step 94000: loss = 2.0729\n",
            "Checkpoint saved -> checkpoints/model_step_94000.pt\n",
            "Epoch 209:  89% 800/901 [01:33<00:24,  4.08it/s]Step 94000: loss = 2.0730\n",
            "Checkpoint saved -> checkpoints/model_step_94000.pt\n",
            "Epoch 209: 100% 898/901 [01:45<00:00,  8.22it/s]Step 94050: loss = 2.0842\n",
            "Epoch 209: 100% 900/901 [01:45<00:00,  8.78it/s]Step 94050: loss = 2.0842\n",
            "Epoch 209: 100% 901/901 [01:45<00:00,  8.55it/s]\n",
            "Epoch 209 completed. Average training loss: 2.0842\n",
            "Validation loss after epoch 209: 2.2780\n",
            "Checkpoint saved -> checkpoints/model_epoch_209.pt\n",
            "Epoch 210:   0% 0/901 [00:00<?, ?it/s]Step 94050: loss = 1.9831\n",
            "Epoch 210:  11% 98/901 [00:11<01:36,  8.29it/s]Step 94100: loss = 2.0576\n",
            "Epoch 210:  11% 100/901 [00:12<01:30,  8.81it/s]Step 94100: loss = 2.0580\n",
            "Epoch 210:  22% 198/901 [00:23<01:13,  9.55it/s]Step 94150: loss = 2.0742\n",
            "Epoch 210:  22% 200/901 [00:23<01:09, 10.03it/s]Step 94150: loss = 2.0741\n",
            "Epoch 210:  33% 298/901 [00:34<01:02,  9.72it/s]Step 94200: loss = 2.0835\n",
            "Epoch 210:  33% 300/901 [00:34<01:03,  9.50it/s]Step 94200: loss = 2.0826\n",
            "Epoch 210:  44% 399/901 [00:46<00:59,  8.46it/s]Step 94250: loss = 2.0843\n",
            "Epoch 210:  44% 400/901 [00:46<00:59,  8.37it/s]Step 94250: loss = 2.0831\n",
            "Epoch 210:  55% 499/901 [00:57<00:46,  8.63it/s]Step 94300: loss = 2.0897\n",
            "Step 94300: loss = 2.0918\n",
            "Epoch 210:  66% 599/901 [01:08<00:37,  8.06it/s]Step 94350: loss = 2.0925\n",
            "Epoch 210:  67% 600/901 [01:09<00:45,  6.59it/s]Step 94350: loss = 2.0924\n",
            "Epoch 210:  78% 699/901 [01:20<00:22,  9.15it/s]Step 94400: loss = 2.0951\n",
            "Epoch 210:  78% 700/901 [01:20<00:23,  8.40it/s]Step 94400: loss = 2.0953\n",
            "Epoch 210:  89% 798/901 [01:31<00:10,  9.99it/s]Step 94450: loss = 2.0989\n",
            "Epoch 210:  89% 800/901 [01:31<00:09, 11.00it/s]Step 94450: loss = 2.0988\n",
            "Epoch 210: 100% 898/901 [01:43<00:00,  9.28it/s]Step 94500: loss = 2.0945\n",
            "Checkpoint saved -> checkpoints/model_step_94500.pt\n",
            "Epoch 210: 100% 900/901 [01:44<00:00,  5.19it/s]Step 94500: loss = 2.0945\n",
            "Checkpoint saved -> checkpoints/model_step_94500.pt\n",
            "Epoch 210: 100% 901/901 [01:44<00:00,  8.60it/s]\n",
            "Epoch 210 completed. Average training loss: 2.0945\n",
            "Validation loss after epoch 210: 2.2773\n",
            "Checkpoint saved -> checkpoints/model_epoch_210.pt\n",
            "Epoch 211:   0% 0/901 [00:00<?, ?it/s]Step 94500: loss = 2.2038\n",
            "Checkpoint saved -> checkpoints/model_step_94500.pt\n",
            "Epoch 211:  11% 98/901 [00:12<01:33,  8.63it/s]Step 94550: loss = 2.0543\n",
            "Epoch 211:  11% 100/901 [00:12<01:27,  9.20it/s]Step 94550: loss = 2.0510\n",
            "Epoch 211:  22% 199/901 [00:23<01:13,  9.60it/s]Step 94600: loss = 2.0536\n",
            "Epoch 211:  22% 200/901 [00:23<01:14,  9.40it/s]Step 94600: loss = 2.0548\n",
            "Epoch 211:  33% 298/901 [00:34<01:15,  8.04it/s]Step 94650: loss = 2.0793\n",
            "Epoch 211:  33% 300/901 [00:34<01:09,  8.69it/s]Step 94650: loss = 2.0790\n",
            "Epoch 211:  44% 398/901 [00:46<00:58,  8.55it/s]Step 94700: loss = 2.0802\n",
            "Epoch 211:  44% 400/901 [00:46<00:57,  8.73it/s]Step 94700: loss = 2.0810\n",
            "Epoch 211:  55% 498/901 [00:57<00:48,  8.33it/s]Step 94750: loss = 2.0865\n",
            "Epoch 211:  55% 500/901 [00:57<00:44,  8.97it/s]Step 94750: loss = 2.0865\n",
            "Epoch 211:  66% 598/901 [01:08<00:35,  8.65it/s]Step 94800: loss = 2.0928\n",
            "Epoch 211:  67% 600/901 [01:09<00:39,  7.69it/s]Step 94800: loss = 2.0918\n",
            "Epoch 211:  77% 698/901 [01:20<00:25,  7.96it/s]Step 94850: loss = 2.0923\n",
            "Epoch 211:  78% 700/901 [01:20<00:25,  7.92it/s]Step 94850: loss = 2.0935\n",
            "Epoch 211:  89% 798/901 [01:32<00:10,  9.75it/s]Step 94900: loss = 2.0947\n",
            "Epoch 211:  89% 800/901 [01:32<00:10,  9.69it/s]Step 94900: loss = 2.0950\n",
            "Epoch 211: 100% 898/901 [01:44<00:00,  8.04it/s]Step 94950: loss = 2.0865\n",
            "Epoch 211: 100% 900/901 [01:44<00:00,  9.39it/s]Step 94950: loss = 2.0867\n",
            "Epoch 211: 100% 901/901 [01:44<00:00,  8.62it/s]\n",
            "Epoch 211 completed. Average training loss: 2.0867\n",
            "Validation loss after epoch 211: 2.2767\n",
            "Checkpoint saved -> checkpoints/model_epoch_211.pt\n",
            "Epoch 212:   0% 0/901 [00:00<?, ?it/s]Step 94950: loss = 1.9482\n",
            "Epoch 212:  11% 98/901 [00:11<01:40,  7.98it/s]Step 95000: loss = 2.0294\n",
            "Checkpoint saved -> checkpoints/model_step_95000.pt\n",
            "Epoch 212:  11% 100/901 [00:12<02:39,  5.02it/s]Step 95000: loss = 2.0322\n",
            "Checkpoint saved -> checkpoints/model_step_95000.pt\n",
            "Epoch 212:  22% 199/901 [00:24<01:16,  9.19it/s]Step 95050: loss = 2.0298\n",
            "Epoch 212:  22% 200/901 [00:24<01:15,  9.28it/s]Step 95050: loss = 2.0290\n",
            "Epoch 212:  33% 298/901 [00:36<01:08,  8.78it/s]Step 95100: loss = 2.0435\n",
            "Epoch 212:  33% 300/901 [00:36<01:06,  9.02it/s]Step 95100: loss = 2.0459\n",
            "Epoch 212:  44% 398/901 [00:47<01:15,  6.65it/s]Step 95150: loss = 2.0574\n",
            "Epoch 212:  44% 400/901 [00:47<01:03,  7.93it/s]Step 95150: loss = 2.0578\n",
            "Epoch 212:  55% 498/901 [00:59<00:48,  8.26it/s]Step 95200: loss = 2.0611\n",
            "Epoch 212:  55% 500/901 [00:59<00:44,  9.10it/s]Step 95200: loss = 2.0623\n",
            "Epoch 212:  66% 599/901 [01:10<00:37,  8.15it/s]Step 95250: loss = 2.0649\n",
            "Epoch 212:  67% 600/901 [01:10<00:36,  8.33it/s]Step 95250: loss = 2.0654\n",
            "Epoch 212:  78% 699/901 [01:22<00:23,  8.57it/s]Step 95300: loss = 2.0738\n",
            "Epoch 212:  78% 700/901 [01:22<00:24,  8.26it/s]Step 95300: loss = 2.0738\n",
            "Epoch 212:  89% 798/901 [01:33<00:12,  8.41it/s]Step 95350: loss = 2.0754\n",
            "Epoch 212:  89% 800/901 [01:33<00:12,  8.04it/s]Step 95350: loss = 2.0754\n",
            "Epoch 212: 100% 898/901 [01:45<00:00,  9.65it/s]Step 95400: loss = 2.0751\n",
            "Epoch 212: 100% 900/901 [01:45<00:00,  9.14it/s]Step 95400: loss = 2.0748\n",
            "Epoch 212: 100% 901/901 [01:45<00:00,  8.54it/s]\n",
            "Epoch 212 completed. Average training loss: 2.0748\n",
            "Validation loss after epoch 212: 2.2761\n",
            "Checkpoint saved -> checkpoints/model_epoch_212.pt\n",
            "Epoch 213:   0% 0/901 [00:00<?, ?it/s]Step 95400: loss = 1.8952\n",
            "Epoch 213:  11% 98/901 [00:10<01:38,  8.17it/s]Step 95450: loss = 2.1103\n",
            "Epoch 213:  11% 100/901 [00:11<01:31,  8.72it/s]Step 95450: loss = 2.1049\n",
            "Epoch 213:  22% 199/901 [00:22<01:29,  7.82it/s]Step 95500: loss = 2.0968\n",
            "Checkpoint saved -> checkpoints/model_step_95500.pt\n",
            "Epoch 213:  22% 200/901 [00:23<02:52,  4.07it/s]Step 95500: loss = 2.0964\n",
            "Checkpoint saved -> checkpoints/model_step_95500.pt\n",
            "Epoch 213:  33% 299/901 [00:35<01:05,  9.18it/s]Step 95550: loss = 2.0928\n",
            "Epoch 213:  33% 300/901 [00:35<01:09,  8.66it/s]Step 95550: loss = 2.0933\n",
            "Epoch 213:  44% 398/901 [00:47<00:53,  9.36it/s]Step 95600: loss = 2.0772\n",
            "Epoch 213:  44% 400/901 [00:47<00:54,  9.12it/s]Step 95600: loss = 2.0762\n",
            "Epoch 213:  55% 499/901 [00:58<00:47,  8.50it/s]Step 95650: loss = 2.0682\n",
            "Epoch 213:  55% 500/901 [00:59<00:46,  8.63it/s]Step 95650: loss = 2.0681\n",
            "Epoch 213:  66% 598/901 [01:10<00:33,  9.01it/s]Step 95700: loss = 2.0781\n",
            "Epoch 213:  67% 600/901 [01:10<00:34,  8.61it/s]Step 95700: loss = 2.0777\n",
            "Epoch 213:  77% 698/901 [01:21<00:22,  9.09it/s]Step 95750: loss = 2.0845\n",
            "Epoch 213:  78% 700/901 [01:21<00:21,  9.54it/s]Step 95750: loss = 2.0841\n",
            "Epoch 213:  89% 799/901 [01:32<00:12,  7.89it/s]Step 95800: loss = 2.0845\n",
            "Epoch 213:  89% 800/901 [01:32<00:12,  8.15it/s]Step 95800: loss = 2.0843\n",
            "Epoch 213: 100% 899/901 [01:44<00:00,  7.18it/s]Step 95850: loss = 2.0848\n",
            "Epoch 213: 100% 900/901 [01:44<00:00,  7.40it/s]Step 95850: loss = 2.0850\n",
            "Epoch 213: 100% 901/901 [01:45<00:00,  8.58it/s]\n",
            "Epoch 213 completed. Average training loss: 2.0850\n",
            "Validation loss after epoch 213: 2.2755\n",
            "Checkpoint saved -> checkpoints/model_epoch_213.pt\n",
            "Epoch 214:   0% 0/901 [00:00<?, ?it/s]Step 95850: loss = 2.2922\n",
            "Epoch 214:  11% 98/901 [00:11<01:27,  9.19it/s]Step 95900: loss = 2.0838\n",
            "Epoch 214:  11% 100/901 [00:11<01:21,  9.89it/s]Step 95900: loss = 2.0885\n",
            "Epoch 214:  22% 198/901 [00:23<01:31,  7.72it/s]Step 95950: loss = 2.0684\n",
            "Epoch 214:  22% 200/901 [00:23<01:29,  7.87it/s]Step 95950: loss = 2.0682\n",
            "Epoch 214:  33% 299/901 [00:34<01:25,  7.06it/s]Step 96000: loss = 2.0760\n",
            "Checkpoint saved -> checkpoints/model_step_96000.pt\n",
            "Epoch 214:  33% 300/901 [00:35<02:50,  3.53it/s]Step 96000: loss = 2.0754\n",
            "Checkpoint saved -> checkpoints/model_step_96000.pt\n",
            "Epoch 214:  44% 398/901 [00:47<01:02,  8.07it/s]Step 96050: loss = 2.0735\n",
            "Epoch 214:  44% 400/901 [00:47<00:52,  9.50it/s]Step 96050: loss = 2.0724\n",
            "Epoch 214:  55% 499/901 [01:00<00:48,  8.34it/s]Step 96100: loss = 2.0613\n",
            "Epoch 214:  55% 500/901 [01:00<00:51,  7.79it/s]Step 96100: loss = 2.0625\n",
            "Epoch 214:  66% 598/901 [01:11<00:34,  8.71it/s]Step 96150: loss = 2.0680\n",
            "Epoch 214:  67% 600/901 [01:11<00:34,  8.71it/s]Step 96150: loss = 2.0680\n",
            "Epoch 214:  71% 640/901 [01:15<00:30,  8.44it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/drive/My Drive/flash_transformer/src/training/train.py\", line 180, in <module>\n",
            "    train_model()\n",
            "  File \"/content/drive/My Drive/flash_transformer/src/training/train.py\", line 138, in train_model\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!bash scripts/train.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5104681",
      "metadata": {
        "id": "a5104681"
      },
      "source": [
        "## 4. Evaluate on Test Set\n",
        "Run the evaluation script to compute the BLEU score on the test split.\n",
        "It will load the final checkpoint (by default, `model_epoch_X.pt`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "QXzQxzPxfGjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0496e9-18d4-4c52-fabd-66367ba5e92f"
      },
      "id": "QXzQxzPxfGjX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57de256",
      "metadata": {
        "id": "b57de256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5705ab8a-82ee-4521-8f09-fd26e5ca0fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/flash_transformer/src/evaluation/evaluate.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
            "Evaluating:  17% 2/12 [02:36<12:48, 76.87s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  25% 3/12 [03:53<11:31, 76.80s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  33% 4/12 [05:02<09:52, 74.01s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  42% 5/12 [06:17<08:39, 74.22s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  50% 6/12 [07:29<07:19, 73.32s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  58% 7/12 [08:41<06:05, 73.08s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  67% 8/12 [09:54<04:51, 72.91s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  75% 9/12 [10:58<03:30, 70.13s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  83% 10/12 [12:17<02:25, 72.85s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating:  92% 11/12 [13:30<01:12, 73.00s/it]That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "Evaluating: 100% 12/12 [14:45<00:00, 73.76s/it]\n",
            "That's 100 lines that end in a tokenized period ('.')\n",
            "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
            "\n",
            "Final Corpus BLEU on 20% subset: 0.10\n",
            "Average Sentence-Level BLEU (batch-averaged): 1.43\n",
            "Saved BLEU scores plot to: bleu_scores_plot.png\n",
            "Figure(800x500)\n",
            "Saved evaluation results to: bleu_scores_results.json\n"
          ]
        }
      ],
      "source": [
        "!bash scripts/evaluate.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4d104b",
      "metadata": {
        "id": "5f4d104b"
      },
      "source": [
        "## 5. Inference Example\n",
        "Below is a quick demonstration of translating custom inputs.\n",
        "This calls the `generate_translation` function from `src/evaluation/inference.py`.\n",
        "> **Note**: This is a minimal demonstration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "import sentencepiece as spm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from src.model.transformer import Transformer\n",
        "from src.evaluation.inference import generate_translation\n",
        "\n",
        "def plot_token_embeddings(tokens, emb_2d, sentence_idx):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=\"blue\")\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        x, y = emb_2d[i]\n",
        "        plt.text(x + 0.02, y + 0.02, token, fontsize=9, color=\"red\")\n",
        "\n",
        "    plt.title(f\"Source Sentence {sentence_idx + 1} Embeddings (PCA)\")\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    with open(\"config/config.yaml\", \"r\") as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "\n",
        "    device = cfg[\"training\"][\"device\"]\n",
        "    sp_model = spm.SentencePieceProcessor(model_file=f\"{cfg['data']['vocab_prefix']}.model\")\n",
        "\n",
        "    src_vocab_size = sp_model.vocab_size()\n",
        "    tgt_vocab_size = sp_model.vocab_size()\n",
        "    model = Transformer(\n",
        "        src_vocab_size=src_vocab_size,\n",
        "        tgt_vocab_size=tgt_vocab_size,\n",
        "        d_model=cfg[\"model\"][\"d_model\"],\n",
        "        n_heads=cfg[\"model\"][\"n_heads\"],\n",
        "        num_encoder_layers=cfg[\"model\"][\"num_encoder_layers\"],\n",
        "        num_decoder_layers=cfg[\"model\"][\"num_decoder_layers\"],\n",
        "        d_ff=cfg[\"model\"][\"d_ff\"],\n",
        "        max_len=cfg[\"model\"][\"max_position_embeddings\"],\n",
        "        dropout=cfg[\"model\"][\"dropout\"]\n",
        "    ).to(device)\n",
        "\n",
        "    epoch_ckpt = f\"model_epoch_{cfg['training']['max_epochs']}.pt\"\n",
        "    ckpt_path = f\"{cfg['logging']['checkpoint_dir']}/{epoch_ckpt}\"\n",
        "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    custom_sentences = [\n",
        "        \"Hello, how are you today?\",\n",
        "        \"This is a test to see if our model can translate English to German.\",\n",
        "        \"The weather is nice, and I want to go outside!\"\n",
        "    ]\n",
        "\n",
        "    tokenized_inputs = []\n",
        "    for sent in custom_sentences:\n",
        "        pieces = sp_model.encode(sent, out_type=int)\n",
        "        tokenized_inputs.append(pieces)\n",
        "\n",
        "    max_len_input = max(len(x) for x in tokenized_inputs)\n",
        "    pad_id = 1\n",
        "\n",
        "    src_tensor_list = []\n",
        "    for inp in tokenized_inputs:\n",
        "        pad_needed = max_len_input - len(inp)\n",
        "        src_tensor_list.append(inp + [pad_id] * pad_needed)\n",
        "    src_tensor = torch.tensor(src_tensor_list, dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        translations = generate_translation(model, src_tensor, sp_model, cfg)\n",
        "\n",
        "    print(\"\\n--- Inference Results ---\")\n",
        "    for i, (inp_ids, hyp_ids) in enumerate(zip(src_tensor_list, translations)):\n",
        "        src_clean = [tid for tid in inp_ids if tid not in [pad_id, 2, 3]]\n",
        "        src_text = sp_model.DecodeIds(src_clean)\n",
        "\n",
        "        hyp_text = sp_model.DecodeIds([tid for tid in hyp_ids if tid not in [2, 3, 1]])\n",
        "\n",
        "        print(f\"Sentence {i+1} | EN: {custom_sentences[i]}\")\n",
        "        print(f\"-> DE (hyp): {hyp_text}\\n\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            src_ids_tensor = torch.tensor(src_clean, device=device).unsqueeze(0)\n",
        "            emb_vectors = model.src_embedding(src_ids_tensor)\n",
        "            emb_vectors = emb_vectors.squeeze(0)\n",
        "\n",
        "        pca = PCA(n_components=2)\n",
        "        emb_2d = pca.fit_transform(emb_vectors.cpu().numpy())\n",
        "\n",
        "        token_strs = sp_model.IdToPiece(src_clean)\n",
        "\n",
        "        plot_token_embeddings(token_strs, emb_2d, i)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fuxAhk_g3q3v",
        "outputId": "ffd6f2b5-21c2-4bb8-a479-569c5f16ccd5"
      },
      "id": "fuxAhk_g3q3v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-79daff8a2875>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Inference Results ---\n",
            "Sentence 1 | EN: Hello, how are you today?\n",
            "-> DE (hyp): I ch ch , daß die s n , daß die s n , daß die s .\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 2 | EN: This is a test to see if our model can translate English to German.\n",
            "-> DE (hyp): I ch ch , daß die , daß die s , daß die , daß die s , daß die s , daß die s , daß die s n , daß die en , daß die s .\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 3 | EN: The weather is nice, and I want to go outside!\n",
            "-> DE (hyp): I ch ch , daß die , daß die , die , daß die , daß die , die , die n , die s , die , die s , die , die n , die , die s ,\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}